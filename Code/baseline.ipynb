{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"combine.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyM6AVwZLTh6Il2ieN4HAjaT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dUj_lAuRt7Ge","executionInfo":{"status":"ok","timestamp":1661758180877,"user_tz":-600,"elapsed":20718,"user":{"displayName":"XIAOMIN CHANG","userId":"17429039977919006081"}},"outputId":"2bea798b-32db-478a-c731-9f1bfc3d8991"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from sklearn.metrics import  zero_one_loss,mean_absolute_error,r2_score, mean_squared_error\n","def get_mae(target, prediction):\n","    assert (target.shape == prediction.shape)\n","\n","    return mean_absolute_error(target, prediction)\n","\n","def get_mse(target, prediction):\n","    assert (target.shape == prediction.shape)\n","\n","    return mean_squared_error(target, prediction)\n","\n","def get_sae(target, prediction):\n","    assert (target.shape == prediction.shape)\n","\n","    r = target.sum()\n","    r0 = prediction.sum()\n","    sae = abs(r0 - r) / r\n","    return sae\n","\n","def get_nde(target, prediction):\n","    assert (target.shape == prediction.shape)\n","\n","    error, squarey = [], []\n","    for i in range(len(prediction)):\n","        value = prediction[i] - target[i]\n","        error.append(value * value)\n","        squarey.append(target[i] * target[i])\n","    nde = sqrt(sum(error) / sum(squarey))\n","    return nde\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import sys\n","import logging\n","import numpy as np\n","\n","\n","def get_logger(filename):\n","    # Logging configuration: set the basic configuration of the logging system\n","    log_formatter = logging.Formatter(fmt='%(asctime)s [%(processName)s, %(process)s] [%(levelname)-5.5s]  %(message)s',\n","                                      datefmt='%m-%d %H:%M')\n","    logger = logging.getLogger()\n","    logger.setLevel(logging.DEBUG)\n","    # File logger\n","    file_handler = logging.FileHandler(\"{}.log\".format(filename))\n","    file_handler.setFormatter(log_formatter)\n","    file_handler.setLevel(logging.DEBUG)\n","    logger.addHandler(file_handler)\n","    # Stderr logger\n","    std_handler = logging.StreamHandler(sys.stdout)\n","    std_handler.setFormatter(log_formatter)\n","    std_handler.setLevel(logging.DEBUG)\n","    logger.addHandler(std_handler)\n","    return logger\n","\n","\n","def data_loader(inputs, targets, batch_size, shuffle=True):\n","    assert inputs.shape[0] == targets.shape[0]\n","    inputs_size = inputs.shape[0]\n","    if shuffle:\n","        random_order = np.arange(inputs_size)\n","        np.random.shuffle(random_order)\n","        inputs, targets = inputs[random_order, :], targets[random_order]\n","    num_blocks = int(inputs_size / batch_size)\n","    for i in range(num_blocks):\n","        yield inputs[i * batch_size: (i+1) * batch_size, :], targets[i * batch_size: (i+1) * batch_size]\n","    if num_blocks * batch_size != inputs_size:\n","        yield inputs[num_blocks * batch_size:, :], targets[num_blocks * batch_size:]\n","\n","\n","def multi_data_loader(inputs, targets, batch_size, shuffle=True):\n","    \"\"\"\n","    Both inputs and targets are list of numpy arrays, containing instances and labels from multiple sources.\n","    \"\"\"\n","    assert len(inputs) == len(targets)\n","    input_sizes = [data.shape[0] for data in inputs]\n","    max_input_size = max(input_sizes)\n","    num_domains = len(inputs)\n","    if shuffle:\n","        for i in range(num_domains):\n","            r_order = np.arange(input_sizes[i])\n","            np.random.shuffle(r_order)\n","            inputs[i], targets[i] = inputs[i][r_order, :], targets[i][r_order]\n","    num_blocks = int(max_input_size / batch_size)\n","    for j in range(num_blocks):\n","        xs, ys = [], []\n","        for i in range(num_domains):\n","            ridx = np.random.choice(input_sizes[i], batch_size)\n","            xs.append(inputs[i][ridx, :])\n","            ys.append(targets[i][ridx])\n","        yield xs, ys\n"],"metadata":{"id":"DEmnAq2qzcyX","executionInfo":{"status":"ok","timestamp":1661758180878,"user_tz":-600,"elapsed":6,"user":{"displayName":"XIAOMIN CHANG","userId":"17429039977919006081"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler,MinMaxScaler\n","def dataProvider(file,windowsize,stepsize,threshold):  \n","    dataframe=pd.read_csv(file,header=0)    \n","    np_array=np.array(dataframe)\n","    inputs, targets=np_array[:, 0], np_array[:, 1]\n","    offset = int(0.5 * (windowsize - 1.0))\n","#     window_num=inputs.size - 2 * offset\n","    features=list()\n","    labels=list()\n","    i=0\n","    while (i<=inputs.size-windowsize):\n","        data_in=inputs[i:i+windowsize]\n","        tar=targets[i+offset]\n","        features.append(data_in)\n","        labels.append(tar)\n","        i=i+stepsize\n","    X=np.array(features)\n","    Y=np.array(labels)\n","    Y[Y<=threshold] = 0\n","    # scaler = MinMaxScaler()\n","    # X=scaler.fit_transform(X)\n","    x_train_all, X, y_train_all, Y = train_test_split(X, Y, test_size=0.2,random_state=100)\n","    return X,Y"],"metadata":{"id":"hus0K81kzgDv","executionInfo":{"status":"ok","timestamp":1661758181569,"user_tz":-600,"elapsed":696,"user":{"displayName":"XIAOMIN CHANG","userId":"17429039977919006081"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import lightgbm as lgb\n","from hyperopt import fmin, tpe, hp, partial, Trials, STATUS_OK,STATUS_FAIL\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error, zero_one_loss,mean_absolute_error,r2_score\n","import matplotlib.pyplot as plt\n","import time\n","from math import sqrt\n","import os\n","from tensorflow import keras\n","import math\n","import tensorflow.compat.v1 as tf\n","config = tf.ConfigProto()\n","config.gpu_options.allow_growth=True\n","sess = tf.Session(config=config)\n","print(tf.__version__)\n","windowsize=19\n","def CNN_training_best(X, Y):\n","    # x_train_all, x_predict, y_train_all, y_predict = train_test_split(X, Y, test_size=0.2, random_state=100)\n","    # del X, Y\n","    #argsDic=argsDict_tranform(argsDic)\n","    model=keras.models.Sequential()\n","    # model.add(LayerNormalization())\n","    model.add(keras.layers.Reshape((-1, windowsize, 1),input_shape=(19,)))\n","    model.add(keras.layers.BatchNormalization())\n","    model.add(keras.layers.Conv2D(filters=30,\n","                  kernel_size=(20, 1),\n","                  strides=(1, 1),\n","                  padding='same',\n","                  activation='relu',\n","                  ))\n","    model.add(keras.layers.Conv2D(filters=30,\n","                  kernel_size=(8, 1),\n","                  strides=(1, 1),\n","                  padding='same',\n","                  activation='relu',\n","                  ))\n","    model.add(keras.layers.Conv2D(filters=40,\n","                  kernel_size=(6, 1),\n","                  strides=(1, 1),\n","                  padding='same',\n","                  activation='relu',\n","                  ))\n","    model.add(keras.layers.Conv2D(filters=50,\n","                  kernel_size=(5, 1),\n","                  strides=(1, 1),\n","                  padding='same',\n","                  activation='relu',\n","                  ))\n","    model.add(keras.layers.Conv2D(filters=50,\n","                  kernel_size=(5, 1),\n","                  strides=(1, 1),\n","                  padding='same',\n","                  activation='relu',\n","                  ))\n","    #model.add(LayerNormalization())\n","    model.add(keras.layers.Flatten(name='flatten'))\n","    # model.add(keras.layers.Dropout(argsDic['layer3_dropout']))\n","    model.add(keras.layers.BatchNormalization())\n","    model.add(keras.layers.Dense(1024, activation='relu', name='dense'))\n","    model.add(keras.layers.BatchNormalization())\n","    # model.add(keras.layers.Dense(256, activation='relu', name='dense1'))\n","    model.add(keras.layers.Dense(1, activation='linear', name='output'))\n","    adam = keras.optimizers.Adam(learning_rate=0.0001,\n","                                  beta_1=0.99,\n","                                  beta_2=0.999,\n","                                  epsilon=1e-08)\n","                                  # use_locking=False)\n","    model.compile(optimizer=adam, loss='mean_squared_error', metrics=['mae'])\n","    # model.compile(optimizer='sgd', loss='mean_absolute_error', metrics=['mae'])\n","    print('start training')\n","   # model.fit(X,Y, epochs=50, batch_size=16, validation_split=0.2)\n","    model.fit(X,Y, epochs=40, batch_size=64,validation_split=0.2)\n","    return model"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BhXWG0j5ziSk","executionInfo":{"status":"ok","timestamp":1661758187316,"user_tz":-600,"elapsed":5749,"user":{"displayName":"XIAOMIN CHANG","userId":"17429039977919006081"}},"outputId":"3db5be3e-cf10-442c-8c18-d57e92e5a2dc"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["2.8.2\n"]}]},{"cell_type":"code","source":["# ######################################Fridge###############################################################\n","# #trainfile4=\"/content/drive/MyDrive/training_data/dishwasher_test_.csv\"\n","# trainfile1=\"/content/drive/MyDrive/training_data/fridge_house_3_training_.csv\"\n","\n","# trainfile2=\"/content/drive/MyDrive/ukdale_training/fridge_house_2_training_.csv\"\n","# # trainfile3=\"/content/drive/MyDrive/ukdale_training/fridge_house_2_training_.csv\"\n","# trainfile3=\"/content/drive/MyDrive/refit_training/fridge/fridge_house_12_training_.csv\"\n","# trainfile4=\"/content/drive/MyDrive/refit_training/fridge/fridge_house_15_training_.csv\"\n","# fileList=[trainfile1,trainfile2,trainfile3,trainfile4]\n","# stepsizeList=[2,16,16,16]\n","# data_insts, data_labels, num_insts,on = [], [], [],[]\n","# threshold=50\n","# for i in range(len(fileList)):\n","#     X,Y=dataProvider(fileList[i], 19, stepsizeList[i], threshold)\n","#     Y=Y.reshape(-1,1)\n","#     data_insts.append(X)\n","#     data_labels.append(Y)\n","#     num_insts.append(X.shape[0])\n","# min_size=min(num_insts)\n","# x_tem, y_tem=[],[]\n","# for j in range(len(fileList)):\n","#   ridx = np.random.choice(num_insts[j], min_size)\n","#   x_tem.append(data_insts[j][ridx, :])\n","#   y_tem.append(data_labels[j][ridx, :])\n","#   num_insts[j]=x_tem[j].shape[0]\n","# data_insts=x_tem\n","# data_labels=y_tem \n","# print(num_insts)"],"metadata":{"id":"1S3WoFWmzpOC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ######################################Fridge###############################################################\n","trainfile1=\"/content/drive/MyDrive/ukdale_training/fridge_house_1_training_.csv\"\n","trainfile2=\"/content/drive/MyDrive/training_data/fridge_house_2_training_.csv\"\n","trainfile3=\"/content/drive/MyDrive/refit_training/fridge/fridge_house_2_training_.csv\"\n","trainfile4=\"/content/drive/MyDrive/refit_training/fridge/fridge_house_5_training_.csv\"\n","\n","trainfile5=\"/content/drive/MyDrive/ukdale_training/fridge_house_2_training_.csv\"\n","trainfile6=\"/content/drive/MyDrive/training_data/fridge_test_.csv\"\n","trainfile7=\"/content/drive/MyDrive/refit_training/fridge/fridge_house_9_training_.csv\"\n","trainfile8=\"/content/drive/MyDrive/refit_training/fridge/fridge_house_12_training_.csv\"\n","trainfile9=\"/content/drive/MyDrive/refit_training/fridge/fridge_house_15_training_.csv\"\n","trainfile10=\"/content/drive/MyDrive/training_data/fridge_house_3_training_.csv\"\n","\n","\n","\n","file=[trainfile1,trainfile2,trainfile3,trainfile4,trainfile5,trainfile6,trainfile7,trainfile8,trainfile9,trainfile10]\n","stepsizeList=[16,2,16,16,16,2,16,16,16,2]\n","list_x=[]\n","list_y=[]\n","for k in [2,4,6,8,10]:\n","    data_insts, data_labels, num_insts,on = [], [], [],[]\n","    threshold=50\n","    fileList=[]\n","    for a in range(k):\n","        fileList.append(file[a])\n","    for i in range(len(fileList)):\n","        X,Y=dataProvider(fileList[i], 19, stepsizeList[i], threshold)\n","        Y=Y.reshape(-1,1)\n","        data_insts.append(X)\n","        data_labels.append(Y)\n","        num_insts.append(X.shape[0])\n","\n","    min_size=min(num_insts)\n","    x_tem, y_tem=[],[]\n","    for j in range(len(fileList)):\n","      ridx = np.random.choice(num_insts[j], min_size)\n","      x_tem.append(data_insts[j][ridx, :])\n","      y_tem.append(data_labels[j][ridx, :])\n","      num_insts[j]=x_tem[j].shape[0]\n","    data_insts=x_tem\n","    data_labels=y_tem \n","    list_x.append(data_insts)\n","    list_y.append(data_labels)\n","    "],"metadata":{"id":"bojGt8F1-t7X"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","expnum=5\n","\n","for num in range(len(list_x)):\n","    for n in range(expnum):\n","        print(\"start group\"+str(num)+\",This is the experiment num:\", n )\n","        num_data_sets=len(list_x[num])\n","        data_insts=list_x[num]\n","        data_labels=list_y[num]\n","        num_domains=num_data_sets-1\n","        for i in [0]:\n","                print('\\n---------------------------------------------- domain num %i is running----------------------------------'%(i))\n","                # Build source instances.\n","                source_insts = []\n","                source_labels = []\n","                for j in range(num_data_sets):\n","                    if j != i:\n","                        source_insts.append(data_insts[j])\n","                        source_labels.append(data_labels[j])\n","                # Build target instances.\n","                target_idx = i\n","                target_insts = data_insts[i]\n","                target_labels = data_labels[i]\n","                target_insts0, X_t, target_labels0, y_t =train_test_split(target_insts, target_labels, test_size=0.2,random_state=100)\n","                \n","                X=np.concatenate(source_insts, axis=0)\n","                Y=np.concatenate(source_labels, axis=0)\n","                \n","                x_train_all, x_test, y_train_all, y_test =train_test_split(X, Y, test_size=0.2,random_state=100)\n","                model=CNN_training_best(X,Y)\n","                prediction=model.predict(X_t)\n","                stopT=get_mae(y_t, prediction)\n","                print(stopT)\n","                print(get_sae(y_t, prediction))\n","                print(get_nde(y_t, prediction))\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DmJX8E9N_AnD","executionInfo":{"status":"ok","timestamp":1661703840722,"user_tz":-600,"elapsed":37020604,"user":{"displayName":"XIAOMIN CHANG","userId":"17429039977919006081"}},"outputId":"52defa71-50a0-47a9-a351-c737b657694c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["start group0,This is the experiment num: 0\n","\n","---------------------------------------------- domain num 0 is running----------------------------------\n","start training\n","Epoch 1/40\n","188/188 [==============================] - 8s 36ms/step - loss: 10483.7441 - mae: 80.8984 - val_loss: 13565.4512 - val_mae: 77.0028\n","Epoch 2/40\n","188/188 [==============================] - 7s 35ms/step - loss: 8603.5898 - mae: 83.1364 - val_loss: 11789.5156 - val_mae: 81.3435\n","Epoch 3/40\n","188/188 [==============================] - 6s 34ms/step - loss: 8258.1416 - mae: 82.5731 - val_loss: 9993.5566 - val_mae: 82.6491\n","Epoch 4/40\n","188/188 [==============================] - 6s 34ms/step - loss: 7987.5474 - mae: 81.5373 - val_loss: 7376.9043 - val_mae: 74.6493\n","Epoch 5/40\n","188/188 [==============================] - 6s 34ms/step - loss: 7719.8721 - mae: 80.0453 - val_loss: 7078.5488 - val_mae: 74.7593\n","Epoch 6/40\n","188/188 [==============================] - 8s 42ms/step - loss: 7424.8491 - mae: 78.1629 - val_loss: 7078.6865 - val_mae: 75.2555\n","Epoch 7/40\n","188/188 [==============================] - 7s 37ms/step - loss: 7088.1040 - mae: 76.4898 - val_loss: 6434.0859 - val_mae: 70.9561\n","Epoch 8/40\n","188/188 [==============================] - 7s 35ms/step - loss: 6831.7930 - mae: 74.5267 - val_loss: 6446.8550 - val_mae: 70.7039\n","Epoch 9/40\n","188/188 [==============================] - 7s 35ms/step - loss: 6424.2876 - mae: 71.7301 - val_loss: 5853.4409 - val_mae: 67.4106\n","Epoch 10/40\n","188/188 [==============================] - 7s 36ms/step - loss: 5819.8857 - mae: 67.6159 - val_loss: 5293.9741 - val_mae: 62.2273\n","Epoch 11/40\n","188/188 [==============================] - 6s 34ms/step - loss: 5279.8364 - mae: 63.2320 - val_loss: 4423.1416 - val_mae: 54.3110\n","Epoch 12/40\n","188/188 [==============================] - 7s 35ms/step - loss: 4823.2280 - mae: 59.0056 - val_loss: 4255.2212 - val_mae: 54.0603\n","Epoch 13/40\n","188/188 [==============================] - 7s 35ms/step - loss: 4251.5142 - mae: 53.4550 - val_loss: 3394.7832 - val_mae: 42.0480\n","Epoch 14/40\n","188/188 [==============================] - 6s 35ms/step - loss: 3697.6301 - mae: 47.6920 - val_loss: 3071.5076 - val_mae: 34.2806\n","Epoch 15/40\n","188/188 [==============================] - 7s 35ms/step - loss: 3463.9773 - mae: 43.3279 - val_loss: 3810.6135 - val_mae: 45.7312\n","Epoch 16/40\n","188/188 [==============================] - 6s 34ms/step - loss: 3124.2900 - mae: 38.4590 - val_loss: 2984.9778 - val_mae: 35.9050\n","Epoch 17/40\n","188/188 [==============================] - 7s 35ms/step - loss: 2911.8657 - mae: 34.3706 - val_loss: 2919.5615 - val_mae: 26.9918\n","Epoch 18/40\n","188/188 [==============================] - 6s 34ms/step - loss: 2841.9216 - mae: 31.4330 - val_loss: 2717.7324 - val_mae: 26.3210\n","Epoch 19/40\n","188/188 [==============================] - 7s 35ms/step - loss: 2798.2446 - mae: 30.1243 - val_loss: 2807.9717 - val_mae: 26.3438\n","Epoch 20/40\n","188/188 [==============================] - 8s 45ms/step - loss: 2732.0305 - mae: 28.9715 - val_loss: 2742.1218 - val_mae: 26.5376\n","Epoch 21/40\n","188/188 [==============================] - 7s 35ms/step - loss: 2686.5298 - mae: 28.0813 - val_loss: 2654.7786 - val_mae: 30.0189\n","Epoch 22/40\n","188/188 [==============================] - 7s 35ms/step - loss: 2719.3147 - mae: 27.7997 - val_loss: 2973.1953 - val_mae: 27.6845\n","Epoch 23/40\n","188/188 [==============================] - 7s 35ms/step - loss: 2645.5950 - mae: 28.0103 - val_loss: 2642.4299 - val_mae: 26.4287\n","Epoch 24/40\n","188/188 [==============================] - 7s 35ms/step - loss: 2656.9644 - mae: 27.7929 - val_loss: 2616.9778 - val_mae: 29.3880\n","Epoch 25/40\n","188/188 [==============================] - 7s 35ms/step - loss: 2760.3718 - mae: 28.9237 - val_loss: 2688.7756 - val_mae: 25.5193\n","Epoch 26/40\n","188/188 [==============================] - 7s 35ms/step - loss: 2644.9160 - mae: 27.3761 - val_loss: 2620.0559 - val_mae: 25.2696\n","Epoch 27/40\n","188/188 [==============================] - 7s 35ms/step - loss: 2674.9487 - mae: 27.7043 - val_loss: 2653.8682 - val_mae: 24.2004\n","Epoch 28/40\n","188/188 [==============================] - 7s 35ms/step - loss: 2673.4492 - mae: 27.5488 - val_loss: 2778.0103 - val_mae: 28.0755\n","Epoch 29/40\n","188/188 [==============================] - 7s 36ms/step - loss: 2595.8333 - mae: 27.2055 - val_loss: 2745.8025 - val_mae: 23.4513\n","Epoch 30/40\n","188/188 [==============================] - 7s 35ms/step - loss: 2673.9160 - mae: 28.3995 - val_loss: 2645.7305 - val_mae: 23.4871\n","Epoch 31/40\n","188/188 [==============================] - 7s 36ms/step - loss: 2673.1772 - mae: 27.7702 - val_loss: 2573.0911 - val_mae: 24.5962\n","Epoch 32/40\n","188/188 [==============================] - 7s 36ms/step - loss: 2644.9749 - mae: 28.0886 - val_loss: 2614.4441 - val_mae: 25.5018\n","Epoch 33/40\n","188/188 [==============================] - 8s 44ms/step - loss: 2646.8372 - mae: 28.1392 - val_loss: 2488.0012 - val_mae: 23.2515\n","Epoch 34/40\n","188/188 [==============================] - 7s 36ms/step - loss: 2569.2498 - mae: 27.6060 - val_loss: 2649.8799 - val_mae: 31.1792\n","Epoch 35/40\n","188/188 [==============================] - 7s 35ms/step - loss: 2568.0593 - mae: 27.3715 - val_loss: 2588.0740 - val_mae: 22.6012\n","Epoch 36/40\n","188/188 [==============================] - 7s 36ms/step - loss: 2534.9075 - mae: 27.0184 - val_loss: 2684.2554 - val_mae: 26.7058\n","Epoch 37/40\n","188/188 [==============================] - 7s 36ms/step - loss: 2539.6833 - mae: 27.7836 - val_loss: 2532.1753 - val_mae: 25.7570\n","Epoch 38/40\n","188/188 [==============================] - 7s 36ms/step - loss: 2523.0637 - mae: 26.7427 - val_loss: 2437.0225 - val_mae: 25.9015\n","Epoch 39/40\n","188/188 [==============================] - 7s 36ms/step - loss: 2576.1462 - mae: 27.6151 - val_loss: 2629.3181 - val_mae: 28.9751\n","Epoch 40/40\n","188/188 [==============================] - 7s 35ms/step - loss: 2491.7512 - mae: 27.2961 - val_loss: 2620.5737 - val_mae: 31.1125\n","62.570668022102424\n","0.8707232055400813\n","1.1826548782421797\n","start group0,This is the experiment num: 1\n","\n","---------------------------------------------- domain num 0 is running----------------------------------\n","start training\n","Epoch 1/40\n","188/188 [==============================] - 8s 37ms/step - loss: 10834.9043 - mae: 79.9893 - val_loss: 13276.1143 - val_mae: 74.2437\n","Epoch 2/40\n","188/188 [==============================] - 7s 35ms/step - loss: 8626.4053 - mae: 82.6185 - val_loss: 12074.2520 - val_mae: 81.5738\n","Epoch 3/40\n","188/188 [==============================] - 7s 36ms/step - loss: 8216.3604 - mae: 82.7349 - val_loss: 9528.8252 - val_mae: 82.0102\n","Epoch 4/40\n","188/188 [==============================] - 7s 36ms/step - loss: 7938.2329 - mae: 81.3839 - val_loss: 8304.2178 - val_mae: 81.5036\n","Epoch 5/40\n","188/188 [==============================] - 7s 35ms/step - loss: 7699.9863 - mae: 80.0549 - val_loss: 7457.6865 - val_mae: 77.0758\n","Epoch 6/40\n","188/188 [==============================] - 9s 45ms/step - loss: 7438.8848 - mae: 78.3378 - val_loss: 7683.6597 - val_mae: 79.0856\n","Epoch 7/40\n","188/188 [==============================] - 7s 36ms/step - loss: 7113.4985 - mae: 76.7622 - val_loss: 7643.4336 - val_mae: 78.0793\n","Epoch 8/40\n","188/188 [==============================] - 7s 35ms/step - loss: 6795.5776 - mae: 74.6365 - val_loss: 6443.2104 - val_mae: 70.4949\n","Epoch 9/40\n","188/188 [==============================] - 7s 36ms/step - loss: 6315.1445 - mae: 71.1500 - val_loss: 5279.5918 - val_mae: 61.3481\n","Epoch 10/40\n","188/188 [==============================] - 7s 35ms/step - loss: 5841.0483 - mae: 68.1417 - val_loss: 5537.9932 - val_mae: 64.0077\n","Epoch 11/40\n","188/188 [==============================] - 7s 36ms/step - loss: 5211.9351 - mae: 62.5321 - val_loss: 5091.5015 - val_mae: 62.0108\n","Epoch 12/40\n","188/188 [==============================] - 7s 35ms/step - loss: 4718.0259 - mae: 58.3546 - val_loss: 3268.4783 - val_mae: 42.2287\n","Epoch 13/40\n","188/188 [==============================] - 7s 36ms/step - loss: 4093.5916 - mae: 52.0110 - val_loss: 3318.5254 - val_mae: 42.3653\n","Epoch 14/40\n","188/188 [==============================] - 7s 35ms/step - loss: 3638.0569 - mae: 47.2399 - val_loss: 3352.6216 - val_mae: 41.6621\n","Epoch 15/40\n","188/188 [==============================] - 7s 36ms/step - loss: 3352.7678 - mae: 42.4946 - val_loss: 3127.9836 - val_mae: 41.2965\n","Epoch 16/40\n","188/188 [==============================] - 7s 36ms/step - loss: 3066.8811 - mae: 37.9231 - val_loss: 2814.7502 - val_mae: 28.3448\n","Epoch 17/40\n","188/188 [==============================] - 7s 35ms/step - loss: 2911.7510 - mae: 34.2957 - val_loss: 2766.0552 - val_mae: 31.9353\n","Epoch 18/40\n","188/188 [==============================] - 7s 36ms/step - loss: 2727.9124 - mae: 31.1261 - val_loss: 2756.1101 - val_mae: 29.6747\n","Epoch 19/40\n","188/188 [==============================] - 7s 38ms/step - loss: 2784.6182 - mae: 29.9902 - val_loss: 2698.5396 - val_mae: 27.5441\n","Epoch 20/40\n","188/188 [==============================] - 8s 42ms/step - loss: 2675.3931 - mae: 28.6203 - val_loss: 2758.3120 - val_mae: 24.5577\n","Epoch 21/40\n","188/188 [==============================] - 7s 35ms/step - loss: 2671.9719 - mae: 28.6583 - val_loss: 3073.0405 - val_mae: 32.2277\n","Epoch 22/40\n","188/188 [==============================] - 7s 36ms/step - loss: 2690.6641 - mae: 27.7550 - val_loss: 3510.5342 - val_mae: 45.8369\n","Epoch 23/40\n","188/188 [==============================] - 7s 35ms/step - loss: 2681.9438 - mae: 28.0219 - val_loss: 2713.2634 - val_mae: 25.5350\n","Epoch 24/40\n","188/188 [==============================] - 7s 36ms/step - loss: 2720.2180 - mae: 28.5097 - val_loss: 2828.8875 - val_mae: 31.6398\n","Epoch 25/40\n","188/188 [==============================] - 7s 35ms/step - loss: 2646.0525 - mae: 28.2251 - val_loss: 2904.1770 - val_mae: 27.4871\n","Epoch 26/40\n","188/188 [==============================] - 7s 35ms/step - loss: 2683.8079 - mae: 27.5837 - val_loss: 2859.1404 - val_mae: 27.7152\n","Epoch 27/40\n","188/188 [==============================] - 7s 35ms/step - loss: 2678.1213 - mae: 28.7267 - val_loss: 2728.3425 - val_mae: 27.5275\n","Epoch 28/40\n","188/188 [==============================] - 7s 35ms/step - loss: 2699.6758 - mae: 28.0396 - val_loss: 2860.6714 - val_mae: 29.0393\n","Epoch 29/40\n","188/188 [==============================] - 7s 36ms/step - loss: 2698.3320 - mae: 28.6045 - val_loss: 2866.4988 - val_mae: 26.1230\n","Epoch 30/40\n","188/188 [==============================] - 7s 36ms/step - loss: 2694.2930 - mae: 28.0473 - val_loss: 2682.8601 - val_mae: 31.0105\n","Epoch 31/40\n","188/188 [==============================] - 7s 36ms/step - loss: 2644.7671 - mae: 27.5274 - val_loss: 2604.9797 - val_mae: 25.5504\n","Epoch 32/40\n","188/188 [==============================] - 7s 36ms/step - loss: 2647.7275 - mae: 27.9393 - val_loss: 2747.5452 - val_mae: 26.8506\n","Epoch 33/40\n","188/188 [==============================] - 9s 46ms/step - loss: 2632.0369 - mae: 27.7393 - val_loss: 2716.1050 - val_mae: 27.8599\n","Epoch 34/40\n","188/188 [==============================] - 7s 36ms/step - loss: 2692.8345 - mae: 28.2307 - val_loss: 2711.9417 - val_mae: 28.4195\n","Epoch 35/40\n","188/188 [==============================] - 7s 36ms/step - loss: 2607.1379 - mae: 28.1036 - val_loss: 2823.4111 - val_mae: 35.1121\n","Epoch 36/40\n","188/188 [==============================] - 7s 36ms/step - loss: 2638.7629 - mae: 27.5460 - val_loss: 2686.4238 - val_mae: 28.1883\n","Epoch 37/40\n","188/188 [==============================] - 7s 35ms/step - loss: 2573.1694 - mae: 27.1448 - val_loss: 2572.5054 - val_mae: 28.1916\n","Epoch 38/40\n","188/188 [==============================] - 7s 35ms/step - loss: 2635.3750 - mae: 27.7123 - val_loss: 2659.1536 - val_mae: 26.8544\n","Epoch 39/40\n","188/188 [==============================] - 7s 35ms/step - loss: 2573.0986 - mae: 27.6129 - val_loss: 2615.0830 - val_mae: 27.3492\n","Epoch 40/40\n","188/188 [==============================] - 7s 36ms/step - loss: 2621.8350 - mae: 27.7643 - val_loss: 2868.6619 - val_mae: 28.3320\n","80.83771751249598\n","1.7965489372508394\n","1.381999354173315\n","start group0,This is the experiment num: 2\n","\n","---------------------------------------------- domain num 0 is running----------------------------------\n","start training\n","Epoch 1/40\n","188/188 [==============================] - 26s 36ms/step - loss: 10430.9561 - mae: 80.5094 - val_loss: 13301.0781 - val_mae: 75.0654\n","Epoch 2/40\n","188/188 [==============================] - 6s 35ms/step - loss: 8595.0391 - mae: 83.1996 - val_loss: 11286.6621 - val_mae: 77.2296\n","Epoch 3/40\n","188/188 [==============================] - 7s 35ms/step - loss: 8234.5430 - mae: 82.6218 - val_loss: 7878.3091 - val_mae: 73.2308\n","Epoch 4/40\n","188/188 [==============================] - 7s 35ms/step - loss: 7896.2729 - mae: 81.5357 - val_loss: 6654.5400 - val_mae: 70.7722\n","Epoch 5/40\n","188/188 [==============================] - 6s 35ms/step - loss: 7754.6519 - mae: 80.3145 - val_loss: 6192.4292 - val_mae: 69.6455\n","Epoch 6/40\n","188/188 [==============================] - 7s 35ms/step - loss: 7440.4741 - mae: 78.7642 - val_loss: 7100.5093 - val_mae: 74.9806\n","Epoch 7/40\n","188/188 [==============================] - 7s 35ms/step - loss: 7118.1279 - mae: 76.3729 - val_loss: 7530.2002 - val_mae: 77.4621\n","Epoch 8/40\n","188/188 [==============================] - 7s 35ms/step - loss: 6686.8560 - mae: 73.5097 - val_loss: 7495.9536 - val_mae: 78.1597\n","Epoch 9/40\n","188/188 [==============================] - 7s 36ms/step - loss: 6200.9814 - mae: 70.4076 - val_loss: 3886.8198 - val_mae: 45.8549\n","Epoch 10/40\n","188/188 [==============================] - 8s 45ms/step - loss: 5727.1265 - mae: 67.1004 - val_loss: 5756.3701 - val_mae: 64.3673\n","Epoch 11/40\n","188/188 [==============================] - 7s 35ms/step - loss: 5092.4253 - mae: 62.0562 - val_loss: 4187.6733 - val_mae: 53.7899\n","Epoch 12/40\n","188/188 [==============================] - 7s 35ms/step - loss: 4540.5659 - mae: 56.8610 - val_loss: 3573.8652 - val_mae: 47.1469\n","Epoch 13/40\n","188/188 [==============================] - 7s 35ms/step - loss: 4038.5725 - mae: 51.8197 - val_loss: 3266.1243 - val_mae: 42.0104\n","Epoch 14/40\n","188/188 [==============================] - 7s 35ms/step - loss: 3623.0105 - mae: 46.1881 - val_loss: 3592.0530 - val_mae: 47.1885\n","Epoch 15/40\n","188/188 [==============================] - 7s 35ms/step - loss: 3269.7861 - mae: 41.4334 - val_loss: 2779.0735 - val_mae: 32.7860\n","Epoch 16/40\n","188/188 [==============================] - 7s 35ms/step - loss: 2962.8162 - mae: 36.7946 - val_loss: 2872.8506 - val_mae: 34.5825\n","Epoch 17/40\n","188/188 [==============================] - 7s 35ms/step - loss: 2949.3816 - mae: 34.0122 - val_loss: 2886.2209 - val_mae: 28.5780\n","Epoch 18/40\n","188/188 [==============================] - 7s 35ms/step - loss: 2759.7651 - mae: 31.3730 - val_loss: 2721.2617 - val_mae: 26.3187\n","Epoch 19/40\n","188/188 [==============================] - 7s 35ms/step - loss: 2733.2749 - mae: 29.4755 - val_loss: 2866.7620 - val_mae: 24.2110\n","Epoch 20/40\n","188/188 [==============================] - 7s 35ms/step - loss: 2791.2112 - mae: 29.4818 - val_loss: 2910.0933 - val_mae: 25.7985\n","Epoch 21/40\n","188/188 [==============================] - 7s 35ms/step - loss: 2751.5793 - mae: 29.3719 - val_loss: 2774.8030 - val_mae: 27.1696\n","Epoch 22/40\n","188/188 [==============================] - 7s 35ms/step - loss: 2668.5288 - mae: 28.2182 - val_loss: 2661.2969 - val_mae: 28.9694\n","Epoch 23/40\n","188/188 [==============================] - 8s 45ms/step - loss: 2718.1067 - mae: 27.8487 - val_loss: 2717.9023 - val_mae: 27.6481\n","Epoch 24/40\n","188/188 [==============================] - 6s 35ms/step - loss: 2621.6174 - mae: 27.7369 - val_loss: 2615.3254 - val_mae: 25.8299\n","Epoch 25/40\n","188/188 [==============================] - 6s 34ms/step - loss: 2619.4866 - mae: 27.6769 - val_loss: 3127.1575 - val_mae: 27.4457\n","Epoch 26/40\n","188/188 [==============================] - 7s 35ms/step - loss: 2683.6475 - mae: 28.3599 - val_loss: 2666.3416 - val_mae: 29.2065\n","Epoch 27/40\n","188/188 [==============================] - 7s 35ms/step - loss: 2631.6206 - mae: 27.4683 - val_loss: 2734.9973 - val_mae: 34.0809\n","Epoch 28/40\n","188/188 [==============================] - 7s 36ms/step - loss: 2675.2441 - mae: 28.3318 - val_loss: 2514.9238 - val_mae: 26.8542\n","Epoch 29/40\n","188/188 [==============================] - 7s 36ms/step - loss: 2637.1106 - mae: 27.4032 - val_loss: 2580.4939 - val_mae: 25.4019\n","Epoch 30/40\n","188/188 [==============================] - 7s 36ms/step - loss: 2613.8193 - mae: 27.8761 - val_loss: 2796.6775 - val_mae: 31.7953\n","Epoch 31/40\n","188/188 [==============================] - 7s 36ms/step - loss: 2649.4692 - mae: 27.7145 - val_loss: 2614.4060 - val_mae: 28.2313\n","Epoch 32/40\n","188/188 [==============================] - 7s 36ms/step - loss: 2650.2114 - mae: 28.3526 - val_loss: 2731.8469 - val_mae: 28.5687\n","Epoch 33/40\n","188/188 [==============================] - 7s 36ms/step - loss: 2676.3462 - mae: 28.1252 - val_loss: 2668.8616 - val_mae: 28.9341\n","Epoch 34/40\n","188/188 [==============================] - 7s 36ms/step - loss: 2563.1423 - mae: 27.8264 - val_loss: 2718.8391 - val_mae: 24.5812\n","Epoch 35/40\n","188/188 [==============================] - 7s 36ms/step - loss: 2602.1672 - mae: 28.0367 - val_loss: 3211.0420 - val_mae: 38.1315\n","Epoch 36/40\n","188/188 [==============================] - 9s 46ms/step - loss: 2557.0220 - mae: 27.5464 - val_loss: 2572.4233 - val_mae: 25.5033\n","Epoch 37/40\n","188/188 [==============================] - 7s 36ms/step - loss: 2561.2495 - mae: 27.2997 - val_loss: 2465.3647 - val_mae: 22.3741\n","Epoch 38/40\n","188/188 [==============================] - 7s 35ms/step - loss: 2551.4631 - mae: 27.5991 - val_loss: 2527.8052 - val_mae: 27.1477\n","Epoch 39/40\n","188/188 [==============================] - 7s 35ms/step - loss: 2553.8196 - mae: 27.0094 - val_loss: 2557.2307 - val_mae: 22.9443\n","Epoch 40/40\n","188/188 [==============================] - 7s 36ms/step - loss: 2548.7905 - mae: 27.3335 - val_loss: 2632.2952 - val_mae: 26.5181\n","73.04109365978191\n","1.5647142287057154\n","1.3070744717845753\n","start group0,This is the experiment num: 3\n","\n","---------------------------------------------- domain num 0 is running----------------------------------\n","start training\n","Epoch 1/40\n","188/188 [==============================] - 10s 46ms/step - loss: 10608.2910 - mae: 80.7962 - val_loss: 13157.6260 - val_mae: 73.7945\n","Epoch 2/40\n","188/188 [==============================] - 7s 36ms/step - loss: 8618.8262 - mae: 82.7600 - val_loss: 12203.5967 - val_mae: 79.5245\n","Epoch 3/40\n","188/188 [==============================] - 7s 36ms/step - loss: 8201.8330 - mae: 82.7793 - val_loss: 9301.3945 - val_mae: 80.7973\n","Epoch 4/40\n","188/188 [==============================] - 7s 36ms/step - loss: 7938.5312 - mae: 81.1519 - val_loss: 7642.9907 - val_mae: 77.1028\n","Epoch 5/40\n","188/188 [==============================] - 7s 36ms/step - loss: 7697.6201 - mae: 80.1287 - val_loss: 7735.4126 - val_mae: 79.3204\n","Epoch 6/40\n","188/188 [==============================] - 7s 36ms/step - loss: 7443.5220 - mae: 78.1932 - val_loss: 7855.8608 - val_mae: 78.4978\n","Epoch 7/40\n","188/188 [==============================] - 7s 36ms/step - loss: 7146.6123 - mae: 76.7136 - val_loss: 7100.4062 - val_mae: 75.2749\n","Epoch 8/40\n","188/188 [==============================] - 7s 36ms/step - loss: 6705.4478 - mae: 73.7490 - val_loss: 9260.3975 - val_mae: 84.0725\n","Epoch 9/40\n","188/188 [==============================] - 7s 36ms/step - loss: 6274.3354 - mae: 70.5059 - val_loss: 4996.7700 - val_mae: 59.8495\n","Epoch 10/40\n","188/188 [==============================] - 7s 36ms/step - loss: 5707.3188 - mae: 66.6624 - val_loss: 4599.2705 - val_mae: 56.1973\n","Epoch 11/40\n","188/188 [==============================] - 7s 36ms/step - loss: 5018.5654 - mae: 61.2146 - val_loss: 3723.6592 - val_mae: 47.6036\n","Epoch 12/40\n","188/188 [==============================] - 7s 36ms/step - loss: 4463.4722 - mae: 56.1436 - val_loss: 4063.0615 - val_mae: 50.0318\n","Epoch 13/40\n","188/188 [==============================] - 7s 36ms/step - loss: 4022.9932 - mae: 50.9740 - val_loss: 3640.6987 - val_mae: 46.2498\n","Epoch 14/40\n","188/188 [==============================] - 9s 46ms/step - loss: 3589.1511 - mae: 46.3843 - val_loss: 3208.0762 - val_mae: 33.8616\n","Epoch 15/40\n","188/188 [==============================] - 7s 36ms/step - loss: 3230.3684 - mae: 40.6950 - val_loss: 3134.5071 - val_mae: 38.2835\n","Epoch 16/40\n","188/188 [==============================] - 7s 36ms/step - loss: 2962.5496 - mae: 36.3580 - val_loss: 2817.4353 - val_mae: 31.5389\n","Epoch 17/40\n","188/188 [==============================] - 7s 36ms/step - loss: 2815.7620 - mae: 32.9139 - val_loss: 2765.5981 - val_mae: 33.6875\n","Epoch 18/40\n","188/188 [==============================] - 7s 36ms/step - loss: 2736.3162 - mae: 30.6264 - val_loss: 2817.0625 - val_mae: 33.5920\n","Epoch 19/40\n","188/188 [==============================] - 7s 36ms/step - loss: 2744.9165 - mae: 29.2702 - val_loss: 2729.1804 - val_mae: 28.3987\n","Epoch 20/40\n","188/188 [==============================] - 7s 36ms/step - loss: 2701.0825 - mae: 28.2913 - val_loss: 2973.2942 - val_mae: 29.4348\n","Epoch 21/40\n","188/188 [==============================] - 7s 37ms/step - loss: 2739.1169 - mae: 28.4937 - val_loss: 2652.9016 - val_mae: 26.0539\n","Epoch 22/40\n","188/188 [==============================] - 7s 37ms/step - loss: 2706.9253 - mae: 27.9606 - val_loss: 2986.2737 - val_mae: 38.2804\n","Epoch 23/40\n","188/188 [==============================] - 7s 37ms/step - loss: 2691.3367 - mae: 27.9971 - val_loss: 2757.8225 - val_mae: 26.9100\n","Epoch 24/40\n","188/188 [==============================] - 7s 37ms/step - loss: 2683.0852 - mae: 27.5382 - val_loss: 3046.2373 - val_mae: 28.7023\n","Epoch 25/40\n","188/188 [==============================] - 7s 37ms/step - loss: 2701.0085 - mae: 27.6533 - val_loss: 2596.7622 - val_mae: 30.0820\n","Epoch 26/40\n","188/188 [==============================] - 7s 39ms/step - loss: 2683.1960 - mae: 27.8110 - val_loss: 3131.2163 - val_mae: 26.2169\n","Epoch 27/40\n","188/188 [==============================] - 9s 45ms/step - loss: 2671.2292 - mae: 28.4617 - val_loss: 2637.1863 - val_mae: 29.1936\n","Epoch 28/40\n","188/188 [==============================] - 7s 38ms/step - loss: 2654.9915 - mae: 27.6538 - val_loss: 2891.6475 - val_mae: 32.5414\n","Epoch 29/40\n","188/188 [==============================] - 7s 38ms/step - loss: 2668.9377 - mae: 27.5872 - val_loss: 2625.5591 - val_mae: 28.9176\n","Epoch 30/40\n","188/188 [==============================] - 7s 38ms/step - loss: 2721.0735 - mae: 28.1533 - val_loss: 3405.5569 - val_mae: 36.9312\n","Epoch 31/40\n","188/188 [==============================] - 7s 37ms/step - loss: 2705.5962 - mae: 27.9926 - val_loss: 2638.8884 - val_mae: 28.7743\n","Epoch 32/40\n","188/188 [==============================] - 7s 36ms/step - loss: 2678.8416 - mae: 27.8995 - val_loss: 2696.2485 - val_mae: 28.5355\n","Epoch 33/40\n","188/188 [==============================] - 7s 36ms/step - loss: 2638.1321 - mae: 27.6905 - val_loss: 2713.8330 - val_mae: 32.8950\n","Epoch 34/40\n","188/188 [==============================] - 7s 36ms/step - loss: 2714.8662 - mae: 28.0301 - val_loss: 2866.9019 - val_mae: 31.6825\n","Epoch 35/40\n","188/188 [==============================] - 7s 36ms/step - loss: 2683.8860 - mae: 27.8177 - val_loss: 2652.8391 - val_mae: 25.5367\n","Epoch 36/40\n","188/188 [==============================] - 7s 36ms/step - loss: 2685.0459 - mae: 28.3194 - val_loss: 2854.5696 - val_mae: 33.0476\n","Epoch 37/40\n","188/188 [==============================] - 7s 37ms/step - loss: 2660.0981 - mae: 28.3319 - val_loss: 2729.8562 - val_mae: 23.8360\n","Epoch 38/40\n","188/188 [==============================] - 7s 36ms/step - loss: 2688.9873 - mae: 27.8322 - val_loss: 2619.4060 - val_mae: 27.3104\n","Epoch 39/40\n","188/188 [==============================] - 9s 46ms/step - loss: 2701.6108 - mae: 28.5770 - val_loss: 2699.5371 - val_mae: 25.6530\n","Epoch 40/40\n","188/188 [==============================] - 7s 36ms/step - loss: 2588.3713 - mae: 27.2701 - val_loss: 2858.5166 - val_mae: 37.6772\n","65.12858519045396\n","0.886055019892536\n","1.1780943959280519\n","start group0,This is the experiment num: 4\n","\n","---------------------------------------------- domain num 0 is running----------------------------------\n","start training\n","Epoch 1/40\n","188/188 [==============================] - 8s 38ms/step - loss: 10419.8369 - mae: 80.9069 - val_loss: 13324.0225 - val_mae: 75.8918\n","Epoch 2/40\n","188/188 [==============================] - 7s 36ms/step - loss: 8634.1035 - mae: 82.8341 - val_loss: 11463.1074 - val_mae: 78.8360\n","Epoch 3/40\n","188/188 [==============================] - 7s 37ms/step - loss: 8190.7241 - mae: 82.3795 - val_loss: 9015.5889 - val_mae: 77.6167\n","Epoch 4/40\n","188/188 [==============================] - 7s 37ms/step - loss: 7982.9424 - mae: 81.5271 - val_loss: 8097.8262 - val_mae: 79.0091\n","Epoch 5/40\n","188/188 [==============================] - 8s 41ms/step - loss: 7719.3008 - mae: 80.1553 - val_loss: 7047.0918 - val_mae: 74.5880\n","Epoch 6/40\n","188/188 [==============================] - 8s 42ms/step - loss: 7474.9736 - mae: 78.5250 - val_loss: 7669.3301 - val_mae: 78.6410\n","Epoch 7/40\n","188/188 [==============================] - 7s 37ms/step - loss: 7108.9272 - mae: 76.2565 - val_loss: 6641.4922 - val_mae: 71.6130\n","Epoch 8/40\n","188/188 [==============================] - 7s 37ms/step - loss: 6645.1509 - mae: 73.4344 - val_loss: 6547.0659 - val_mae: 71.2815\n","Epoch 9/40\n","188/188 [==============================] - 7s 37ms/step - loss: 6196.4331 - mae: 70.3925 - val_loss: 6623.3364 - val_mae: 72.5710\n","Epoch 10/40\n","188/188 [==============================] - 7s 36ms/step - loss: 5705.4951 - mae: 67.0912 - val_loss: 5080.9683 - val_mae: 59.0117\n","Epoch 11/40\n","188/188 [==============================] - 7s 36ms/step - loss: 5209.2451 - mae: 62.5807 - val_loss: 3254.1128 - val_mae: 37.2294\n","Epoch 12/40\n","188/188 [==============================] - 7s 36ms/step - loss: 4584.1592 - mae: 57.6434 - val_loss: 3457.7727 - val_mae: 43.3109\n","Epoch 13/40\n","188/188 [==============================] - 7s 36ms/step - loss: 4088.6096 - mae: 51.7460 - val_loss: 3098.1472 - val_mae: 39.5144\n","Epoch 14/40\n","188/188 [==============================] - 7s 36ms/step - loss: 3723.7859 - mae: 47.9403 - val_loss: 3004.0835 - val_mae: 36.3323\n","Epoch 15/40\n","188/188 [==============================] - 7s 36ms/step - loss: 3285.9102 - mae: 41.8200 - val_loss: 3094.2937 - val_mae: 38.2969\n","Epoch 16/40\n","188/188 [==============================] - 7s 36ms/step - loss: 3158.8862 - mae: 38.1542 - val_loss: 2840.3950 - val_mae: 33.5580\n","Epoch 17/40\n","188/188 [==============================] - 7s 36ms/step - loss: 2899.5742 - mae: 34.3413 - val_loss: 2892.3386 - val_mae: 35.7688\n","Epoch 18/40\n","188/188 [==============================] - 9s 46ms/step - loss: 2794.5200 - mae: 31.7326 - val_loss: 2739.8752 - val_mae: 28.6064\n","Epoch 19/40\n","188/188 [==============================] - 7s 36ms/step - loss: 2743.3049 - mae: 30.2330 - val_loss: 2833.9434 - val_mae: 24.6494\n","Epoch 20/40\n","188/188 [==============================] - 7s 37ms/step - loss: 2705.2891 - mae: 29.3551 - val_loss: 2898.0640 - val_mae: 25.9171\n","Epoch 21/40\n","188/188 [==============================] - 7s 37ms/step - loss: 2704.1179 - mae: 28.4594 - val_loss: 2723.7505 - val_mae: 25.9570\n","Epoch 22/40\n","188/188 [==============================] - 7s 37ms/step - loss: 2653.9080 - mae: 28.2479 - val_loss: 2886.2996 - val_mae: 31.0510\n","Epoch 23/40\n","188/188 [==============================] - 7s 37ms/step - loss: 2646.0715 - mae: 28.1525 - val_loss: 2623.9368 - val_mae: 24.4108\n","Epoch 24/40\n","188/188 [==============================] - 7s 37ms/step - loss: 2686.5044 - mae: 28.8698 - val_loss: 2522.1931 - val_mae: 25.2388\n","Epoch 25/40\n","188/188 [==============================] - 7s 37ms/step - loss: 2600.5239 - mae: 27.4664 - val_loss: 2567.2456 - val_mae: 30.7118\n","Epoch 26/40\n","188/188 [==============================] - 7s 37ms/step - loss: 2636.1404 - mae: 28.1664 - val_loss: 2703.7681 - val_mae: 24.2683\n","Epoch 27/40\n","188/188 [==============================] - 7s 37ms/step - loss: 2573.2205 - mae: 27.4294 - val_loss: 2637.0767 - val_mae: 22.6108\n","Epoch 28/40\n","188/188 [==============================] - 7s 37ms/step - loss: 2494.1270 - mae: 26.8645 - val_loss: 2645.9636 - val_mae: 32.4070\n","Epoch 29/40\n","188/188 [==============================] - 7s 37ms/step - loss: 2568.6223 - mae: 28.4089 - val_loss: 2517.7004 - val_mae: 26.2621\n","Epoch 30/40\n","188/188 [==============================] - 7s 39ms/step - loss: 2560.3101 - mae: 27.6675 - val_loss: 2475.1775 - val_mae: 23.8919\n","Epoch 31/40\n","188/188 [==============================] - 8s 44ms/step - loss: 2561.6396 - mae: 27.6827 - val_loss: 2685.9431 - val_mae: 26.9703\n","Epoch 32/40\n","188/188 [==============================] - 7s 37ms/step - loss: 2531.5522 - mae: 27.1724 - val_loss: 2511.0291 - val_mae: 23.3361\n","Epoch 33/40\n","188/188 [==============================] - 7s 37ms/step - loss: 2493.0801 - mae: 26.9388 - val_loss: 2480.0312 - val_mae: 23.7757\n","Epoch 34/40\n","188/188 [==============================] - 7s 36ms/step - loss: 2485.6997 - mae: 27.4654 - val_loss: 2452.4609 - val_mae: 22.7738\n","Epoch 35/40\n","188/188 [==============================] - 7s 37ms/step - loss: 2465.3794 - mae: 26.7033 - val_loss: 2490.6316 - val_mae: 21.7740\n","Epoch 36/40\n","188/188 [==============================] - 7s 37ms/step - loss: 2435.7969 - mae: 26.5025 - val_loss: 2486.3701 - val_mae: 22.3380\n","Epoch 37/40\n","188/188 [==============================] - 7s 36ms/step - loss: 2507.4717 - mae: 26.9029 - val_loss: 2931.1338 - val_mae: 30.7215\n","Epoch 38/40\n","188/188 [==============================] - 7s 36ms/step - loss: 2544.8022 - mae: 27.0105 - val_loss: 2575.7854 - val_mae: 25.8980\n","Epoch 39/40\n","188/188 [==============================] - 7s 36ms/step - loss: 2474.7207 - mae: 27.1631 - val_loss: 2630.8401 - val_mae: 27.3520\n","Epoch 40/40\n","188/188 [==============================] - 7s 36ms/step - loss: 2503.4314 - mae: 27.6237 - val_loss: 2641.4785 - val_mae: 26.1628\n","72.73398337160025\n","1.4867448595832846\n","1.2928678034148837\n","start group1,This is the experiment num: 0\n","\n","---------------------------------------------- domain num 0 is running----------------------------------\n","start training\n","Epoch 1/40\n","564/564 [==============================] - 21s 36ms/step - loss: 7062.9756 - mae: 65.9389 - val_loss: 6444.4722 - val_mae: 57.9322\n","Epoch 2/40\n","564/564 [==============================] - 20s 36ms/step - loss: 6267.0117 - mae: 63.8930 - val_loss: 5803.6328 - val_mae: 59.8168\n","Epoch 3/40\n","564/564 [==============================] - 20s 36ms/step - loss: 5377.3672 - mae: 58.3924 - val_loss: 5327.9487 - val_mae: 59.5616\n","Epoch 4/40\n","564/564 [==============================] - 22s 40ms/step - loss: 4456.3887 - mae: 51.2117 - val_loss: 5263.0503 - val_mae: 58.3564\n","Epoch 5/40\n","564/564 [==============================] - 21s 37ms/step - loss: 3930.9666 - mae: 45.2303 - val_loss: 5275.0366 - val_mae: 57.4581\n","Epoch 6/40\n","564/564 [==============================] - 21s 37ms/step - loss: 3773.8442 - mae: 42.7458 - val_loss: 5592.8613 - val_mae: 59.2729\n","Epoch 7/40\n","564/564 [==============================] - 21s 37ms/step - loss: 3765.7861 - mae: 42.6583 - val_loss: 5930.3008 - val_mae: 60.1061\n","Epoch 8/40\n","564/564 [==============================] - 23s 40ms/step - loss: 3737.2649 - mae: 42.4358 - val_loss: 5967.8516 - val_mae: 60.2431\n","Epoch 9/40\n","564/564 [==============================] - 21s 37ms/step - loss: 3739.8909 - mae: 42.5131 - val_loss: 5982.0801 - val_mae: 59.4274\n","Epoch 10/40\n","564/564 [==============================] - 21s 37ms/step - loss: 3736.5652 - mae: 42.4556 - val_loss: 5970.8823 - val_mae: 59.9224\n","Epoch 11/40\n","564/564 [==============================] - 21s 36ms/step - loss: 3703.0483 - mae: 42.1574 - val_loss: 5888.4287 - val_mae: 60.1203\n","Epoch 12/40\n","564/564 [==============================] - 22s 40ms/step - loss: 3709.7539 - mae: 42.1671 - val_loss: 6268.0171 - val_mae: 59.8523\n","Epoch 13/40\n","564/564 [==============================] - 20s 36ms/step - loss: 3695.1985 - mae: 42.0981 - val_loss: 6068.7646 - val_mae: 60.1237\n","Epoch 14/40\n","564/564 [==============================] - 20s 36ms/step - loss: 3706.5254 - mae: 42.1814 - val_loss: 5548.4199 - val_mae: 59.1665\n","Epoch 15/40\n","564/564 [==============================] - 20s 36ms/step - loss: 3686.5876 - mae: 41.9671 - val_loss: 5854.6577 - val_mae: 60.3469\n","Epoch 16/40\n","564/564 [==============================] - 20s 35ms/step - loss: 3683.2751 - mae: 41.9064 - val_loss: 5866.1831 - val_mae: 59.4808\n","Epoch 17/40\n","564/564 [==============================] - 22s 39ms/step - loss: 3679.0710 - mae: 41.9252 - val_loss: 5827.6562 - val_mae: 59.9035\n","Epoch 18/40\n","564/564 [==============================] - 20s 36ms/step - loss: 3651.0586 - mae: 41.6258 - val_loss: 6042.1450 - val_mae: 61.5125\n","Epoch 19/40\n","564/564 [==============================] - 20s 36ms/step - loss: 3677.9822 - mae: 41.7379 - val_loss: 6247.8682 - val_mae: 60.6666\n","Epoch 20/40\n","564/564 [==============================] - 20s 36ms/step - loss: 3677.7302 - mae: 41.9327 - val_loss: 5883.4204 - val_mae: 60.7966\n","Epoch 21/40\n","564/564 [==============================] - 22s 38ms/step - loss: 3677.3794 - mae: 41.9439 - val_loss: 5995.4141 - val_mae: 58.6976\n","Epoch 22/40\n","564/564 [==============================] - 20s 35ms/step - loss: 3647.3638 - mae: 41.6136 - val_loss: 5790.8828 - val_mae: 60.1973\n","Epoch 23/40\n","564/564 [==============================] - 20s 36ms/step - loss: 3638.2561 - mae: 41.4662 - val_loss: 5882.3867 - val_mae: 59.9976\n","Epoch 24/40\n","564/564 [==============================] - 20s 35ms/step - loss: 3632.0601 - mae: 41.5450 - val_loss: 5942.1138 - val_mae: 60.4953\n","Epoch 25/40\n","564/564 [==============================] - 21s 38ms/step - loss: 3616.7019 - mae: 41.3273 - val_loss: 5939.8555 - val_mae: 60.7045\n","Epoch 26/40\n","564/564 [==============================] - 20s 35ms/step - loss: 3630.2937 - mae: 41.4938 - val_loss: 5774.6968 - val_mae: 60.1454\n","Epoch 27/40\n","564/564 [==============================] - 20s 35ms/step - loss: 3616.0266 - mae: 41.3693 - val_loss: 5793.6387 - val_mae: 58.1532\n","Epoch 28/40\n","564/564 [==============================] - 20s 35ms/step - loss: 3619.7876 - mae: 41.4932 - val_loss: 5653.6953 - val_mae: 59.1235\n","Epoch 29/40\n","564/564 [==============================] - 20s 35ms/step - loss: 3619.9756 - mae: 41.4564 - val_loss: 6097.0073 - val_mae: 59.5724\n","Epoch 30/40\n","564/564 [==============================] - 21s 38ms/step - loss: 3627.8171 - mae: 41.5132 - val_loss: 5821.7378 - val_mae: 60.3483\n","Epoch 31/40\n","564/564 [==============================] - 20s 35ms/step - loss: 3589.7766 - mae: 41.2040 - val_loss: 6287.3823 - val_mae: 60.4707\n","Epoch 32/40\n","564/564 [==============================] - 20s 35ms/step - loss: 3577.2468 - mae: 41.1152 - val_loss: 6058.0337 - val_mae: 60.4499\n","Epoch 33/40\n","564/564 [==============================] - 19s 35ms/step - loss: 3606.1399 - mae: 41.2873 - val_loss: 5677.6211 - val_mae: 60.0865\n","Epoch 34/40\n","564/564 [==============================] - 21s 38ms/step - loss: 3573.2063 - mae: 41.0034 - val_loss: 5998.6870 - val_mae: 59.4596\n","Epoch 35/40\n","564/564 [==============================] - 20s 35ms/step - loss: 3581.6382 - mae: 41.0932 - val_loss: 6200.6401 - val_mae: 61.9616\n","Epoch 36/40\n","564/564 [==============================] - 19s 34ms/step - loss: 3595.3660 - mae: 41.2923 - val_loss: 6112.0615 - val_mae: 61.7906\n","Epoch 37/40\n","564/564 [==============================] - 20s 35ms/step - loss: 3565.6040 - mae: 41.0297 - val_loss: 6084.6870 - val_mae: 61.0958\n","Epoch 38/40\n","564/564 [==============================] - 22s 38ms/step - loss: 3578.5376 - mae: 41.1123 - val_loss: 5925.3062 - val_mae: 59.8174\n","Epoch 39/40\n","564/564 [==============================] - 20s 35ms/step - loss: 3564.8518 - mae: 40.9034 - val_loss: 5579.8403 - val_mae: 58.5154\n","Epoch 40/40\n","564/564 [==============================] - 20s 35ms/step - loss: 3544.9719 - mae: 40.8464 - val_loss: 6268.9790 - val_mae: 61.9612\n","57.076547042983826\n","1.2384889146029106\n","1.0802931752289395\n","start group1,This is the experiment num: 1\n","\n","---------------------------------------------- domain num 0 is running----------------------------------\n","start training\n","Epoch 1/40\n","564/564 [==============================] - 23s 39ms/step - loss: 7123.8618 - mae: 65.2891 - val_loss: 6175.7104 - val_mae: 58.6715\n","Epoch 2/40\n","564/564 [==============================] - 20s 35ms/step - loss: 6324.6172 - mae: 64.3794 - val_loss: 5700.7153 - val_mae: 60.0333\n","Epoch 3/40\n","564/564 [==============================] - 20s 35ms/step - loss: 5380.1372 - mae: 58.4594 - val_loss: 5107.3530 - val_mae: 58.3012\n","Epoch 4/40\n","564/564 [==============================] - 20s 36ms/step - loss: 4455.6763 - mae: 51.1632 - val_loss: 5351.8604 - val_mae: 59.7115\n","Epoch 5/40\n","564/564 [==============================] - 22s 39ms/step - loss: 3926.9434 - mae: 45.3084 - val_loss: 5285.3145 - val_mae: 57.9881\n","Epoch 6/40\n","564/564 [==============================] - 20s 36ms/step - loss: 3779.9744 - mae: 43.1250 - val_loss: 5659.5210 - val_mae: 57.3246\n","Epoch 7/40\n","564/564 [==============================] - 20s 35ms/step - loss: 3727.9041 - mae: 42.5814 - val_loss: 6002.9736 - val_mae: 59.9404\n","Epoch 8/40\n","564/564 [==============================] - 20s 36ms/step - loss: 3721.8167 - mae: 42.4036 - val_loss: 6023.1924 - val_mae: 60.1133\n","Epoch 9/40\n","564/564 [==============================] - 22s 39ms/step - loss: 3736.2832 - mae: 42.3992 - val_loss: 6293.6475 - val_mae: 61.2812\n","Epoch 10/40\n","564/564 [==============================] - 20s 36ms/step - loss: 3725.3811 - mae: 42.4759 - val_loss: 6140.0732 - val_mae: 60.6412\n","Epoch 11/40\n","564/564 [==============================] - 20s 36ms/step - loss: 3725.7065 - mae: 42.3885 - val_loss: 5575.7075 - val_mae: 58.3335\n","Epoch 12/40\n","564/564 [==============================] - 21s 36ms/step - loss: 3689.1101 - mae: 42.0688 - val_loss: 5847.9355 - val_mae: 60.0220\n","Epoch 13/40\n","564/564 [==============================] - 21s 37ms/step - loss: 3705.6155 - mae: 42.2076 - val_loss: 5914.6338 - val_mae: 58.3277\n","Epoch 14/40\n","564/564 [==============================] - 23s 40ms/step - loss: 3686.9219 - mae: 42.1364 - val_loss: 5995.2041 - val_mae: 60.0383\n","Epoch 15/40\n","564/564 [==============================] - 21s 37ms/step - loss: 3685.8110 - mae: 42.1907 - val_loss: 6104.0303 - val_mae: 59.7722\n","Epoch 16/40\n","564/564 [==============================] - 21s 37ms/step - loss: 3685.0344 - mae: 42.0697 - val_loss: 5831.5654 - val_mae: 58.5194\n","Epoch 17/40\n","564/564 [==============================] - 21s 37ms/step - loss: 3682.8408 - mae: 42.1465 - val_loss: 5705.3999 - val_mae: 58.9193\n","Epoch 18/40\n","564/564 [==============================] - 23s 40ms/step - loss: 3660.9680 - mae: 41.8982 - val_loss: 5886.6655 - val_mae: 60.5766\n","Epoch 19/40\n","564/564 [==============================] - 21s 36ms/step - loss: 3659.3901 - mae: 41.8853 - val_loss: 5765.3223 - val_mae: 59.2989\n","Epoch 20/40\n","564/564 [==============================] - 21s 37ms/step - loss: 3647.9082 - mae: 42.0298 - val_loss: 6022.0889 - val_mae: 60.9861\n","Epoch 21/40\n","564/564 [==============================] - 21s 37ms/step - loss: 3646.7263 - mae: 41.8602 - val_loss: 5768.2466 - val_mae: 58.8952\n","Epoch 22/40\n","564/564 [==============================] - 23s 40ms/step - loss: 3639.2388 - mae: 41.5632 - val_loss: 5865.3540 - val_mae: 61.4737\n","Epoch 23/40\n","564/564 [==============================] - 21s 37ms/step - loss: 3645.5195 - mae: 41.7643 - val_loss: 6107.4946 - val_mae: 61.6375\n","Epoch 24/40\n","564/564 [==============================] - 20s 36ms/step - loss: 3628.7412 - mae: 41.5251 - val_loss: 5966.2236 - val_mae: 59.8487\n","Epoch 25/40\n","564/564 [==============================] - 20s 36ms/step - loss: 3637.0503 - mae: 41.5485 - val_loss: 6286.8198 - val_mae: 60.5861\n","Epoch 26/40\n","564/564 [==============================] - 21s 36ms/step - loss: 3609.8201 - mae: 41.3761 - val_loss: 6052.9741 - val_mae: 61.0185\n","Epoch 27/40\n","564/564 [==============================] - 23s 40ms/step - loss: 3601.9746 - mae: 41.3305 - val_loss: 6024.3950 - val_mae: 60.6759\n","Epoch 28/40\n","564/564 [==============================] - 21s 37ms/step - loss: 3607.9248 - mae: 41.3521 - val_loss: 5631.7588 - val_mae: 60.0088\n","Epoch 29/40\n","564/564 [==============================] - 21s 37ms/step - loss: 3585.3352 - mae: 41.1723 - val_loss: 5897.6226 - val_mae: 59.4416\n","Epoch 30/40\n","564/564 [==============================] - 21s 37ms/step - loss: 3579.3276 - mae: 41.1733 - val_loss: 5891.3184 - val_mae: 60.0927\n","Epoch 31/40\n","564/564 [==============================] - 23s 40ms/step - loss: 3581.1187 - mae: 41.1889 - val_loss: 5866.9814 - val_mae: 60.9174\n","Epoch 32/40\n","564/564 [==============================] - 22s 38ms/step - loss: 3570.1294 - mae: 40.9623 - val_loss: 5951.1948 - val_mae: 61.0046\n","Epoch 33/40\n","564/564 [==============================] - 21s 38ms/step - loss: 3557.1738 - mae: 40.9244 - val_loss: 5850.0645 - val_mae: 60.1296\n","Epoch 34/40\n","564/564 [==============================] - 21s 37ms/step - loss: 3563.2935 - mae: 40.9155 - val_loss: 5769.3550 - val_mae: 58.5230\n","Epoch 35/40\n","564/564 [==============================] - 22s 39ms/step - loss: 3550.8501 - mae: 40.9056 - val_loss: 5784.0693 - val_mae: 59.5608\n","Epoch 36/40\n","564/564 [==============================] - 22s 38ms/step - loss: 3547.4392 - mae: 40.8540 - val_loss: 5679.9277 - val_mae: 59.7910\n","Epoch 37/40\n","564/564 [==============================] - 21s 37ms/step - loss: 3545.9553 - mae: 40.7881 - val_loss: 5830.9243 - val_mae: 60.2701\n","Epoch 38/40\n","564/564 [==============================] - 21s 37ms/step - loss: 3545.3630 - mae: 40.8158 - val_loss: 5745.8271 - val_mae: 60.0803\n","Epoch 39/40\n","564/564 [==============================] - 21s 37ms/step - loss: 3549.8706 - mae: 40.8756 - val_loss: 6071.7686 - val_mae: 59.5113\n","Epoch 40/40\n","564/564 [==============================] - 23s 40ms/step - loss: 3545.2480 - mae: 40.8800 - val_loss: 5359.0171 - val_mae: 59.0532\n","50.048780430847415\n","0.9217380796979106\n","0.9529164622903303\n","start group1,This is the experiment num: 2\n","\n","---------------------------------------------- domain num 0 is running----------------------------------\n","start training\n","Epoch 1/40\n","564/564 [==============================] - 22s 37ms/step - loss: 7035.0054 - mae: 65.7036 - val_loss: 6434.9937 - val_mae: 58.6204\n","Epoch 2/40\n","564/564 [==============================] - 21s 37ms/step - loss: 6187.5806 - mae: 63.5765 - val_loss: 5966.4385 - val_mae: 59.5714\n","Epoch 3/40\n","564/564 [==============================] - 23s 40ms/step - loss: 5225.7036 - mae: 57.4066 - val_loss: 5149.7612 - val_mae: 58.5729\n","Epoch 4/40\n","564/564 [==============================] - 21s 37ms/step - loss: 4309.6465 - mae: 49.6549 - val_loss: 5178.7002 - val_mae: 59.3829\n","Epoch 5/40\n","564/564 [==============================] - 21s 37ms/step - loss: 3857.3757 - mae: 44.4172 - val_loss: 5969.4360 - val_mae: 60.0392\n","Epoch 6/40\n","564/564 [==============================] - 21s 36ms/step - loss: 3756.3152 - mae: 42.6355 - val_loss: 6053.2642 - val_mae: 60.0504\n","Epoch 7/40\n","564/564 [==============================] - 21s 37ms/step - loss: 3727.3030 - mae: 42.3613 - val_loss: 5704.0342 - val_mae: 58.8685\n","Epoch 8/40\n","564/564 [==============================] - 23s 40ms/step - loss: 3727.4072 - mae: 42.3162 - val_loss: 5973.0356 - val_mae: 60.3828\n","Epoch 9/40\n","564/564 [==============================] - 21s 37ms/step - loss: 3728.3987 - mae: 42.1248 - val_loss: 6217.8306 - val_mae: 60.1695\n","Epoch 10/40\n","564/564 [==============================] - 21s 37ms/step - loss: 3739.3447 - mae: 42.3135 - val_loss: 5609.8203 - val_mae: 59.1735\n","Epoch 11/40\n","564/564 [==============================] - 21s 37ms/step - loss: 3721.4561 - mae: 42.1232 - val_loss: 5906.6553 - val_mae: 59.2687\n","Epoch 12/40\n","564/564 [==============================] - 23s 40ms/step - loss: 3703.9922 - mae: 41.9926 - val_loss: 5772.8784 - val_mae: 59.4205\n","Epoch 13/40\n","564/564 [==============================] - 21s 37ms/step - loss: 3712.3015 - mae: 42.1876 - val_loss: 6110.9634 - val_mae: 59.2530\n","Epoch 14/40\n","564/564 [==============================] - 21s 37ms/step - loss: 3708.2295 - mae: 42.0471 - val_loss: 5420.7388 - val_mae: 58.1703\n","Epoch 15/40\n","564/564 [==============================] - 20s 36ms/step - loss: 3682.0598 - mae: 41.8891 - val_loss: 6001.8242 - val_mae: 59.9648\n","Epoch 16/40\n","564/564 [==============================] - 23s 40ms/step - loss: 3671.8350 - mae: 41.7674 - val_loss: 5920.9653 - val_mae: 60.5801\n","Epoch 17/40\n","564/564 [==============================] - 21s 38ms/step - loss: 3692.2361 - mae: 42.0329 - val_loss: 5830.4722 - val_mae: 59.3056\n","Epoch 18/40\n","564/564 [==============================] - 21s 37ms/step - loss: 3671.3613 - mae: 41.7631 - val_loss: 5848.8291 - val_mae: 60.2709\n","Epoch 19/40\n","564/564 [==============================] - 21s 37ms/step - loss: 3671.0476 - mae: 41.8199 - val_loss: 6008.2349 - val_mae: 60.0020\n","Epoch 20/40\n","564/564 [==============================] - 21s 36ms/step - loss: 3643.1377 - mae: 41.5555 - val_loss: 6035.7114 - val_mae: 60.2988\n","Epoch 21/40\n","564/564 [==============================] - 23s 40ms/step - loss: 3648.0234 - mae: 41.7029 - val_loss: 5659.0898 - val_mae: 58.6569\n","Epoch 22/40\n","564/564 [==============================] - 21s 37ms/step - loss: 3650.4214 - mae: 41.6319 - val_loss: 5869.2520 - val_mae: 58.7075\n","Epoch 23/40\n","564/564 [==============================] - 20s 36ms/step - loss: 3639.3992 - mae: 41.4387 - val_loss: 5792.6250 - val_mae: 59.5329\n","Epoch 24/40\n","564/564 [==============================] - 21s 37ms/step - loss: 3632.6365 - mae: 41.4775 - val_loss: 6226.9365 - val_mae: 59.8814\n","Epoch 25/40\n","564/564 [==============================] - 22s 40ms/step - loss: 3651.8103 - mae: 41.7316 - val_loss: 6019.0400 - val_mae: 59.1891\n","Epoch 26/40\n","564/564 [==============================] - 20s 36ms/step - loss: 3623.6438 - mae: 41.3791 - val_loss: 6191.2607 - val_mae: 60.8681\n","Epoch 27/40\n","564/564 [==============================] - 21s 37ms/step - loss: 3614.5486 - mae: 41.3549 - val_loss: 5778.5352 - val_mae: 59.9361\n","Epoch 28/40\n","564/564 [==============================] - 21s 37ms/step - loss: 3613.2312 - mae: 41.2638 - val_loss: 6043.5854 - val_mae: 60.7783\n","Epoch 29/40\n","564/564 [==============================] - 21s 38ms/step - loss: 3612.0237 - mae: 41.1817 - val_loss: 6225.5947 - val_mae: 60.3032\n","Epoch 30/40\n","564/564 [==============================] - 23s 41ms/step - loss: 3607.1489 - mae: 41.2021 - val_loss: 5869.2686 - val_mae: 60.2618\n","Epoch 31/40\n","564/564 [==============================] - 21s 37ms/step - loss: 3575.3948 - mae: 41.1024 - val_loss: 5919.0571 - val_mae: 60.5091\n","Epoch 32/40\n","564/564 [==============================] - 21s 37ms/step - loss: 3604.5942 - mae: 41.2404 - val_loss: 6411.3638 - val_mae: 62.3812\n","Epoch 33/40\n","564/564 [==============================] - 21s 37ms/step - loss: 3570.0308 - mae: 40.9637 - val_loss: 5895.6177 - val_mae: 59.7965\n","Epoch 34/40\n","564/564 [==============================] - 23s 40ms/step - loss: 3571.5137 - mae: 40.9723 - val_loss: 5768.1729 - val_mae: 60.6573\n","Epoch 35/40\n","564/564 [==============================] - 21s 37ms/step - loss: 3577.2505 - mae: 41.1048 - val_loss: 5556.7437 - val_mae: 60.2103\n","Epoch 36/40\n","564/564 [==============================] - 21s 37ms/step - loss: 3572.0144 - mae: 41.1812 - val_loss: 6409.7803 - val_mae: 60.7264\n","Epoch 37/40\n","564/564 [==============================] - 21s 37ms/step - loss: 3582.5513 - mae: 40.9854 - val_loss: 5963.3892 - val_mae: 60.7900\n","Epoch 38/40\n","564/564 [==============================] - 21s 37ms/step - loss: 3558.9124 - mae: 40.9094 - val_loss: 5885.2827 - val_mae: 61.1334\n","Epoch 39/40\n","564/564 [==============================] - 23s 40ms/step - loss: 3581.2334 - mae: 41.1129 - val_loss: 5833.3613 - val_mae: 57.7951\n","Epoch 40/40\n","564/564 [==============================] - 21s 37ms/step - loss: 3562.5840 - mae: 40.8348 - val_loss: 6030.5376 - val_mae: 60.8151\n","54.256864198197064\n","1.1469507436934303\n","1.0377613964514518\n","start group1,This is the experiment num: 3\n","\n","---------------------------------------------- domain num 0 is running----------------------------------\n","start training\n","Epoch 1/40\n","564/564 [==============================] - 22s 36ms/step - loss: 7076.8477 - mae: 65.6211 - val_loss: 6997.6895 - val_mae: 58.9411\n","Epoch 2/40\n","564/564 [==============================] - 21s 36ms/step - loss: 6230.2847 - mae: 63.7610 - val_loss: 5750.1177 - val_mae: 60.2799\n","Epoch 3/40\n","564/564 [==============================] - 22s 40ms/step - loss: 5254.3398 - mae: 57.6678 - val_loss: 5250.3901 - val_mae: 59.5050\n","Epoch 4/40\n","564/564 [==============================] - 21s 37ms/step - loss: 4339.8779 - mae: 50.1255 - val_loss: 5755.2886 - val_mae: 59.8228\n","Epoch 5/40\n","564/564 [==============================] - 21s 37ms/step - loss: 3869.3284 - mae: 44.4720 - val_loss: 5255.7632 - val_mae: 58.7798\n","Epoch 6/40\n","564/564 [==============================] - 21s 37ms/step - loss: 3754.1279 - mae: 42.5731 - val_loss: 6144.0659 - val_mae: 61.9420\n","Epoch 7/40\n","564/564 [==============================] - 21s 37ms/step - loss: 3730.5483 - mae: 42.3576 - val_loss: 5736.0757 - val_mae: 58.9978\n","Epoch 8/40\n","564/564 [==============================] - 22s 40ms/step - loss: 3734.1550 - mae: 42.3091 - val_loss: 5587.4946 - val_mae: 58.7613\n","Epoch 9/40\n","564/564 [==============================] - 20s 36ms/step - loss: 3740.2441 - mae: 42.3415 - val_loss: 6345.1992 - val_mae: 60.8944\n","Epoch 10/40\n","564/564 [==============================] - 20s 36ms/step - loss: 3715.0095 - mae: 42.1225 - val_loss: 6330.0181 - val_mae: 61.1619\n","Epoch 11/40\n","564/564 [==============================] - 20s 36ms/step - loss: 3721.8008 - mae: 42.1484 - val_loss: 6280.2017 - val_mae: 60.7780\n","Epoch 12/40\n","564/564 [==============================] - 23s 41ms/step - loss: 3711.8667 - mae: 42.0098 - val_loss: 6190.9189 - val_mae: 61.2378\n","Epoch 13/40\n","564/564 [==============================] - 21s 37ms/step - loss: 3693.7998 - mae: 42.1386 - val_loss: 6074.8032 - val_mae: 59.9027\n","Epoch 14/40\n","564/564 [==============================] - 21s 37ms/step - loss: 3695.3892 - mae: 42.0879 - val_loss: 5834.9482 - val_mae: 58.6238\n","Epoch 15/40\n","564/564 [==============================] - 21s 37ms/step - loss: 3669.6760 - mae: 41.7092 - val_loss: 6056.2085 - val_mae: 60.3806\n","Epoch 16/40\n","564/564 [==============================] - 21s 37ms/step - loss: 3673.9475 - mae: 41.9186 - val_loss: 5858.9487 - val_mae: 59.2278\n","Epoch 17/40\n","564/564 [==============================] - 22s 40ms/step - loss: 3677.0249 - mae: 41.8080 - val_loss: 5909.6904 - val_mae: 58.7385\n","Epoch 18/40\n","564/564 [==============================] - 21s 36ms/step - loss: 3648.4104 - mae: 41.5394 - val_loss: 6355.7891 - val_mae: 60.4075\n","Epoch 19/40\n","564/564 [==============================] - 21s 36ms/step - loss: 3656.8628 - mae: 41.6915 - val_loss: 5719.8350 - val_mae: 57.9395\n","Epoch 20/40\n","564/564 [==============================] - 20s 36ms/step - loss: 3640.7595 - mae: 41.6080 - val_loss: 6043.7734 - val_mae: 60.5495\n","Epoch 21/40\n","564/564 [==============================] - 22s 39ms/step - loss: 3647.1641 - mae: 41.5345 - val_loss: 6005.1172 - val_mae: 59.5110\n","Epoch 22/40\n","564/564 [==============================] - 20s 36ms/step - loss: 3638.0139 - mae: 41.5634 - val_loss: 5768.4834 - val_mae: 59.0653\n","Epoch 23/40\n","564/564 [==============================] - 20s 36ms/step - loss: 3650.4326 - mae: 41.6126 - val_loss: 5722.4771 - val_mae: 59.4645\n","Epoch 24/40\n","564/564 [==============================] - 20s 36ms/step - loss: 3623.8970 - mae: 41.3801 - val_loss: 5805.1250 - val_mae: 60.0577\n","Epoch 25/40\n","564/564 [==============================] - 21s 38ms/step - loss: 3614.0793 - mae: 41.3361 - val_loss: 6074.2783 - val_mae: 60.2265\n","Epoch 26/40\n","564/564 [==============================] - 21s 37ms/step - loss: 3618.8350 - mae: 41.4360 - val_loss: 6128.4629 - val_mae: 60.9037\n","Epoch 27/40\n","564/564 [==============================] - 20s 36ms/step - loss: 3626.1487 - mae: 41.4108 - val_loss: 6131.6729 - val_mae: 61.6668\n","Epoch 28/40\n","564/564 [==============================] - 20s 36ms/step - loss: 3620.6384 - mae: 41.3350 - val_loss: 5923.2163 - val_mae: 59.8599\n","Epoch 29/40\n","564/564 [==============================] - 20s 36ms/step - loss: 3609.0276 - mae: 41.2837 - val_loss: 5872.4902 - val_mae: 60.3111\n","Epoch 30/40\n","564/564 [==============================] - 22s 39ms/step - loss: 3606.2439 - mae: 41.5003 - val_loss: 6508.9839 - val_mae: 61.8973\n","Epoch 31/40\n","564/564 [==============================] - 20s 36ms/step - loss: 3594.2754 - mae: 41.2349 - val_loss: 6285.4434 - val_mae: 61.1816\n","Epoch 32/40\n","564/564 [==============================] - 21s 37ms/step - loss: 3598.5896 - mae: 41.1655 - val_loss: 6115.9209 - val_mae: 60.5603\n","Epoch 33/40\n","564/564 [==============================] - 21s 37ms/step - loss: 3592.8704 - mae: 41.2477 - val_loss: 5964.5054 - val_mae: 59.7606\n","Epoch 34/40\n","564/564 [==============================] - 22s 38ms/step - loss: 3594.2188 - mae: 41.2678 - val_loss: 6057.1670 - val_mae: 61.5780\n","Epoch 35/40\n","564/564 [==============================] - 21s 38ms/step - loss: 3569.5469 - mae: 40.9909 - val_loss: 5945.4790 - val_mae: 60.6509\n","Epoch 36/40\n","564/564 [==============================] - 21s 36ms/step - loss: 3573.9353 - mae: 41.0122 - val_loss: 6053.0269 - val_mae: 60.1362\n","Epoch 37/40\n","564/564 [==============================] - 20s 36ms/step - loss: 3568.4917 - mae: 40.9554 - val_loss: 5961.7070 - val_mae: 59.6523\n","Epoch 38/40\n","564/564 [==============================] - 21s 36ms/step - loss: 3567.9412 - mae: 40.8930 - val_loss: 6023.5542 - val_mae: 60.8840\n","Epoch 39/40\n","564/564 [==============================] - 22s 40ms/step - loss: 3572.0327 - mae: 41.0183 - val_loss: 5934.7700 - val_mae: 60.4057\n","Epoch 40/40\n","564/564 [==============================] - 20s 36ms/step - loss: 3557.5056 - mae: 40.7482 - val_loss: 6256.3374 - val_mae: 61.4859\n","53.9229716837168\n","1.148933514383838\n","1.0327164977360344\n","start group1,This is the experiment num: 4\n","\n","---------------------------------------------- domain num 0 is running----------------------------------\n","start training\n","Epoch 1/40\n","564/564 [==============================] - 22s 37ms/step - loss: 7069.2383 - mae: 65.7936 - val_loss: 6339.7944 - val_mae: 58.6939\n","Epoch 2/40\n","564/564 [==============================] - 22s 39ms/step - loss: 6296.8623 - mae: 64.1490 - val_loss: 5596.8706 - val_mae: 59.3019\n","Epoch 3/40\n","564/564 [==============================] - 20s 36ms/step - loss: 5355.8135 - mae: 58.6029 - val_loss: 5493.0356 - val_mae: 59.7878\n","Epoch 4/40\n","564/564 [==============================] - 20s 36ms/step - loss: 4435.4434 - mae: 50.9930 - val_loss: 5971.4258 - val_mae: 60.6964\n","Epoch 5/40\n","564/564 [==============================] - 20s 36ms/step - loss: 3916.0364 - mae: 45.0157 - val_loss: 5481.1997 - val_mae: 58.9246\n","Epoch 6/40\n","564/564 [==============================] - 21s 37ms/step - loss: 3747.3896 - mae: 42.6812 - val_loss: 5797.7744 - val_mae: 59.0646\n","Epoch 7/40\n","564/564 [==============================] - 22s 40ms/step - loss: 3729.8140 - mae: 42.3058 - val_loss: 6166.2485 - val_mae: 61.2626\n","Epoch 8/40\n","564/564 [==============================] - 21s 37ms/step - loss: 3712.4282 - mae: 42.1035 - val_loss: 6222.9438 - val_mae: 60.6349\n","Epoch 9/40\n","564/564 [==============================] - 20s 36ms/step - loss: 3736.7014 - mae: 42.3104 - val_loss: 6020.1196 - val_mae: 59.5491\n","Epoch 10/40\n","564/564 [==============================] - 20s 36ms/step - loss: 3725.3030 - mae: 42.2043 - val_loss: 6775.0308 - val_mae: 61.5549\n","Epoch 11/40\n","564/564 [==============================] - 22s 39ms/step - loss: 3707.0317 - mae: 41.9725 - val_loss: 5871.8350 - val_mae: 59.1865\n","Epoch 12/40\n","564/564 [==============================] - 21s 37ms/step - loss: 3728.1475 - mae: 42.2479 - val_loss: 5753.8047 - val_mae: 58.7399\n","Epoch 13/40\n","564/564 [==============================] - 20s 36ms/step - loss: 3692.7864 - mae: 41.8706 - val_loss: 6373.4414 - val_mae: 60.6457\n","Epoch 14/40\n","564/564 [==============================] - 20s 36ms/step - loss: 3694.9697 - mae: 41.9621 - val_loss: 6018.3745 - val_mae: 59.6419\n","Epoch 15/40\n","564/564 [==============================] - 21s 37ms/step - loss: 3683.5679 - mae: 41.7885 - val_loss: 5688.0972 - val_mae: 58.2119\n","Epoch 16/40\n","564/564 [==============================] - 22s 40ms/step - loss: 3667.3225 - mae: 41.7642 - val_loss: 6102.9897 - val_mae: 60.0825\n","Epoch 17/40\n","564/564 [==============================] - 20s 36ms/step - loss: 3671.8325 - mae: 41.8728 - val_loss: 6343.1304 - val_mae: 61.5945\n","Epoch 18/40\n","564/564 [==============================] - 20s 36ms/step - loss: 3669.6858 - mae: 41.7809 - val_loss: 6257.0308 - val_mae: 59.9781\n","Epoch 19/40\n","564/564 [==============================] - 20s 36ms/step - loss: 3662.3933 - mae: 41.6423 - val_loss: 6006.1318 - val_mae: 61.0144\n","Epoch 20/40\n","564/564 [==============================] - 22s 39ms/step - loss: 3674.4741 - mae: 41.9411 - val_loss: 5937.6040 - val_mae: 60.4734\n","Epoch 21/40\n","564/564 [==============================] - 20s 36ms/step - loss: 3651.7749 - mae: 41.8092 - val_loss: 5400.5352 - val_mae: 56.1660\n","Epoch 22/40\n","564/564 [==============================] - 20s 36ms/step - loss: 3654.2700 - mae: 41.7310 - val_loss: 5791.3271 - val_mae: 60.4583\n","Epoch 23/40\n","564/564 [==============================] - 20s 36ms/step - loss: 3654.9119 - mae: 41.6376 - val_loss: 5596.7485 - val_mae: 57.4627\n","Epoch 24/40\n","564/564 [==============================] - 21s 36ms/step - loss: 3634.0066 - mae: 41.5094 - val_loss: 6062.7998 - val_mae: 61.3503\n","Epoch 25/40\n","564/564 [==============================] - 23s 40ms/step - loss: 3632.1284 - mae: 41.5990 - val_loss: 5847.9844 - val_mae: 59.4161\n","Epoch 26/40\n","564/564 [==============================] - 20s 36ms/step - loss: 3626.2439 - mae: 41.3799 - val_loss: 5678.7383 - val_mae: 58.4573\n","Epoch 27/40\n","564/564 [==============================] - 20s 36ms/step - loss: 3612.4250 - mae: 41.3804 - val_loss: 5683.0552 - val_mae: 59.5142\n","Epoch 28/40\n","564/564 [==============================] - 20s 36ms/step - loss: 3610.0479 - mae: 41.4210 - val_loss: 5664.3687 - val_mae: 59.2856\n","Epoch 29/40\n","564/564 [==============================] - 20s 36ms/step - loss: 3622.9060 - mae: 41.3716 - val_loss: 6174.6147 - val_mae: 62.1716\n","Epoch 30/40\n","564/564 [==============================] - 22s 39ms/step - loss: 3616.6116 - mae: 41.4518 - val_loss: 6062.0132 - val_mae: 59.6952\n","Epoch 31/40\n","564/564 [==============================] - 20s 36ms/step - loss: 3616.0894 - mae: 41.3684 - val_loss: 5792.9497 - val_mae: 59.8608\n","Epoch 32/40\n","564/564 [==============================] - 20s 36ms/step - loss: 3591.5901 - mae: 41.1545 - val_loss: 6156.3867 - val_mae: 60.4826\n","Epoch 33/40\n","564/564 [==============================] - 20s 36ms/step - loss: 3583.4045 - mae: 41.0427 - val_loss: 5538.1089 - val_mae: 57.1210\n","Epoch 34/40\n","564/564 [==============================] - 20s 36ms/step - loss: 3604.2808 - mae: 41.3311 - val_loss: 6027.2109 - val_mae: 58.4498\n","Epoch 35/40\n","564/564 [==============================] - 22s 39ms/step - loss: 3594.2639 - mae: 41.2536 - val_loss: 5691.6226 - val_mae: 59.0480\n","Epoch 36/40\n","564/564 [==============================] - 20s 36ms/step - loss: 3562.8245 - mae: 40.9580 - val_loss: 6012.2725 - val_mae: 59.3405\n","Epoch 37/40\n","564/564 [==============================] - 20s 35ms/step - loss: 3602.2017 - mae: 41.3461 - val_loss: 5853.0957 - val_mae: 59.8757\n","Epoch 38/40\n","564/564 [==============================] - 20s 36ms/step - loss: 3566.3335 - mae: 41.1893 - val_loss: 6006.6738 - val_mae: 61.0662\n","Epoch 39/40\n","564/564 [==============================] - 20s 36ms/step - loss: 3578.1543 - mae: 41.1769 - val_loss: 5948.2939 - val_mae: 60.7432\n","Epoch 40/40\n","564/564 [==============================] - 22s 39ms/step - loss: 3561.1426 - mae: 40.9388 - val_loss: 5680.4971 - val_mae: 60.0392\n","53.46984185558185\n","1.0783989692886733\n","1.0168112570657235\n","start group2,This is the experiment num: 0\n","\n","---------------------------------------------- domain num 0 is running----------------------------------\n","start training\n","Epoch 1/40\n","939/939 [==============================] - 35s 36ms/step - loss: 6300.0400 - mae: 60.3279 - val_loss: 7896.8403 - val_mae: 54.8317\n","Epoch 2/40\n","939/939 [==============================] - 35s 38ms/step - loss: 4922.5498 - mae: 53.6242 - val_loss: 7155.7886 - val_mae: 68.1908\n","Epoch 3/40\n","939/939 [==============================] - 34s 36ms/step - loss: 3889.0732 - mae: 45.8038 - val_loss: 5971.3066 - val_mae: 60.8217\n","Epoch 4/40\n","939/939 [==============================] - 33s 35ms/step - loss: 3714.0332 - mae: 43.7744 - val_loss: 6769.2583 - val_mae: 72.6831\n","Epoch 5/40\n","939/939 [==============================] - 36s 38ms/step - loss: 3703.9143 - mae: 43.5586 - val_loss: 6895.0522 - val_mae: 75.0659\n","Epoch 6/40\n","939/939 [==============================] - 34s 36ms/step - loss: 3691.8005 - mae: 43.3870 - val_loss: 7389.8965 - val_mae: 77.2924\n","Epoch 7/40\n","939/939 [==============================] - 34s 37ms/step - loss: 3689.1587 - mae: 43.3573 - val_loss: 6809.4946 - val_mae: 73.7766\n","Epoch 8/40\n","939/939 [==============================] - 36s 38ms/step - loss: 3676.2097 - mae: 43.3200 - val_loss: 6713.5229 - val_mae: 72.0552\n","Epoch 9/40\n","939/939 [==============================] - 34s 37ms/step - loss: 3679.6113 - mae: 43.2986 - val_loss: 7139.8330 - val_mae: 76.2067\n","Epoch 10/40\n","939/939 [==============================] - 37s 39ms/step - loss: 3676.6082 - mae: 43.3597 - val_loss: 6260.8569 - val_mae: 67.9955\n","Epoch 11/40\n","939/939 [==============================] - 35s 37ms/step - loss: 3653.2896 - mae: 43.1052 - val_loss: 6109.8672 - val_mae: 64.2020\n","Epoch 12/40\n","939/939 [==============================] - 35s 37ms/step - loss: 3665.3997 - mae: 43.2407 - val_loss: 6456.2363 - val_mae: 70.0105\n","Epoch 13/40\n","939/939 [==============================] - 36s 38ms/step - loss: 3656.1362 - mae: 43.1126 - val_loss: 7512.9282 - val_mae: 76.5935\n","Epoch 14/40\n","939/939 [==============================] - 34s 36ms/step - loss: 3659.9441 - mae: 43.1878 - val_loss: 6602.4414 - val_mae: 70.5811\n","Epoch 15/40\n","939/939 [==============================] - 34s 36ms/step - loss: 3647.7229 - mae: 42.9866 - val_loss: 6068.2910 - val_mae: 66.1538\n","Epoch 16/40\n","939/939 [==============================] - 36s 38ms/step - loss: 3641.1855 - mae: 42.9623 - val_loss: 5944.9683 - val_mae: 63.7495\n","Epoch 17/40\n","939/939 [==============================] - 34s 36ms/step - loss: 3622.6628 - mae: 42.8356 - val_loss: 6902.3550 - val_mae: 73.9067\n","Epoch 18/40\n","939/939 [==============================] - 34s 36ms/step - loss: 3620.2542 - mae: 42.8119 - val_loss: 6809.7925 - val_mae: 73.5067\n","Epoch 19/40\n","939/939 [==============================] - 36s 38ms/step - loss: 3608.0596 - mae: 42.6620 - val_loss: 6604.3413 - val_mae: 70.3693\n","Epoch 20/40\n","939/939 [==============================] - 34s 36ms/step - loss: 3620.2097 - mae: 42.8094 - val_loss: 6367.2319 - val_mae: 68.3499\n","Epoch 21/40\n","939/939 [==============================] - 34s 36ms/step - loss: 3621.6763 - mae: 42.7955 - val_loss: 6164.7695 - val_mae: 62.2835\n","Epoch 22/40\n","939/939 [==============================] - 36s 39ms/step - loss: 3615.7705 - mae: 42.7691 - val_loss: 6926.2300 - val_mae: 73.4513\n","Epoch 23/40\n","939/939 [==============================] - 35s 37ms/step - loss: 3606.8345 - mae: 42.7375 - val_loss: 5951.8325 - val_mae: 61.5253\n","Epoch 24/40\n","939/939 [==============================] - 35s 37ms/step - loss: 3600.4417 - mae: 42.5695 - val_loss: 6173.5225 - val_mae: 66.8272\n","Epoch 25/40\n","939/939 [==============================] - 37s 39ms/step - loss: 3613.3699 - mae: 42.7627 - val_loss: 6082.4829 - val_mae: 66.0849\n","Epoch 26/40\n","939/939 [==============================] - 35s 37ms/step - loss: 3606.4739 - mae: 42.7396 - val_loss: 5974.0630 - val_mae: 64.1819\n","Epoch 27/40\n","939/939 [==============================] - 37s 40ms/step - loss: 3602.3638 - mae: 42.7186 - val_loss: 6946.0068 - val_mae: 74.9118\n","Epoch 28/40\n","939/939 [==============================] - 35s 38ms/step - loss: 3599.0859 - mae: 42.6823 - val_loss: 5985.8701 - val_mae: 63.3430\n","Epoch 29/40\n","939/939 [==============================] - 35s 37ms/step - loss: 3593.3076 - mae: 42.6236 - val_loss: 6288.9878 - val_mae: 66.5144\n","Epoch 30/40\n","939/939 [==============================] - 37s 39ms/step - loss: 3593.9893 - mae: 42.6518 - val_loss: 6082.6475 - val_mae: 64.2815\n","Epoch 31/40\n","939/939 [==============================] - 35s 37ms/step - loss: 3590.2971 - mae: 42.6246 - val_loss: 6483.4761 - val_mae: 69.6880\n","Epoch 32/40\n","939/939 [==============================] - 35s 37ms/step - loss: 3587.6167 - mae: 42.5183 - val_loss: 7039.5454 - val_mae: 73.6352\n","Epoch 33/40\n","939/939 [==============================] - 37s 39ms/step - loss: 3582.8848 - mae: 42.5235 - val_loss: 6842.5210 - val_mae: 73.4450\n","Epoch 34/40\n","939/939 [==============================] - 35s 37ms/step - loss: 3578.8313 - mae: 42.4124 - val_loss: 6368.4229 - val_mae: 68.0980\n","Epoch 35/40\n","939/939 [==============================] - 35s 37ms/step - loss: 3582.1340 - mae: 42.4765 - val_loss: 5968.1851 - val_mae: 60.2484\n","Epoch 36/40\n","939/939 [==============================] - 37s 39ms/step - loss: 3566.1223 - mae: 42.3359 - val_loss: 7111.2036 - val_mae: 74.1330\n","Epoch 37/40\n","939/939 [==============================] - 35s 37ms/step - loss: 3569.6743 - mae: 42.4030 - val_loss: 6623.4507 - val_mae: 69.8196\n","Epoch 38/40\n","939/939 [==============================] - 35s 37ms/step - loss: 3570.6533 - mae: 42.4203 - val_loss: 6933.4058 - val_mae: 72.5430\n","Epoch 39/40\n","939/939 [==============================] - 37s 39ms/step - loss: 3568.4417 - mae: 42.3355 - val_loss: 7106.5327 - val_mae: 74.9361\n","Epoch 40/40\n","939/939 [==============================] - 35s 37ms/step - loss: 3552.1211 - mae: 42.2796 - val_loss: 6290.7754 - val_mae: 64.3566\n","44.92933223726905\n","0.6280456507802546\n","0.8356414107314752\n","start group2,This is the experiment num: 1\n","\n","---------------------------------------------- domain num 0 is running----------------------------------\n","start training\n","Epoch 1/40\n","939/939 [==============================] - 36s 37ms/step - loss: 6313.1978 - mae: 60.1186 - val_loss: 7996.8301 - val_mae: 55.3627\n","Epoch 2/40\n","939/939 [==============================] - 34s 37ms/step - loss: 4905.5513 - mae: 53.5336 - val_loss: 6931.2808 - val_mae: 60.2485\n","Epoch 3/40\n","939/939 [==============================] - 37s 39ms/step - loss: 3868.6877 - mae: 45.5582 - val_loss: 7314.2949 - val_mae: 78.0258\n","Epoch 4/40\n","939/939 [==============================] - 35s 37ms/step - loss: 3709.3901 - mae: 43.7131 - val_loss: 6700.0503 - val_mae: 64.2262\n","Epoch 5/40\n","939/939 [==============================] - 36s 38ms/step - loss: 3720.4744 - mae: 43.8306 - val_loss: 5653.7710 - val_mae: 58.3646\n","Epoch 6/40\n","939/939 [==============================] - 37s 39ms/step - loss: 3705.9431 - mae: 43.5643 - val_loss: 7692.8013 - val_mae: 80.9017\n","Epoch 7/40\n","939/939 [==============================] - 35s 37ms/step - loss: 3691.6074 - mae: 43.4401 - val_loss: 6330.8916 - val_mae: 66.4394\n","Epoch 8/40\n","939/939 [==============================] - 37s 39ms/step - loss: 3680.8279 - mae: 43.2687 - val_loss: 6581.9302 - val_mae: 69.6875\n","Epoch 9/40\n","939/939 [==============================] - 35s 37ms/step - loss: 3666.0164 - mae: 43.1318 - val_loss: 6641.0371 - val_mae: 71.5266\n","Epoch 10/40\n","939/939 [==============================] - 35s 37ms/step - loss: 3669.6887 - mae: 43.2682 - val_loss: 6256.6167 - val_mae: 66.2576\n","Epoch 11/40\n","939/939 [==============================] - 36s 39ms/step - loss: 3670.0242 - mae: 43.1393 - val_loss: 6567.1045 - val_mae: 69.5989\n","Epoch 12/40\n","939/939 [==============================] - 34s 37ms/step - loss: 3661.9141 - mae: 43.0573 - val_loss: 6804.5264 - val_mae: 71.1717\n","Epoch 13/40\n","939/939 [==============================] - 35s 37ms/step - loss: 3644.4504 - mae: 42.9628 - val_loss: 6843.6338 - val_mae: 73.5071\n","Epoch 14/40\n","939/939 [==============================] - 36s 39ms/step - loss: 3649.3132 - mae: 43.0125 - val_loss: 6692.4824 - val_mae: 70.3987\n","Epoch 15/40\n","939/939 [==============================] - 35s 37ms/step - loss: 3646.2805 - mae: 42.9844 - val_loss: 6303.2549 - val_mae: 66.5081\n","Epoch 16/40\n","939/939 [==============================] - 34s 37ms/step - loss: 3644.0764 - mae: 42.9575 - val_loss: 6232.5801 - val_mae: 67.7029\n","Epoch 17/40\n","939/939 [==============================] - 37s 39ms/step - loss: 3637.5476 - mae: 43.0103 - val_loss: 6016.9648 - val_mae: 64.3277\n","Epoch 18/40\n","939/939 [==============================] - 34s 36ms/step - loss: 3638.3098 - mae: 42.9274 - val_loss: 6751.5034 - val_mae: 72.7384\n","Epoch 19/40\n","939/939 [==============================] - 34s 37ms/step - loss: 3624.7144 - mae: 42.6866 - val_loss: 6778.0132 - val_mae: 68.5633\n","Epoch 20/40\n","939/939 [==============================] - 37s 39ms/step - loss: 3631.6038 - mae: 42.8345 - val_loss: 7203.3628 - val_mae: 75.5913\n","Epoch 21/40\n","939/939 [==============================] - 35s 37ms/step - loss: 3625.6819 - mae: 42.8496 - val_loss: 6544.4810 - val_mae: 71.3344\n","Epoch 22/40\n","939/939 [==============================] - 35s 37ms/step - loss: 3626.4385 - mae: 42.9158 - val_loss: 5997.3101 - val_mae: 65.4878\n","Epoch 23/40\n","939/939 [==============================] - 37s 39ms/step - loss: 3623.8672 - mae: 42.7026 - val_loss: 6996.0615 - val_mae: 73.9707\n","Epoch 24/40\n","939/939 [==============================] - 35s 37ms/step - loss: 3622.5840 - mae: 42.8375 - val_loss: 5991.9941 - val_mae: 64.2771\n","Epoch 25/40\n","939/939 [==============================] - 36s 39ms/step - loss: 3617.2163 - mae: 42.7906 - val_loss: 6470.5771 - val_mae: 70.6927\n","Epoch 26/40\n","939/939 [==============================] - 35s 37ms/step - loss: 3600.4495 - mae: 42.5605 - val_loss: 6733.2241 - val_mae: 72.2157\n","Epoch 27/40\n","939/939 [==============================] - 35s 37ms/step - loss: 3606.2297 - mae: 42.7120 - val_loss: 6866.6392 - val_mae: 73.5868\n","Epoch 28/40\n","939/939 [==============================] - 36s 39ms/step - loss: 3606.1160 - mae: 42.6393 - val_loss: 6849.0356 - val_mae: 72.8486\n","Epoch 29/40\n","939/939 [==============================] - 34s 37ms/step - loss: 3577.8257 - mae: 42.3569 - val_loss: 7082.7119 - val_mae: 75.2174\n","Epoch 30/40\n","939/939 [==============================] - 35s 37ms/step - loss: 3605.7236 - mae: 42.6497 - val_loss: 7651.2490 - val_mae: 79.7285\n","Epoch 31/40\n","939/939 [==============================] - 36s 39ms/step - loss: 3590.2646 - mae: 42.5616 - val_loss: 6835.9878 - val_mae: 73.2443\n","Epoch 32/40\n","939/939 [==============================] - 34s 37ms/step - loss: 3577.1519 - mae: 42.4536 - val_loss: 7046.7344 - val_mae: 74.2387\n","Epoch 33/40\n","939/939 [==============================] - 34s 36ms/step - loss: 3571.4712 - mae: 42.2506 - val_loss: 7470.8989 - val_mae: 78.9236\n","Epoch 34/40\n","939/939 [==============================] - 36s 39ms/step - loss: 3570.3838 - mae: 42.3173 - val_loss: 6630.1392 - val_mae: 72.1442\n","Epoch 35/40\n","939/939 [==============================] - 34s 37ms/step - loss: 3573.9529 - mae: 42.3722 - val_loss: 7577.7402 - val_mae: 79.5796\n","Epoch 36/40\n","939/939 [==============================] - 34s 36ms/step - loss: 3573.0935 - mae: 42.4114 - val_loss: 6567.3716 - val_mae: 70.3673\n","Epoch 37/40\n","939/939 [==============================] - 36s 38ms/step - loss: 3570.7883 - mae: 42.3632 - val_loss: 6286.1611 - val_mae: 69.2131\n","Epoch 38/40\n","939/939 [==============================] - 34s 36ms/step - loss: 3573.6633 - mae: 42.3892 - val_loss: 7027.0088 - val_mae: 73.4003\n","Epoch 39/40\n","939/939 [==============================] - 34s 37ms/step - loss: 3564.3660 - mae: 42.3150 - val_loss: 6469.3071 - val_mae: 69.2898\n","Epoch 40/40\n","939/939 [==============================] - 36s 39ms/step - loss: 3560.9609 - mae: 42.2438 - val_loss: 6234.1426 - val_mae: 65.8685\n","44.80310393514709\n","0.6115400494201851\n","0.8313787939011253\n","start group2,This is the experiment num: 2\n","\n","---------------------------------------------- domain num 0 is running----------------------------------\n","start training\n","Epoch 1/40\n","939/939 [==============================] - 36s 37ms/step - loss: 6305.3926 - mae: 60.1439 - val_loss: 8133.5752 - val_mae: 54.4984\n","Epoch 2/40\n","939/939 [==============================] - 35s 37ms/step - loss: 4892.8228 - mae: 53.3672 - val_loss: 6595.4136 - val_mae: 67.4487\n","Epoch 3/40\n","939/939 [==============================] - 37s 39ms/step - loss: 3869.4077 - mae: 45.4906 - val_loss: 6996.1436 - val_mae: 72.4417\n","Epoch 4/40\n","939/939 [==============================] - 35s 37ms/step - loss: 3729.9749 - mae: 43.9726 - val_loss: 6366.4526 - val_mae: 68.4897\n","Epoch 5/40\n","939/939 [==============================] - 36s 38ms/step - loss: 3703.6628 - mae: 43.6364 - val_loss: 6731.7842 - val_mae: 74.0758\n","Epoch 6/40\n","939/939 [==============================] - 37s 39ms/step - loss: 3692.8674 - mae: 43.5135 - val_loss: 6818.5938 - val_mae: 73.8900\n","Epoch 7/40\n","939/939 [==============================] - 35s 37ms/step - loss: 3681.7068 - mae: 43.3356 - val_loss: 7440.9565 - val_mae: 76.0715\n","Epoch 8/40\n","939/939 [==============================] - 35s 37ms/step - loss: 3684.7222 - mae: 43.3935 - val_loss: 6875.7900 - val_mae: 72.9856\n","Epoch 9/40\n","939/939 [==============================] - 37s 39ms/step - loss: 3662.1084 - mae: 43.1006 - val_loss: 6659.9521 - val_mae: 70.6621\n","Epoch 10/40\n","939/939 [==============================] - 35s 37ms/step - loss: 3649.6152 - mae: 43.0012 - val_loss: 6704.6494 - val_mae: 72.4352\n","Epoch 11/40\n","939/939 [==============================] - 36s 39ms/step - loss: 3664.3958 - mae: 43.1335 - val_loss: 6599.9897 - val_mae: 70.6603\n","Epoch 12/40\n","939/939 [==============================] - 35s 37ms/step - loss: 3642.9346 - mae: 42.8903 - val_loss: 6181.3687 - val_mae: 65.4875\n","Epoch 13/40\n","939/939 [==============================] - 35s 37ms/step - loss: 3650.6353 - mae: 43.0258 - val_loss: 6895.5049 - val_mae: 72.6622\n","Epoch 14/40\n","939/939 [==============================] - 37s 39ms/step - loss: 3644.2742 - mae: 42.9879 - val_loss: 7446.6729 - val_mae: 76.5139\n","Epoch 15/40\n","939/939 [==============================] - 35s 37ms/step - loss: 3636.3521 - mae: 42.9700 - val_loss: 6262.2432 - val_mae: 67.2394\n","Epoch 16/40\n","939/939 [==============================] - 36s 39ms/step - loss: 3632.5354 - mae: 42.8169 - val_loss: 6873.3813 - val_mae: 72.5727\n","Epoch 17/40\n","939/939 [==============================] - 40s 42ms/step - loss: 3641.8787 - mae: 42.9814 - val_loss: 5756.8394 - val_mae: 62.5110\n","Epoch 18/40\n","939/939 [==============================] - 37s 40ms/step - loss: 3635.7405 - mae: 42.7930 - val_loss: 6924.2422 - val_mae: 73.6768\n","Epoch 19/40\n","939/939 [==============================] - 38s 40ms/step - loss: 3621.4421 - mae: 42.7691 - val_loss: 6610.5024 - val_mae: 71.6518\n","Epoch 20/40\n","939/939 [==============================] - 38s 41ms/step - loss: 3640.6553 - mae: 42.9522 - val_loss: 6670.3931 - val_mae: 71.4920\n","Epoch 21/40\n","939/939 [==============================] - 36s 39ms/step - loss: 3625.6543 - mae: 42.7647 - val_loss: 6284.1450 - val_mae: 66.9619\n","Epoch 22/40\n","939/939 [==============================] - 39s 41ms/step - loss: 3606.4587 - mae: 42.6821 - val_loss: 6421.0508 - val_mae: 68.9648\n","Epoch 23/40\n","939/939 [==============================] - 36s 38ms/step - loss: 3613.4912 - mae: 42.6476 - val_loss: 6405.4697 - val_mae: 69.2395\n","Epoch 24/40\n","939/939 [==============================] - 36s 39ms/step - loss: 3606.3157 - mae: 42.5429 - val_loss: 6206.7500 - val_mae: 68.1096\n","Epoch 25/40\n","939/939 [==============================] - 38s 40ms/step - loss: 3586.9094 - mae: 42.4174 - val_loss: 6622.9092 - val_mae: 70.2150\n","Epoch 26/40\n","939/939 [==============================] - 36s 38ms/step - loss: 3605.2834 - mae: 42.6237 - val_loss: 6368.3237 - val_mae: 68.1429\n","Epoch 27/40\n","939/939 [==============================] - 36s 38ms/step - loss: 3603.8411 - mae: 42.6591 - val_loss: 5762.4648 - val_mae: 61.0515\n","Epoch 28/40\n","939/939 [==============================] - 37s 40ms/step - loss: 3591.7402 - mae: 42.5353 - val_loss: 6162.2163 - val_mae: 66.4993\n","Epoch 29/40\n","939/939 [==============================] - 36s 38ms/step - loss: 3598.3838 - mae: 42.5016 - val_loss: 6634.0576 - val_mae: 72.1634\n","Epoch 30/40\n","939/939 [==============================] - 36s 38ms/step - loss: 3587.8130 - mae: 42.4048 - val_loss: 6462.8813 - val_mae: 69.4135\n","Epoch 31/40\n","939/939 [==============================] - 38s 40ms/step - loss: 3586.1060 - mae: 42.3925 - val_loss: 6627.0088 - val_mae: 70.6688\n","Epoch 32/40\n","939/939 [==============================] - 35s 38ms/step - loss: 3570.4482 - mae: 42.3296 - val_loss: 6260.7417 - val_mae: 68.4508\n","Epoch 33/40\n","939/939 [==============================] - 37s 40ms/step - loss: 3575.2271 - mae: 42.3135 - val_loss: 7083.5283 - val_mae: 74.3130\n","Epoch 34/40\n","939/939 [==============================] - 36s 38ms/step - loss: 3571.7139 - mae: 42.3630 - val_loss: 7094.6162 - val_mae: 74.0809\n","Epoch 35/40\n","939/939 [==============================] - 36s 38ms/step - loss: 3563.3584 - mae: 42.2621 - val_loss: 6534.1099 - val_mae: 68.5844\n","Epoch 36/40\n","939/939 [==============================] - 39s 41ms/step - loss: 3570.7886 - mae: 42.3154 - val_loss: 6018.0625 - val_mae: 65.2264\n","Epoch 37/40\n","939/939 [==============================] - 36s 39ms/step - loss: 3568.9661 - mae: 42.3955 - val_loss: 6227.3452 - val_mae: 66.6763\n","Epoch 38/40\n","939/939 [==============================] - 36s 39ms/step - loss: 3576.5432 - mae: 42.4328 - val_loss: 6289.3003 - val_mae: 68.4729\n","Epoch 39/40\n","939/939 [==============================] - 38s 41ms/step - loss: 3561.7603 - mae: 42.2908 - val_loss: 6548.6035 - val_mae: 70.5023\n","Epoch 40/40\n","939/939 [==============================] - 37s 39ms/step - loss: 3558.5774 - mae: 42.2612 - val_loss: 6225.3813 - val_mae: 67.7686\n","43.52937140088583\n","0.5895479655762847\n","0.8169181516381852\n","start group2,This is the experiment num: 3\n","\n","---------------------------------------------- domain num 0 is running----------------------------------\n","start training\n","Epoch 1/40\n","939/939 [==============================] - 39s 41ms/step - loss: 6305.9160 - mae: 60.1878 - val_loss: 8042.6108 - val_mae: 55.3836\n","Epoch 2/40\n","939/939 [==============================] - 37s 39ms/step - loss: 4881.6147 - mae: 53.3174 - val_loss: 7074.8301 - val_mae: 68.1762\n","Epoch 3/40\n","939/939 [==============================] - 36s 39ms/step - loss: 3860.0442 - mae: 45.5824 - val_loss: 7287.1196 - val_mae: 77.6574\n","Epoch 4/40\n","939/939 [==============================] - 39s 41ms/step - loss: 3730.6084 - mae: 43.9416 - val_loss: 8094.4819 - val_mae: 83.3313\n","Epoch 5/40\n","939/939 [==============================] - 37s 40ms/step - loss: 3707.0669 - mae: 43.7035 - val_loss: 6169.6250 - val_mae: 67.2640\n","Epoch 6/40\n","939/939 [==============================] - 38s 40ms/step - loss: 3706.6104 - mae: 43.7183 - val_loss: 6627.6426 - val_mae: 72.5313\n","Epoch 7/40\n","939/939 [==============================] - 39s 42ms/step - loss: 3698.2183 - mae: 43.5722 - val_loss: 5536.8428 - val_mae: 58.6324\n","Epoch 8/40\n","939/939 [==============================] - 38s 40ms/step - loss: 3676.2629 - mae: 43.4641 - val_loss: 6657.1543 - val_mae: 70.7110\n","Epoch 9/40\n","939/939 [==============================] - 40s 42ms/step - loss: 3662.2590 - mae: 43.2255 - val_loss: 5883.2505 - val_mae: 62.7243\n","Epoch 10/40\n","939/939 [==============================] - 38s 40ms/step - loss: 3674.4617 - mae: 43.2796 - val_loss: 6318.5171 - val_mae: 68.3615\n","Epoch 11/40\n","939/939 [==============================] - 38s 41ms/step - loss: 3657.7227 - mae: 43.1516 - val_loss: 6349.2710 - val_mae: 68.3640\n","Epoch 12/40\n","939/939 [==============================] - 40s 43ms/step - loss: 3660.6194 - mae: 43.1301 - val_loss: 7002.9238 - val_mae: 75.2204\n","Epoch 13/40\n","939/939 [==============================] - 38s 41ms/step - loss: 3653.9663 - mae: 43.0217 - val_loss: 6489.9233 - val_mae: 69.3610\n","Epoch 14/40\n","939/939 [==============================] - 37s 40ms/step - loss: 3651.5195 - mae: 43.0728 - val_loss: 6481.3271 - val_mae: 68.6900\n","Epoch 15/40\n","939/939 [==============================] - 39s 42ms/step - loss: 3636.0208 - mae: 42.9050 - val_loss: 6496.0132 - val_mae: 69.8919\n","Epoch 16/40\n","939/939 [==============================] - 38s 41ms/step - loss: 3626.0835 - mae: 42.8466 - val_loss: 6627.2134 - val_mae: 72.5929\n","Epoch 17/40\n","939/939 [==============================] - 40s 43ms/step - loss: 3633.3049 - mae: 42.9340 - val_loss: 6614.5732 - val_mae: 70.9547\n","Epoch 18/40\n","939/939 [==============================] - 37s 40ms/step - loss: 3629.9514 - mae: 42.9066 - val_loss: 6445.2744 - val_mae: 68.8218\n","Epoch 19/40\n","939/939 [==============================] - 38s 40ms/step - loss: 3621.4583 - mae: 42.7158 - val_loss: 6317.4121 - val_mae: 67.3304\n","Epoch 20/40\n","939/939 [==============================] - 39s 42ms/step - loss: 3628.7515 - mae: 42.8102 - val_loss: 6747.8262 - val_mae: 72.9070\n","Epoch 21/40\n","939/939 [==============================] - 38s 40ms/step - loss: 3618.4587 - mae: 42.7482 - val_loss: 6221.1890 - val_mae: 68.8384\n","Epoch 22/40\n","939/939 [==============================] - 38s 40ms/step - loss: 3620.1951 - mae: 42.7270 - val_loss: 6636.3540 - val_mae: 70.2090\n","Epoch 23/40\n","939/939 [==============================] - 39s 41ms/step - loss: 3613.3232 - mae: 42.7136 - val_loss: 6952.2876 - val_mae: 74.3006\n","Epoch 24/40\n","939/939 [==============================] - 38s 40ms/step - loss: 3615.1677 - mae: 42.7402 - val_loss: 6501.0400 - val_mae: 69.7102\n","Epoch 25/40\n","939/939 [==============================] - 40s 42ms/step - loss: 3598.2646 - mae: 42.5755 - val_loss: 6594.3140 - val_mae: 69.0597\n","Epoch 26/40\n","939/939 [==============================] - 38s 40ms/step - loss: 3611.1953 - mae: 42.6979 - val_loss: 6537.2153 - val_mae: 71.1802\n","Epoch 27/40\n","939/939 [==============================] - 38s 41ms/step - loss: 3604.5217 - mae: 42.6252 - val_loss: 6236.2905 - val_mae: 66.7768\n","Epoch 28/40\n","939/939 [==============================] - 40s 43ms/step - loss: 3590.9705 - mae: 42.5522 - val_loss: 7060.7935 - val_mae: 74.7530\n","Epoch 29/40\n","939/939 [==============================] - 38s 40ms/step - loss: 3595.2778 - mae: 42.5794 - val_loss: 6341.2031 - val_mae: 68.2600\n","Epoch 30/40\n","939/939 [==============================] - 39s 42ms/step - loss: 3576.1702 - mae: 42.4094 - val_loss: 6544.3965 - val_mae: 69.9325\n","Epoch 31/40\n","939/939 [==============================] - 38s 40ms/step - loss: 3572.9285 - mae: 42.3707 - val_loss: 6881.9966 - val_mae: 73.4277\n","Epoch 32/40\n","939/939 [==============================] - 38s 41ms/step - loss: 3582.7007 - mae: 42.4474 - val_loss: 6680.5049 - val_mae: 70.0702\n","Epoch 33/40\n","939/939 [==============================] - 40s 43ms/step - loss: 3570.6567 - mae: 42.2654 - val_loss: 6375.0752 - val_mae: 68.1157\n","Epoch 34/40\n","939/939 [==============================] - 38s 40ms/step - loss: 3581.0869 - mae: 42.4355 - val_loss: 6750.1294 - val_mae: 71.3586\n","Epoch 35/40\n","939/939 [==============================] - 39s 41ms/step - loss: 3583.4363 - mae: 42.4770 - val_loss: 6038.9355 - val_mae: 65.4675\n","Epoch 36/40\n","939/939 [==============================] - 40s 43ms/step - loss: 3560.7981 - mae: 42.2343 - val_loss: 7345.3486 - val_mae: 77.4000\n","Epoch 37/40\n","939/939 [==============================] - 38s 41ms/step - loss: 3562.4722 - mae: 42.3305 - val_loss: 6414.1460 - val_mae: 68.3027\n","Epoch 38/40\n","939/939 [==============================] - 40s 43ms/step - loss: 3561.1052 - mae: 42.1262 - val_loss: 6926.9644 - val_mae: 71.7482\n","Epoch 39/40\n","939/939 [==============================] - 38s 40ms/step - loss: 3553.9507 - mae: 42.1871 - val_loss: 6721.9155 - val_mae: 70.5984\n","Epoch 40/40\n","939/939 [==============================] - 38s 40ms/step - loss: 3563.4468 - mae: 42.2364 - val_loss: 6511.2646 - val_mae: 68.4148\n","45.973891041354435\n","0.6783591169692199\n","0.8549438208128821\n","start group2,This is the experiment num: 4\n","\n","---------------------------------------------- domain num 0 is running----------------------------------\n","start training\n","Epoch 1/40\n","939/939 [==============================] - 41s 43ms/step - loss: 6287.1519 - mae: 60.3627 - val_loss: 8954.8994 - val_mae: 66.1420\n","Epoch 2/40\n","939/939 [==============================] - 37s 39ms/step - loss: 4944.6299 - mae: 53.6942 - val_loss: 6646.3081 - val_mae: 58.3154\n","Epoch 3/40\n","939/939 [==============================] - 38s 41ms/step - loss: 3885.2771 - mae: 45.7059 - val_loss: 5876.2188 - val_mae: 61.8734\n","Epoch 4/40\n","939/939 [==============================] - 37s 39ms/step - loss: 3720.8821 - mae: 43.9548 - val_loss: 6179.3911 - val_mae: 66.6404\n","Epoch 5/40\n","939/939 [==============================] - 36s 39ms/step - loss: 3709.9299 - mae: 43.8703 - val_loss: 6117.8662 - val_mae: 66.1682\n","Epoch 6/40\n","939/939 [==============================] - 39s 42ms/step - loss: 3689.4075 - mae: 43.5884 - val_loss: 6408.5435 - val_mae: 68.4507\n","Epoch 7/40\n","939/939 [==============================] - 37s 39ms/step - loss: 3684.2043 - mae: 43.5315 - val_loss: 6180.6396 - val_mae: 67.7314\n","Epoch 8/40\n","939/939 [==============================] - 37s 39ms/step - loss: 3681.4629 - mae: 43.5790 - val_loss: 6722.3516 - val_mae: 72.3799\n","Epoch 9/40\n","939/939 [==============================] - 39s 41ms/step - loss: 3668.2439 - mae: 43.3712 - val_loss: 7118.4492 - val_mae: 75.3825\n","Epoch 10/40\n","939/939 [==============================] - 37s 39ms/step - loss: 3672.9897 - mae: 43.4286 - val_loss: 7219.2153 - val_mae: 74.9391\n","Epoch 11/40\n","939/939 [==============================] - 39s 41ms/step - loss: 3663.9705 - mae: 43.3888 - val_loss: 6528.5190 - val_mae: 69.5585\n","Epoch 12/40\n","939/939 [==============================] - 37s 40ms/step - loss: 3668.0176 - mae: 43.3638 - val_loss: 7330.8091 - val_mae: 76.6562\n","Epoch 13/40\n","939/939 [==============================] - 37s 39ms/step - loss: 3659.7070 - mae: 43.2988 - val_loss: 6692.6685 - val_mae: 71.0070\n","Epoch 14/40\n","939/939 [==============================] - 39s 42ms/step - loss: 3652.2712 - mae: 43.1752 - val_loss: 6796.2080 - val_mae: 73.0406\n","Epoch 15/40\n","939/939 [==============================] - 37s 40ms/step - loss: 3657.7224 - mae: 43.2449 - val_loss: 6777.5679 - val_mae: 72.9588\n","Epoch 16/40\n","939/939 [==============================] - 37s 40ms/step - loss: 3648.8379 - mae: 43.1016 - val_loss: 6580.5298 - val_mae: 70.5968\n","Epoch 17/40\n","939/939 [==============================] - 40s 42ms/step - loss: 3641.7947 - mae: 43.0776 - val_loss: 6815.7412 - val_mae: 72.1533\n","Epoch 18/40\n","939/939 [==============================] - 37s 40ms/step - loss: 3644.3857 - mae: 43.0766 - val_loss: 6353.9951 - val_mae: 68.2399\n","Epoch 19/40\n","939/939 [==============================] - 39s 42ms/step - loss: 3642.3772 - mae: 43.0900 - val_loss: 6668.1504 - val_mae: 72.7153\n","Epoch 20/40\n","939/939 [==============================] - 37s 39ms/step - loss: 3627.8569 - mae: 43.0214 - val_loss: 6608.9355 - val_mae: 70.6289\n","Epoch 21/40\n","939/939 [==============================] - 37s 39ms/step - loss: 3639.2043 - mae: 42.9834 - val_loss: 6418.1650 - val_mae: 69.2753\n","Epoch 22/40\n","939/939 [==============================] - 39s 42ms/step - loss: 3621.5896 - mae: 42.9076 - val_loss: 7181.6289 - val_mae: 74.9321\n","Epoch 23/40\n","939/939 [==============================] - 37s 39ms/step - loss: 3620.3787 - mae: 42.8839 - val_loss: 6915.8149 - val_mae: 74.2428\n","Epoch 24/40\n","939/939 [==============================] - 38s 40ms/step - loss: 3619.8804 - mae: 42.8385 - val_loss: 6384.8193 - val_mae: 69.1925\n","Epoch 25/40\n","939/939 [==============================] - 39s 41ms/step - loss: 3613.8181 - mae: 42.9026 - val_loss: 6706.3784 - val_mae: 71.7343\n","Epoch 26/40\n","939/939 [==============================] - 37s 39ms/step - loss: 3616.2771 - mae: 42.9464 - val_loss: 6247.8018 - val_mae: 66.0939\n","Epoch 27/40\n","939/939 [==============================] - 39s 42ms/step - loss: 3605.7358 - mae: 42.8375 - val_loss: 6588.0776 - val_mae: 69.6599\n","Epoch 28/40\n","939/939 [==============================] - 37s 40ms/step - loss: 3604.4448 - mae: 42.7516 - val_loss: 7173.2329 - val_mae: 74.8818\n","Epoch 29/40\n","939/939 [==============================] - 38s 41ms/step - loss: 3605.0032 - mae: 42.7587 - val_loss: 5947.7651 - val_mae: 64.2818\n","Epoch 30/40\n","939/939 [==============================] - 40s 43ms/step - loss: 3602.7153 - mae: 42.8207 - val_loss: 6603.7651 - val_mae: 69.3025\n","Epoch 31/40\n","939/939 [==============================] - 37s 40ms/step - loss: 3594.4495 - mae: 42.7093 - val_loss: 6946.6797 - val_mae: 73.9094\n","Epoch 32/40\n","939/939 [==============================] - 39s 42ms/step - loss: 3593.6697 - mae: 42.5815 - val_loss: 6436.6699 - val_mae: 68.4999\n","Epoch 33/40\n","939/939 [==============================] - 37s 40ms/step - loss: 3591.5161 - mae: 42.7078 - val_loss: 6597.2104 - val_mae: 70.6566\n","Epoch 34/40\n","939/939 [==============================] - 37s 40ms/step - loss: 3595.6467 - mae: 42.5941 - val_loss: 6201.5474 - val_mae: 67.9951\n","Epoch 35/40\n","939/939 [==============================] - 40s 42ms/step - loss: 3574.9849 - mae: 42.5407 - val_loss: 6589.8208 - val_mae: 69.1055\n","Epoch 36/40\n","939/939 [==============================] - 38s 40ms/step - loss: 3591.5305 - mae: 42.6375 - val_loss: 6921.4624 - val_mae: 71.9530\n","Epoch 37/40\n","939/939 [==============================] - 37s 40ms/step - loss: 3580.2815 - mae: 42.5766 - val_loss: 6562.4194 - val_mae: 71.8184\n","Epoch 38/40\n","939/939 [==============================] - 40s 42ms/step - loss: 3580.7283 - mae: 42.4562 - val_loss: 6582.2622 - val_mae: 72.7269\n","Epoch 39/40\n","939/939 [==============================] - 38s 40ms/step - loss: 3574.1958 - mae: 42.5315 - val_loss: 6772.9263 - val_mae: 70.4126\n","Epoch 40/40\n","939/939 [==============================] - 37s 40ms/step - loss: 3569.7026 - mae: 42.3848 - val_loss: 6187.8345 - val_mae: 66.9889\n","45.3153534537149\n","0.7587656923289161\n","0.8674211661227405\n","start group3,This is the experiment num: 0\n","\n","---------------------------------------------- domain num 0 is running----------------------------------\n","start training\n","Epoch 1/40\n","1314/1314 [==============================] - 52s 39ms/step - loss: 6489.4541 - mae: 58.9778 - val_loss: 3442.5298 - val_mae: 37.4087\n","Epoch 2/40\n","1314/1314 [==============================] - 53s 40ms/step - loss: 4725.4468 - mae: 48.6946 - val_loss: 3894.6255 - val_mae: 49.1541\n","Epoch 3/40\n","1314/1314 [==============================] - 50s 38ms/step - loss: 4235.8076 - mae: 45.2662 - val_loss: 4273.4395 - val_mae: 51.6041\n","Epoch 4/40\n","1314/1314 [==============================] - 53s 40ms/step - loss: 4222.1475 - mae: 45.2532 - val_loss: 3311.6548 - val_mae: 43.3460\n","Epoch 5/40\n","1314/1314 [==============================] - 51s 39ms/step - loss: 4206.0708 - mae: 45.1569 - val_loss: 3410.2261 - val_mae: 43.6447\n","Epoch 6/40\n","1314/1314 [==============================] - 53s 41ms/step - loss: 4194.4062 - mae: 44.9805 - val_loss: 3428.1248 - val_mae: 44.0647\n","Epoch 7/40\n","1314/1314 [==============================] - 50s 38ms/step - loss: 4197.2266 - mae: 45.0314 - val_loss: 3890.3081 - val_mae: 48.7828\n","Epoch 8/40\n","1314/1314 [==============================] - 52s 40ms/step - loss: 4180.0752 - mae: 44.9976 - val_loss: 3446.1333 - val_mae: 43.8005\n","Epoch 9/40\n","1314/1314 [==============================] - 50s 38ms/step - loss: 4181.8281 - mae: 44.8887 - val_loss: 3834.9365 - val_mae: 48.4432\n","Epoch 10/40\n","1314/1314 [==============================] - 52s 39ms/step - loss: 4170.7422 - mae: 44.8530 - val_loss: 3442.3284 - val_mae: 45.0164\n","Epoch 11/40\n","1314/1314 [==============================] - 50s 38ms/step - loss: 4172.7031 - mae: 44.9186 - val_loss: 3559.7219 - val_mae: 45.7323\n","Epoch 12/40\n","1314/1314 [==============================] - 51s 39ms/step - loss: 4154.0786 - mae: 44.7700 - val_loss: 3454.1245 - val_mae: 44.2052\n","Epoch 13/40\n","1314/1314 [==============================] - 52s 39ms/step - loss: 4157.5615 - mae: 44.7610 - val_loss: 3491.7651 - val_mae: 45.3550\n","Epoch 14/40\n","1314/1314 [==============================] - 51s 39ms/step - loss: 4159.3091 - mae: 44.7718 - val_loss: 3534.2725 - val_mae: 45.6957\n","Epoch 15/40\n","1314/1314 [==============================] - 51s 39ms/step - loss: 4143.8433 - mae: 44.6733 - val_loss: 3522.2378 - val_mae: 45.4353\n","Epoch 16/40\n","1314/1314 [==============================] - 52s 40ms/step - loss: 4133.7153 - mae: 44.6211 - val_loss: 3326.2451 - val_mae: 41.8742\n","Epoch 17/40\n","1314/1314 [==============================] - 50s 38ms/step - loss: 4129.7319 - mae: 44.5781 - val_loss: 3362.4512 - val_mae: 39.5696\n","Epoch 18/40\n","1314/1314 [==============================] - 52s 40ms/step - loss: 4148.1177 - mae: 44.7654 - val_loss: 3648.8242 - val_mae: 47.1844\n","Epoch 19/40\n","1314/1314 [==============================] - 50s 38ms/step - loss: 4125.2964 - mae: 44.6879 - val_loss: 3940.3501 - val_mae: 49.5454\n","Epoch 20/40\n","1314/1314 [==============================] - 52s 40ms/step - loss: 4128.0923 - mae: 44.5516 - val_loss: 3306.8481 - val_mae: 42.8550\n","Epoch 21/40\n","1314/1314 [==============================] - 50s 38ms/step - loss: 4112.8311 - mae: 44.5279 - val_loss: 3368.7969 - val_mae: 42.7098\n","Epoch 22/40\n","1314/1314 [==============================] - 53s 40ms/step - loss: 4115.5073 - mae: 44.5676 - val_loss: 3698.6262 - val_mae: 46.8078\n","Epoch 23/40\n","1314/1314 [==============================] - 51s 39ms/step - loss: 4117.2847 - mae: 44.5737 - val_loss: 3417.6074 - val_mae: 43.2833\n","Epoch 24/40\n","1314/1314 [==============================] - 52s 40ms/step - loss: 4116.8882 - mae: 44.5214 - val_loss: 3434.3245 - val_mae: 44.5322\n","Epoch 25/40\n","1314/1314 [==============================] - 50s 38ms/step - loss: 4105.4170 - mae: 44.5694 - val_loss: 3621.0005 - val_mae: 46.7748\n","Epoch 26/40\n","1314/1314 [==============================] - 52s 39ms/step - loss: 4100.8218 - mae: 44.4585 - val_loss: 3652.9856 - val_mae: 47.1597\n","Epoch 27/40\n","1314/1314 [==============================] - 49s 38ms/step - loss: 4094.1807 - mae: 44.3447 - val_loss: 3511.0681 - val_mae: 45.6824\n","Epoch 28/40\n","1314/1314 [==============================] - 52s 39ms/step - loss: 4100.7007 - mae: 44.3115 - val_loss: 3579.9026 - val_mae: 46.2973\n","Epoch 29/40\n","1314/1314 [==============================] - 49s 38ms/step - loss: 4110.2656 - mae: 44.4063 - val_loss: 3597.0137 - val_mae: 46.4300\n","Epoch 30/40\n","1314/1314 [==============================] - 52s 40ms/step - loss: 4088.8276 - mae: 44.4385 - val_loss: 3392.3643 - val_mae: 43.3444\n","Epoch 31/40\n","1314/1314 [==============================] - 50s 38ms/step - loss: 4086.1421 - mae: 44.3744 - val_loss: 3520.8501 - val_mae: 45.7425\n","Epoch 32/40\n","1314/1314 [==============================] - 56s 43ms/step - loss: 4085.4600 - mae: 44.3305 - val_loss: 3424.0996 - val_mae: 44.3073\n","Epoch 33/40\n","1314/1314 [==============================] - 53s 40ms/step - loss: 4078.9187 - mae: 44.3263 - val_loss: 3399.1272 - val_mae: 43.5035\n","Epoch 34/40\n","1314/1314 [==============================] - 54s 41ms/step - loss: 4088.2556 - mae: 44.3375 - val_loss: 3656.7935 - val_mae: 47.2014\n","Epoch 35/40\n","1314/1314 [==============================] - 51s 39ms/step - loss: 4072.5176 - mae: 44.3098 - val_loss: 3440.6211 - val_mae: 44.5291\n","Epoch 36/40\n","1314/1314 [==============================] - 54s 41ms/step - loss: 4079.1514 - mae: 44.2497 - val_loss: 3487.6294 - val_mae: 45.3062\n","Epoch 37/40\n","1314/1314 [==============================] - 52s 40ms/step - loss: 4070.6257 - mae: 44.2333 - val_loss: 3582.1765 - val_mae: 45.8544\n","Epoch 38/40\n","1314/1314 [==============================] - 54s 41ms/step - loss: 4081.8716 - mae: 44.2759 - val_loss: 3557.2039 - val_mae: 45.9659\n","Epoch 39/40\n","1314/1314 [==============================] - 50s 38ms/step - loss: 4069.8296 - mae: 44.1530 - val_loss: 3480.4597 - val_mae: 45.4774\n","Epoch 40/40\n","1314/1314 [==============================] - 52s 39ms/step - loss: 4082.9221 - mae: 44.3514 - val_loss: 3378.2839 - val_mae: 43.2091\n","41.91600274936496\n","0.6371079761652828\n","0.8214068430936111\n","start group3,This is the experiment num: 1\n","\n","---------------------------------------------- domain num 0 is running----------------------------------\n","start training\n","Epoch 1/40\n","1314/1314 [==============================] - 51s 38ms/step - loss: 6529.6216 - mae: 59.5049 - val_loss: 5204.3672 - val_mae: 54.7671\n","Epoch 2/40\n","1314/1314 [==============================] - 52s 39ms/step - loss: 4821.3091 - mae: 49.4201 - val_loss: 3273.4297 - val_mae: 43.9400\n","Epoch 3/40\n","1314/1314 [==============================] - 50s 38ms/step - loss: 4249.1641 - mae: 45.4622 - val_loss: 3390.6301 - val_mae: 43.2930\n","Epoch 4/40\n","1314/1314 [==============================] - 52s 40ms/step - loss: 4218.2729 - mae: 45.3195 - val_loss: 3484.1555 - val_mae: 44.5929\n","Epoch 5/40\n","1314/1314 [==============================] - 50s 38ms/step - loss: 4204.2612 - mae: 45.2994 - val_loss: 3409.1902 - val_mae: 44.0795\n","Epoch 6/40\n","1314/1314 [==============================] - 52s 40ms/step - loss: 4203.1558 - mae: 45.2369 - val_loss: 3554.9167 - val_mae: 45.7132\n","Epoch 7/40\n","1314/1314 [==============================] - 50s 38ms/step - loss: 4184.6362 - mae: 45.1270 - val_loss: 3427.6777 - val_mae: 44.0302\n","Epoch 8/40\n","1314/1314 [==============================] - 52s 40ms/step - loss: 4175.6763 - mae: 45.0346 - val_loss: 3835.2397 - val_mae: 48.4696\n","Epoch 9/40\n","1314/1314 [==============================] - 50s 38ms/step - loss: 4171.3301 - mae: 45.0266 - val_loss: 3792.9573 - val_mae: 47.9683\n","Epoch 10/40\n","1314/1314 [==============================] - 52s 40ms/step - loss: 4168.0986 - mae: 44.9021 - val_loss: 3522.5632 - val_mae: 45.1611\n","Epoch 11/40\n","1314/1314 [==============================] - 50s 38ms/step - loss: 4169.3594 - mae: 44.8936 - val_loss: 3762.5745 - val_mae: 47.8910\n","Epoch 12/40\n","1314/1314 [==============================] - 51s 38ms/step - loss: 4154.1479 - mae: 44.8185 - val_loss: 3505.6589 - val_mae: 44.4135\n","Epoch 13/40\n","1314/1314 [==============================] - 52s 39ms/step - loss: 4147.8745 - mae: 44.8260 - val_loss: 3401.5212 - val_mae: 43.1919\n","Epoch 14/40\n","1314/1314 [==============================] - 50s 38ms/step - loss: 4147.0200 - mae: 44.8361 - val_loss: 3624.4121 - val_mae: 46.6816\n","Epoch 15/40\n","1314/1314 [==============================] - 52s 40ms/step - loss: 4151.4238 - mae: 44.9223 - val_loss: 3475.8386 - val_mae: 43.5976\n","Epoch 16/40\n","1314/1314 [==============================] - 50s 38ms/step - loss: 4138.5171 - mae: 44.6177 - val_loss: 3562.8767 - val_mae: 45.4474\n","Epoch 17/40\n","1314/1314 [==============================] - 52s 39ms/step - loss: 4136.0342 - mae: 44.7248 - val_loss: 3757.2058 - val_mae: 48.0763\n","Epoch 18/40\n","1314/1314 [==============================] - 50s 38ms/step - loss: 4136.5288 - mae: 44.7542 - val_loss: 3491.5122 - val_mae: 45.4439\n","Epoch 19/40\n","1314/1314 [==============================] - 52s 40ms/step - loss: 4139.0947 - mae: 44.7088 - val_loss: 3519.4109 - val_mae: 45.3785\n","Epoch 20/40\n","1314/1314 [==============================] - 50s 38ms/step - loss: 4135.5371 - mae: 44.6944 - val_loss: 3426.4409 - val_mae: 44.0121\n","Epoch 21/40\n","1314/1314 [==============================] - 52s 40ms/step - loss: 4141.1294 - mae: 44.7104 - val_loss: 3316.5422 - val_mae: 41.8473\n","Epoch 22/40\n","1314/1314 [==============================] - 50s 38ms/step - loss: 4124.5010 - mae: 44.6424 - val_loss: 3836.8086 - val_mae: 48.5301\n","Epoch 23/40\n","1314/1314 [==============================] - 53s 40ms/step - loss: 4114.9668 - mae: 44.5080 - val_loss: 3369.2710 - val_mae: 43.5788\n","Epoch 24/40\n","1314/1314 [==============================] - 50s 38ms/step - loss: 4114.7607 - mae: 44.5680 - val_loss: 3462.8779 - val_mae: 44.8021\n","Epoch 25/40\n","1314/1314 [==============================] - 52s 40ms/step - loss: 4114.2168 - mae: 44.5222 - val_loss: 3786.2698 - val_mae: 48.0153\n","Epoch 26/40\n","1314/1314 [==============================] - 50s 38ms/step - loss: 4109.7925 - mae: 44.5256 - val_loss: 3670.3684 - val_mae: 47.0443\n","Epoch 27/40\n","1314/1314 [==============================] - 52s 40ms/step - loss: 4091.3088 - mae: 44.4285 - val_loss: 3320.6279 - val_mae: 41.0467\n","Epoch 28/40\n","1314/1314 [==============================] - 50s 38ms/step - loss: 4102.4663 - mae: 44.5028 - val_loss: 3557.3367 - val_mae: 46.0952\n","Epoch 29/40\n","1314/1314 [==============================] - 52s 40ms/step - loss: 4105.2983 - mae: 44.4256 - val_loss: 4059.9102 - val_mae: 50.1908\n","Epoch 30/40\n","1314/1314 [==============================] - 50s 38ms/step - loss: 4095.5156 - mae: 44.3802 - val_loss: 3478.9304 - val_mae: 45.1153\n","Epoch 31/40\n","1314/1314 [==============================] - 52s 39ms/step - loss: 4093.0640 - mae: 44.5326 - val_loss: 3459.8215 - val_mae: 43.9641\n","Epoch 32/40\n","1314/1314 [==============================] - 49s 38ms/step - loss: 4096.6724 - mae: 44.4590 - val_loss: 3415.9951 - val_mae: 43.6138\n","Epoch 33/40\n","1314/1314 [==============================] - 51s 39ms/step - loss: 4074.6809 - mae: 44.3858 - val_loss: 3610.5190 - val_mae: 46.6603\n","Epoch 34/40\n","1314/1314 [==============================] - 49s 37ms/step - loss: 4097.6162 - mae: 44.5539 - val_loss: 3538.8071 - val_mae: 45.5631\n","Epoch 35/40\n","1314/1314 [==============================] - 51s 39ms/step - loss: 4086.5491 - mae: 44.3846 - val_loss: 3352.9822 - val_mae: 42.2771\n","Epoch 36/40\n","1314/1314 [==============================] - 49s 37ms/step - loss: 4086.3184 - mae: 44.3663 - val_loss: 3387.0579 - val_mae: 43.1956\n","Epoch 37/40\n","1314/1314 [==============================] - 52s 39ms/step - loss: 4091.6165 - mae: 44.5634 - val_loss: 3607.1472 - val_mae: 46.5326\n","Epoch 38/40\n","1314/1314 [==============================] - 49s 37ms/step - loss: 4068.3904 - mae: 44.2113 - val_loss: 3411.6594 - val_mae: 43.8908\n","Epoch 39/40\n","1314/1314 [==============================] - 51s 39ms/step - loss: 4080.4453 - mae: 44.2676 - val_loss: 3481.9453 - val_mae: 44.8368\n","Epoch 40/40\n","1314/1314 [==============================] - 49s 37ms/step - loss: 4075.1165 - mae: 44.2416 - val_loss: 3528.2405 - val_mae: 45.4410\n","43.463596227165866\n","0.7519324990767366\n","0.8533837186193917\n","start group3,This is the experiment num: 2\n","\n","---------------------------------------------- domain num 0 is running----------------------------------\n","start training\n","Epoch 1/40\n","1314/1314 [==============================] - 54s 40ms/step - loss: 6544.6289 - mae: 59.4026 - val_loss: 3722.0278 - val_mae: 41.0825\n","Epoch 2/40\n","1314/1314 [==============================] - 51s 38ms/step - loss: 4828.0176 - mae: 49.5760 - val_loss: 3296.9075 - val_mae: 37.5065\n","Epoch 3/40\n","1314/1314 [==============================] - 53s 41ms/step - loss: 4248.8828 - mae: 45.4039 - val_loss: 3435.3958 - val_mae: 41.8504\n","Epoch 4/40\n","1314/1314 [==============================] - 51s 39ms/step - loss: 4224.7368 - mae: 45.2661 - val_loss: 3342.0083 - val_mae: 42.5628\n","Epoch 5/40\n","1314/1314 [==============================] - 53s 41ms/step - loss: 4197.7598 - mae: 45.0750 - val_loss: 3370.7021 - val_mae: 40.0303\n","Epoch 6/40\n","1314/1314 [==============================] - 52s 40ms/step - loss: 4199.6328 - mae: 45.1444 - val_loss: 3530.6846 - val_mae: 45.6560\n","Epoch 7/40\n","1314/1314 [==============================] - 54s 41ms/step - loss: 4189.7061 - mae: 45.0986 - val_loss: 4135.6729 - val_mae: 50.1472\n","Epoch 8/40\n","1314/1314 [==============================] - 52s 40ms/step - loss: 4179.6792 - mae: 44.9792 - val_loss: 3501.6763 - val_mae: 45.1597\n","Epoch 9/40\n","1314/1314 [==============================] - 53s 41ms/step - loss: 4170.9531 - mae: 44.8566 - val_loss: 3616.4856 - val_mae: 45.7100\n","Epoch 10/40\n","1314/1314 [==============================] - 51s 39ms/step - loss: 4179.0381 - mae: 44.9429 - val_loss: 3541.5996 - val_mae: 45.4951\n","Epoch 11/40\n","1314/1314 [==============================] - 53s 41ms/step - loss: 4161.9160 - mae: 44.9690 - val_loss: 3433.1511 - val_mae: 44.4045\n","Epoch 12/40\n","1314/1314 [==============================] - 51s 39ms/step - loss: 4166.7881 - mae: 44.7940 - val_loss: 3863.1301 - val_mae: 48.6400\n","Epoch 13/40\n","1314/1314 [==============================] - 53s 41ms/step - loss: 4167.1357 - mae: 44.8560 - val_loss: 3513.9263 - val_mae: 45.3673\n","Epoch 14/40\n","1314/1314 [==============================] - 51s 39ms/step - loss: 4168.8252 - mae: 44.9081 - val_loss: 3538.3081 - val_mae: 44.7219\n","Epoch 15/40\n","1314/1314 [==============================] - 53s 41ms/step - loss: 4159.5215 - mae: 44.7602 - val_loss: 3729.2849 - val_mae: 47.4470\n","Epoch 16/40\n","1314/1314 [==============================] - 51s 39ms/step - loss: 4152.3188 - mae: 44.7585 - val_loss: 3846.5686 - val_mae: 48.5300\n","Epoch 17/40\n","1314/1314 [==============================] - 53s 40ms/step - loss: 4161.4277 - mae: 44.8558 - val_loss: 3746.3645 - val_mae: 47.7722\n","Epoch 18/40\n","1314/1314 [==============================] - 53s 41ms/step - loss: 4144.4155 - mae: 44.6722 - val_loss: 3545.1343 - val_mae: 45.7701\n","Epoch 19/40\n","1314/1314 [==============================] - 51s 39ms/step - loss: 4138.7080 - mae: 44.5903 - val_loss: 3584.0063 - val_mae: 46.1345\n","Epoch 20/40\n","1314/1314 [==============================] - 53s 41ms/step - loss: 4141.4961 - mae: 44.7023 - val_loss: 3379.0461 - val_mae: 43.0842\n","Epoch 21/40\n","1314/1314 [==============================] - 51s 39ms/step - loss: 4127.0469 - mae: 44.5615 - val_loss: 3436.2866 - val_mae: 44.4762\n","Epoch 22/40\n","1314/1314 [==============================] - 53s 41ms/step - loss: 4133.0215 - mae: 44.6467 - val_loss: 3677.7996 - val_mae: 47.3200\n","Epoch 23/40\n","1314/1314 [==============================] - 52s 39ms/step - loss: 4129.0659 - mae: 44.5400 - val_loss: 3709.6055 - val_mae: 47.5491\n","Epoch 24/40\n","1314/1314 [==============================] - 54s 41ms/step - loss: 4128.1465 - mae: 44.6214 - val_loss: 3681.7134 - val_mae: 46.6315\n","Epoch 25/40\n","1314/1314 [==============================] - 52s 40ms/step - loss: 4117.4419 - mae: 44.5621 - val_loss: 3438.4087 - val_mae: 43.5941\n","Epoch 26/40\n","1314/1314 [==============================] - 54s 41ms/step - loss: 4114.0396 - mae: 44.3814 - val_loss: 3482.8870 - val_mae: 44.7470\n","Epoch 27/40\n","1314/1314 [==============================] - 52s 40ms/step - loss: 4113.6416 - mae: 44.5870 - val_loss: 3617.2888 - val_mae: 46.3881\n","Epoch 28/40\n","1314/1314 [==============================] - 54s 41ms/step - loss: 4110.9600 - mae: 44.3595 - val_loss: 3446.0564 - val_mae: 44.3678\n","Epoch 29/40\n","1314/1314 [==============================] - 53s 40ms/step - loss: 4106.0664 - mae: 44.4310 - val_loss: 3539.2507 - val_mae: 45.7350\n","Epoch 30/40\n","1314/1314 [==============================] - 55s 42ms/step - loss: 4097.6699 - mae: 44.3415 - val_loss: 3483.6919 - val_mae: 45.5265\n","Epoch 31/40\n","1314/1314 [==============================] - 53s 40ms/step - loss: 4112.0752 - mae: 44.4545 - val_loss: 3487.0654 - val_mae: 44.6976\n","Epoch 32/40\n","1314/1314 [==============================] - 58s 44ms/step - loss: 4088.4648 - mae: 44.3205 - val_loss: 3827.1763 - val_mae: 48.5071\n","Epoch 33/40\n","1314/1314 [==============================] - 56s 42ms/step - loss: 4092.6631 - mae: 44.4808 - val_loss: 3490.4961 - val_mae: 44.9238\n","Epoch 34/40\n","1314/1314 [==============================] - 54s 41ms/step - loss: 4094.3181 - mae: 44.3459 - val_loss: 3470.4314 - val_mae: 45.1727\n","Epoch 35/40\n","1314/1314 [==============================] - 56s 43ms/step - loss: 4079.8081 - mae: 44.3330 - val_loss: 3446.5586 - val_mae: 45.0778\n","Epoch 36/40\n","1314/1314 [==============================] - 54s 41ms/step - loss: 4094.8569 - mae: 44.3882 - val_loss: 3492.1233 - val_mae: 45.4560\n","Epoch 37/40\n","1314/1314 [==============================] - 56s 42ms/step - loss: 4081.3298 - mae: 44.3171 - val_loss: 3478.1282 - val_mae: 45.0828\n","Epoch 38/40\n","1314/1314 [==============================] - 53s 40ms/step - loss: 4079.6003 - mae: 44.1492 - val_loss: 3664.2622 - val_mae: 47.3433\n","Epoch 39/40\n","1314/1314 [==============================] - 55s 42ms/step - loss: 4085.1094 - mae: 44.2873 - val_loss: 3621.1860 - val_mae: 46.5628\n","Epoch 40/40\n","1314/1314 [==============================] - 53s 40ms/step - loss: 4086.7087 - mae: 44.3291 - val_loss: 3530.8296 - val_mae: 45.6111\n","43.05866090324366\n","0.732576776088932\n","0.8490416339379068\n","start group3,This is the experiment num: 3\n","\n","---------------------------------------------- domain num 0 is running----------------------------------\n","start training\n","Epoch 1/40\n","1314/1314 [==============================] - 53s 39ms/step - loss: 6508.7173 - mae: 59.2907 - val_loss: 3182.7712 - val_mae: 37.8995\n","Epoch 2/40\n","1314/1314 [==============================] - 56s 43ms/step - loss: 4762.9844 - mae: 49.0525 - val_loss: 3209.0005 - val_mae: 42.2331\n","Epoch 3/40\n","1314/1314 [==============================] - 55s 42ms/step - loss: 4245.3491 - mae: 45.4519 - val_loss: 3429.8115 - val_mae: 42.5186\n","Epoch 4/40\n","1314/1314 [==============================] - 54s 41ms/step - loss: 4218.9585 - mae: 45.3132 - val_loss: 3698.2732 - val_mae: 47.4488\n","Epoch 5/40\n","1314/1314 [==============================] - 56s 42ms/step - loss: 4206.0576 - mae: 45.2596 - val_loss: 3532.6472 - val_mae: 46.1545\n","Epoch 6/40\n","1314/1314 [==============================] - 54s 41ms/step - loss: 4202.8330 - mae: 45.1817 - val_loss: 3505.2800 - val_mae: 45.5083\n","Epoch 7/40\n","1314/1314 [==============================] - 56s 43ms/step - loss: 4200.2944 - mae: 45.1554 - val_loss: 3389.3943 - val_mae: 43.6598\n","Epoch 8/40\n","1314/1314 [==============================] - 54s 41ms/step - loss: 4176.0464 - mae: 44.9697 - val_loss: 3433.6521 - val_mae: 44.9075\n","Epoch 9/40\n","1314/1314 [==============================] - 57s 44ms/step - loss: 4174.8428 - mae: 45.0193 - val_loss: 3387.2595 - val_mae: 41.6368\n","Epoch 10/40\n","1314/1314 [==============================] - 54s 41ms/step - loss: 4182.4355 - mae: 45.0954 - val_loss: 3366.0962 - val_mae: 43.3415\n","Epoch 11/40\n","1314/1314 [==============================] - 57s 43ms/step - loss: 4173.9116 - mae: 44.9399 - val_loss: 3339.5530 - val_mae: 43.0827\n","Epoch 12/40\n","1314/1314 [==============================] - 54s 41ms/step - loss: 4166.1426 - mae: 44.9446 - val_loss: 3363.7063 - val_mae: 42.6694\n","Epoch 13/40\n","1314/1314 [==============================] - 56s 42ms/step - loss: 4150.7588 - mae: 44.8848 - val_loss: 3682.4822 - val_mae: 47.2289\n","Epoch 14/40\n","1314/1314 [==============================] - 54s 41ms/step - loss: 4157.3584 - mae: 44.8528 - val_loss: 3309.3142 - val_mae: 42.5226\n","Epoch 15/40\n","1314/1314 [==============================] - 56s 43ms/step - loss: 4148.2329 - mae: 44.7991 - val_loss: 3430.7529 - val_mae: 44.9709\n","Epoch 16/40\n","1314/1314 [==============================] - 56s 43ms/step - loss: 4146.4736 - mae: 44.6443 - val_loss: 3522.5137 - val_mae: 44.9195\n","Epoch 17/40\n","1314/1314 [==============================] - 55s 42ms/step - loss: 4135.3369 - mae: 44.6274 - val_loss: 3754.8147 - val_mae: 47.8112\n","Epoch 18/40\n","1314/1314 [==============================] - 57s 43ms/step - loss: 4152.3325 - mae: 44.8725 - val_loss: 3656.5366 - val_mae: 47.1896\n","Epoch 19/40\n","1314/1314 [==============================] - 55s 42ms/step - loss: 4146.1738 - mae: 44.7313 - val_loss: 3323.6929 - val_mae: 40.3133\n","Epoch 20/40\n","1314/1314 [==============================] - 57s 43ms/step - loss: 4143.3281 - mae: 44.7151 - val_loss: 3505.5615 - val_mae: 45.4852\n","Epoch 21/40\n","1314/1314 [==============================] - 54s 41ms/step - loss: 4123.8979 - mae: 44.5401 - val_loss: 3698.8857 - val_mae: 47.3088\n","Epoch 22/40\n","1314/1314 [==============================] - 57s 43ms/step - loss: 4129.2544 - mae: 44.6651 - val_loss: 3657.2393 - val_mae: 47.0843\n","Epoch 23/40\n","1314/1314 [==============================] - 55s 42ms/step - loss: 4120.2778 - mae: 44.5575 - val_loss: 3657.0137 - val_mae: 46.9210\n","Epoch 24/40\n","1314/1314 [==============================] - 57s 43ms/step - loss: 4119.9883 - mae: 44.6300 - val_loss: 3523.1541 - val_mae: 45.8071\n","Epoch 25/40\n","1314/1314 [==============================] - 55s 42ms/step - loss: 4114.8428 - mae: 44.5516 - val_loss: 3542.3420 - val_mae: 45.7275\n","Epoch 26/40\n","1314/1314 [==============================] - 57s 43ms/step - loss: 4119.4712 - mae: 44.5537 - val_loss: 3604.9531 - val_mae: 46.6808\n","Epoch 27/40\n","1314/1314 [==============================] - 56s 42ms/step - loss: 4108.5791 - mae: 44.4801 - val_loss: 3687.5359 - val_mae: 46.5402\n","Epoch 28/40\n","1314/1314 [==============================] - 58s 44ms/step - loss: 4106.6387 - mae: 44.4425 - val_loss: 3414.4893 - val_mae: 44.0313\n","Epoch 29/40\n","1314/1314 [==============================] - 55s 42ms/step - loss: 4096.2188 - mae: 44.4298 - val_loss: 3536.4080 - val_mae: 45.9262\n","Epoch 30/40\n","1314/1314 [==============================] - 58s 44ms/step - loss: 4105.2271 - mae: 44.5133 - val_loss: 3340.5088 - val_mae: 42.7953\n","Epoch 31/40\n","1314/1314 [==============================] - 56s 43ms/step - loss: 4087.9790 - mae: 44.2472 - val_loss: 3365.5955 - val_mae: 42.5923\n","Epoch 32/40\n","1314/1314 [==============================] - 58s 44ms/step - loss: 4107.3340 - mae: 44.3975 - val_loss: 3461.7263 - val_mae: 44.3458\n","Epoch 33/40\n","1314/1314 [==============================] - 55s 42ms/step - loss: 4091.0764 - mae: 44.3250 - val_loss: 3786.6648 - val_mae: 48.2958\n","Epoch 34/40\n","1314/1314 [==============================] - 57s 43ms/step - loss: 4074.5850 - mae: 44.4079 - val_loss: 3446.2693 - val_mae: 44.7243\n","Epoch 35/40\n","1314/1314 [==============================] - 54s 41ms/step - loss: 4089.3181 - mae: 44.3541 - val_loss: 3749.0823 - val_mae: 47.5140\n","Epoch 36/40\n","1314/1314 [==============================] - 57s 43ms/step - loss: 4070.2681 - mae: 44.2282 - val_loss: 3458.8298 - val_mae: 44.8611\n","Epoch 37/40\n","1314/1314 [==============================] - 54s 41ms/step - loss: 4086.9893 - mae: 44.3283 - val_loss: 3314.2703 - val_mae: 41.2491\n","Epoch 38/40\n","1314/1314 [==============================] - 57s 43ms/step - loss: 4069.7070 - mae: 44.1825 - val_loss: 3311.2383 - val_mae: 39.4857\n","Epoch 39/40\n","1314/1314 [==============================] - 55s 42ms/step - loss: 4071.1531 - mae: 44.3012 - val_loss: 3448.7668 - val_mae: 44.1004\n","Epoch 40/40\n","1314/1314 [==============================] - 56s 43ms/step - loss: 4060.8489 - mae: 44.1997 - val_loss: 3457.7705 - val_mae: 43.9806\n","42.23548481912016\n","0.7028886731149867\n","0.840148988385417\n","start group3,This is the experiment num: 4\n","\n","---------------------------------------------- domain num 0 is running----------------------------------\n","start training\n","Epoch 1/40\n","1314/1314 [==============================] - 55s 41ms/step - loss: 6525.3486 - mae: 59.6519 - val_loss: 3443.0007 - val_mae: 37.1586\n","Epoch 2/40\n","1314/1314 [==============================] - 53s 40ms/step - loss: 4827.5122 - mae: 49.5858 - val_loss: 3872.5662 - val_mae: 48.7283\n","Epoch 3/40\n","1314/1314 [==============================] - 55s 42ms/step - loss: 4240.8262 - mae: 45.4046 - val_loss: 3826.1396 - val_mae: 48.1808\n","Epoch 4/40\n","1314/1314 [==============================] - 53s 41ms/step - loss: 4210.2891 - mae: 45.3246 - val_loss: 3883.7988 - val_mae: 48.9556\n","Epoch 5/40\n","1314/1314 [==============================] - 55s 42ms/step - loss: 4191.2637 - mae: 45.0404 - val_loss: 3531.4939 - val_mae: 45.8142\n","Epoch 6/40\n","1314/1314 [==============================] - 53s 41ms/step - loss: 4188.3618 - mae: 45.0960 - val_loss: 3834.1555 - val_mae: 48.2161\n","Epoch 7/40\n","1314/1314 [==============================] - 56s 42ms/step - loss: 4193.7861 - mae: 45.0848 - val_loss: 3334.9893 - val_mae: 40.5027\n","Epoch 8/40\n","1314/1314 [==============================] - 54s 41ms/step - loss: 4185.7422 - mae: 44.9949 - val_loss: 3575.1477 - val_mae: 45.6420\n","Epoch 9/40\n","1314/1314 [==============================] - 56s 42ms/step - loss: 4192.0059 - mae: 45.1413 - val_loss: 3469.3496 - val_mae: 44.2841\n","Epoch 10/40\n","1314/1314 [==============================] - 54s 41ms/step - loss: 4174.1382 - mae: 44.9219 - val_loss: 3433.0540 - val_mae: 43.3040\n","Epoch 11/40\n","1314/1314 [==============================] - 56s 43ms/step - loss: 4167.5815 - mae: 44.8535 - val_loss: 3318.8101 - val_mae: 43.1024\n","Epoch 12/40\n","1314/1314 [==============================] - 54s 41ms/step - loss: 4173.6621 - mae: 44.8452 - val_loss: 4166.5010 - val_mae: 50.8513\n","Epoch 13/40\n","1314/1314 [==============================] - 56s 42ms/step - loss: 4152.7124 - mae: 44.7680 - val_loss: 3485.3057 - val_mae: 45.1167\n","Epoch 14/40\n","1314/1314 [==============================] - 54s 41ms/step - loss: 4150.7729 - mae: 44.8416 - val_loss: 3398.2922 - val_mae: 40.3703\n","Epoch 15/40\n","1314/1314 [==============================] - 57s 43ms/step - loss: 4144.1909 - mae: 44.7825 - val_loss: 3491.6504 - val_mae: 44.7852\n","Epoch 16/40\n","1314/1314 [==============================] - 54s 41ms/step - loss: 4162.2515 - mae: 44.8642 - val_loss: 3445.3909 - val_mae: 42.9475\n","Epoch 17/40\n","1314/1314 [==============================] - 57s 43ms/step - loss: 4142.7612 - mae: 44.6469 - val_loss: 3617.4365 - val_mae: 46.8819\n","Epoch 18/40\n","1314/1314 [==============================] - 55s 42ms/step - loss: 4146.5361 - mae: 44.7918 - val_loss: 3589.3950 - val_mae: 45.9285\n","Epoch 19/40\n","1314/1314 [==============================] - 56s 42ms/step - loss: 4134.3354 - mae: 44.6539 - val_loss: 3479.3979 - val_mae: 44.9923\n","Epoch 20/40\n","1314/1314 [==============================] - 54s 41ms/step - loss: 4131.0718 - mae: 44.5961 - val_loss: 3464.4236 - val_mae: 45.2357\n","Epoch 21/40\n","1314/1314 [==============================] - 56s 42ms/step - loss: 4128.8345 - mae: 44.5715 - val_loss: 3788.8645 - val_mae: 48.1388\n","Epoch 22/40\n","1314/1314 [==============================] - 55s 42ms/step - loss: 4130.1685 - mae: 44.6049 - val_loss: 3478.1008 - val_mae: 43.9780\n","Epoch 23/40\n","1314/1314 [==============================] - 57s 43ms/step - loss: 4115.5405 - mae: 44.5740 - val_loss: 3395.6743 - val_mae: 42.2623\n","Epoch 24/40\n","1314/1314 [==============================] - 55s 42ms/step - loss: 4119.0864 - mae: 44.6098 - val_loss: 3723.8679 - val_mae: 47.7311\n","Epoch 25/40\n","1314/1314 [==============================] - 56s 43ms/step - loss: 4111.5996 - mae: 44.5847 - val_loss: 3604.9265 - val_mae: 46.2171\n","Epoch 26/40\n","1314/1314 [==============================] - 53s 41ms/step - loss: 4118.2236 - mae: 44.5219 - val_loss: 3520.9148 - val_mae: 45.2679\n","Epoch 27/40\n","1314/1314 [==============================] - 56s 43ms/step - loss: 4110.4604 - mae: 44.4671 - val_loss: 3604.4297 - val_mae: 44.9424\n","Epoch 28/40\n","1314/1314 [==============================] - 53s 40ms/step - loss: 4102.9888 - mae: 44.4828 - val_loss: 3402.5996 - val_mae: 43.6473\n","Epoch 29/40\n","1314/1314 [==============================] - 55s 42ms/step - loss: 4102.4434 - mae: 44.4700 - val_loss: 3780.7390 - val_mae: 47.9400\n","Epoch 30/40\n","1314/1314 [==============================] - 53s 40ms/step - loss: 4087.0691 - mae: 44.3900 - val_loss: 3414.7004 - val_mae: 44.0856\n","Epoch 31/40\n","1314/1314 [==============================] - 55s 42ms/step - loss: 4091.5337 - mae: 44.3322 - val_loss: 3372.5852 - val_mae: 42.5472\n","Epoch 32/40\n","1314/1314 [==============================] - 53s 40ms/step - loss: 4097.9214 - mae: 44.3620 - val_loss: 3809.2466 - val_mae: 48.6081\n","Epoch 33/40\n","1314/1314 [==============================] - 55s 42ms/step - loss: 4094.6001 - mae: 44.4717 - val_loss: 3505.4175 - val_mae: 44.4782\n","Epoch 34/40\n","1314/1314 [==============================] - 53s 40ms/step - loss: 4073.8860 - mae: 44.2955 - val_loss: 3574.3237 - val_mae: 46.4392\n","Epoch 35/40\n","1314/1314 [==============================] - 54s 41ms/step - loss: 4086.2480 - mae: 44.4451 - val_loss: 3406.5571 - val_mae: 44.3104\n","Epoch 36/40\n","1314/1314 [==============================] - 53s 40ms/step - loss: 4088.1814 - mae: 44.3540 - val_loss: 3539.6750 - val_mae: 45.5688\n","Epoch 37/40\n","1314/1314 [==============================] - 54s 41ms/step - loss: 4076.6699 - mae: 44.2756 - val_loss: 3440.1272 - val_mae: 44.4349\n","Epoch 38/40\n","1314/1314 [==============================] - 53s 40ms/step - loss: 4079.6562 - mae: 44.1989 - val_loss: 3743.0134 - val_mae: 47.8420\n","Epoch 39/40\n","1314/1314 [==============================] - 55s 42ms/step - loss: 4064.6860 - mae: 44.2107 - val_loss: 3473.9202 - val_mae: 43.9602\n","Epoch 40/40\n","1314/1314 [==============================] - 53s 41ms/step - loss: 4073.8757 - mae: 44.2773 - val_loss: 3413.5522 - val_mae: 43.9256\n","41.43635337036872\n","0.6278727494159582\n","0.8182413316402398\n","start group4,This is the experiment num: 0\n","\n","---------------------------------------------- domain num 0 is running----------------------------------\n","start training\n","Epoch 1/40\n","1690/1690 [==============================] - 68s 40ms/step - loss: 5293.0376 - mae: 53.1248 - val_loss: 2635.5278 - val_mae: 36.2368\n","Epoch 2/40\n","1690/1690 [==============================] - 70s 41ms/step - loss: 3818.9980 - mae: 44.4249 - val_loss: 2972.9846 - val_mae: 44.9499\n","Epoch 3/40\n","1690/1690 [==============================] - 71s 42ms/step - loss: 3689.3035 - mae: 43.8927 - val_loss: 2619.4309 - val_mae: 39.0809\n","Epoch 4/40\n","1690/1690 [==============================] - 69s 41ms/step - loss: 3677.3645 - mae: 43.6959 - val_loss: 2830.5815 - val_mae: 42.6697\n","Epoch 5/40\n","1690/1690 [==============================] - 71s 42ms/step - loss: 3669.9553 - mae: 43.5882 - val_loss: 3227.7444 - val_mae: 48.2335\n","Epoch 6/40\n","1690/1690 [==============================] - 71s 42ms/step - loss: 3666.2222 - mae: 43.5896 - val_loss: 2838.0508 - val_mae: 43.2635\n","Epoch 7/40\n","1690/1690 [==============================] - 69s 41ms/step - loss: 3660.8992 - mae: 43.4641 - val_loss: 3010.2029 - val_mae: 45.1809\n","Epoch 8/40\n","1690/1690 [==============================] - 70s 41ms/step - loss: 3657.3225 - mae: 43.4962 - val_loss: 2817.8538 - val_mae: 42.5182\n","Epoch 9/40\n","1690/1690 [==============================] - 69s 41ms/step - loss: 3653.8608 - mae: 43.4112 - val_loss: 3190.9551 - val_mae: 47.2734\n","Epoch 10/40\n","1690/1690 [==============================] - 65s 38ms/step - loss: 3654.2939 - mae: 43.4953 - val_loss: 2711.3394 - val_mae: 42.1498\n","Epoch 11/40\n","1690/1690 [==============================] - 67s 39ms/step - loss: 3644.2478 - mae: 43.3878 - val_loss: 2934.8828 - val_mae: 44.7515\n","Epoch 12/40\n","1690/1690 [==============================] - 64s 38ms/step - loss: 3651.2781 - mae: 43.4871 - val_loss: 3052.3645 - val_mae: 45.9295\n","Epoch 13/40\n","1690/1690 [==============================] - 66s 39ms/step - loss: 3638.9070 - mae: 43.3594 - val_loss: 2883.6060 - val_mae: 44.4951\n","Epoch 14/40\n","1690/1690 [==============================] - 67s 39ms/step - loss: 3639.5615 - mae: 43.4068 - val_loss: 2753.5100 - val_mae: 42.0052\n","Epoch 15/40\n","1690/1690 [==============================] - 64s 38ms/step - loss: 3635.5178 - mae: 43.3823 - val_loss: 2614.1487 - val_mae: 38.5766\n","Epoch 16/40\n","1690/1690 [==============================] - 66s 39ms/step - loss: 3634.3972 - mae: 43.3598 - val_loss: 3207.2874 - val_mae: 47.6072\n","Epoch 17/40\n","1690/1690 [==============================] - 64s 38ms/step - loss: 3620.1707 - mae: 43.2417 - val_loss: 2930.1799 - val_mae: 44.9424\n","Epoch 18/40\n","1690/1690 [==============================] - 66s 39ms/step - loss: 3629.3201 - mae: 43.2983 - val_loss: 2969.9377 - val_mae: 45.0442\n","Epoch 19/40\n","1690/1690 [==============================] - 66s 39ms/step - loss: 3615.4846 - mae: 43.2677 - val_loss: 2815.3450 - val_mae: 43.5176\n","Epoch 20/40\n","1690/1690 [==============================] - 64s 38ms/step - loss: 3613.1748 - mae: 43.1879 - val_loss: 3023.1912 - val_mae: 45.7167\n","Epoch 21/40\n","1690/1690 [==============================] - 67s 39ms/step - loss: 3613.6794 - mae: 43.2097 - val_loss: 3146.0527 - val_mae: 47.0832\n","Epoch 22/40\n","1690/1690 [==============================] - 64s 38ms/step - loss: 3603.5105 - mae: 43.1096 - val_loss: 2954.8938 - val_mae: 44.3923\n","Epoch 23/40\n","1690/1690 [==============================] - 67s 39ms/step - loss: 3601.3821 - mae: 43.1574 - val_loss: 2721.7151 - val_mae: 41.3492\n","Epoch 24/40\n","1690/1690 [==============================] - 64s 38ms/step - loss: 3592.5740 - mae: 43.0095 - val_loss: 2942.2627 - val_mae: 43.2376\n","Epoch 25/40\n","1690/1690 [==============================] - 67s 39ms/step - loss: 3592.7090 - mae: 43.1182 - val_loss: 2986.5723 - val_mae: 45.2819\n","Epoch 26/40\n","1690/1690 [==============================] - 67s 39ms/step - loss: 3588.7188 - mae: 43.0307 - val_loss: 2927.9207 - val_mae: 43.8594\n","Epoch 27/40\n","1690/1690 [==============================] - 65s 38ms/step - loss: 3577.9094 - mae: 42.9238 - val_loss: 2923.6162 - val_mae: 43.6647\n","Epoch 28/40\n","1690/1690 [==============================] - 66s 39ms/step - loss: 3589.6040 - mae: 43.0695 - val_loss: 2884.0347 - val_mae: 43.6159\n","Epoch 29/40\n","1690/1690 [==============================] - 64s 38ms/step - loss: 3584.8403 - mae: 43.0646 - val_loss: 2806.7578 - val_mae: 42.9017\n","Epoch 30/40\n","1690/1690 [==============================] - 67s 39ms/step - loss: 3576.4971 - mae: 42.9568 - val_loss: 2834.4597 - val_mae: 43.4194\n","Epoch 31/40\n","1690/1690 [==============================] - 65s 38ms/step - loss: 3572.3230 - mae: 42.9424 - val_loss: 2824.5581 - val_mae: 43.7023\n","Epoch 32/40\n","1690/1690 [==============================] - 67s 39ms/step - loss: 3564.2083 - mae: 42.8178 - val_loss: 2923.8782 - val_mae: 43.8643\n","Epoch 33/40\n","1690/1690 [==============================] - 67s 40ms/step - loss: 3568.6577 - mae: 42.8994 - val_loss: 2976.7651 - val_mae: 44.8941\n","Epoch 34/40\n","1690/1690 [==============================] - 65s 39ms/step - loss: 3561.1721 - mae: 42.9305 - val_loss: 2818.7134 - val_mae: 41.9626\n","Epoch 35/40\n","1690/1690 [==============================] - 68s 40ms/step - loss: 3560.3215 - mae: 42.9087 - val_loss: 2688.5205 - val_mae: 41.2356\n","Epoch 36/40\n","1690/1690 [==============================] - 65s 38ms/step - loss: 3563.7026 - mae: 42.9058 - val_loss: 2839.0867 - val_mae: 43.3814\n","Epoch 37/40\n","1690/1690 [==============================] - 68s 40ms/step - loss: 3545.7263 - mae: 42.8138 - val_loss: 2890.7671 - val_mae: 44.0029\n","Epoch 38/40\n","1690/1690 [==============================] - 67s 40ms/step - loss: 3559.9282 - mae: 42.9195 - val_loss: 2703.4097 - val_mae: 40.9581\n","Epoch 39/40\n","1690/1690 [==============================] - 66s 39ms/step - loss: 3549.6355 - mae: 42.8164 - val_loss: 2768.3779 - val_mae: 41.5441\n","Epoch 40/40\n","1690/1690 [==============================] - 68s 40ms/step - loss: 3552.4731 - mae: 42.7851 - val_loss: 2846.9832 - val_mae: 44.2030\n","42.58764794187127\n","0.5469962997426088\n","0.7895113849718228\n","start group4,This is the experiment num: 1\n","\n","---------------------------------------------- domain num 0 is running----------------------------------\n","start training\n","Epoch 1/40\n","1690/1690 [==============================] - 64s 37ms/step - loss: 5351.2710 - mae: 53.5422 - val_loss: 2755.3455 - val_mae: 36.3698\n","Epoch 2/40\n","1690/1690 [==============================] - 63s 37ms/step - loss: 3831.0208 - mae: 44.3771 - val_loss: 2605.9165 - val_mae: 38.5648\n","Epoch 3/40\n","1690/1690 [==============================] - 63s 37ms/step - loss: 3680.8184 - mae: 43.7334 - val_loss: 2614.2566 - val_mae: 38.3011\n","Epoch 4/40\n","1690/1690 [==============================] - 61s 36ms/step - loss: 3671.8657 - mae: 43.6122 - val_loss: 2884.1113 - val_mae: 44.1659\n","Epoch 5/40\n","1690/1690 [==============================] - 63s 37ms/step - loss: 3666.0576 - mae: 43.5679 - val_loss: 2710.2637 - val_mae: 40.5423\n","Epoch 6/40\n","1690/1690 [==============================] - 61s 36ms/step - loss: 3667.0007 - mae: 43.6490 - val_loss: 2852.6768 - val_mae: 43.5310\n","Epoch 7/40\n","1690/1690 [==============================] - 63s 37ms/step - loss: 3660.5989 - mae: 43.5226 - val_loss: 2747.8655 - val_mae: 42.3135\n","Epoch 8/40\n","1690/1690 [==============================] - 61s 36ms/step - loss: 3648.9561 - mae: 43.4802 - val_loss: 2731.1904 - val_mae: 41.6384\n","Epoch 9/40\n","1690/1690 [==============================] - 62s 37ms/step - loss: 3644.7336 - mae: 43.3984 - val_loss: 3066.0662 - val_mae: 46.5577\n","Epoch 10/40\n","1690/1690 [==============================] - 60s 36ms/step - loss: 3652.5691 - mae: 43.4613 - val_loss: 2913.1208 - val_mae: 44.6807\n","Epoch 11/40\n","1690/1690 [==============================] - 62s 37ms/step - loss: 3645.9951 - mae: 43.5023 - val_loss: 2838.6799 - val_mae: 43.4134\n","Epoch 12/40\n","1690/1690 [==============================] - 59s 35ms/step - loss: 3641.0962 - mae: 43.3728 - val_loss: 2865.8538 - val_mae: 43.1314\n","Epoch 13/40\n","1690/1690 [==============================] - 62s 36ms/step - loss: 3635.5205 - mae: 43.3633 - val_loss: 2865.7253 - val_mae: 44.0712\n","Epoch 14/40\n","1690/1690 [==============================] - 60s 35ms/step - loss: 3628.9426 - mae: 43.3217 - val_loss: 2783.8757 - val_mae: 42.6256\n","Epoch 15/40\n","1690/1690 [==============================] - 61s 36ms/step - loss: 3625.5522 - mae: 43.2662 - val_loss: 2866.0903 - val_mae: 43.9759\n","Epoch 16/40\n","1690/1690 [==============================] - 59s 35ms/step - loss: 3630.2393 - mae: 43.3131 - val_loss: 2990.2620 - val_mae: 45.2894\n","Epoch 17/40\n","1690/1690 [==============================] - 62s 37ms/step - loss: 3621.1316 - mae: 43.2501 - val_loss: 2917.0942 - val_mae: 43.8824\n","Epoch 18/40\n","1690/1690 [==============================] - 61s 36ms/step - loss: 3618.6301 - mae: 43.2465 - val_loss: 2796.5906 - val_mae: 42.7208\n","Epoch 19/40\n","1690/1690 [==============================] - 62s 37ms/step - loss: 3611.4277 - mae: 43.1939 - val_loss: 2796.1614 - val_mae: 43.2624\n","Epoch 20/40\n","1690/1690 [==============================] - 62s 37ms/step - loss: 3612.5322 - mae: 43.2625 - val_loss: 2980.7114 - val_mae: 45.0737\n","Epoch 21/40\n","1690/1690 [==============================] - 60s 35ms/step - loss: 3606.5173 - mae: 43.2014 - val_loss: 2700.2605 - val_mae: 40.4489\n","Epoch 22/40\n","1690/1690 [==============================] - 62s 37ms/step - loss: 3600.2048 - mae: 43.1216 - val_loss: 3010.3330 - val_mae: 45.8933\n","Epoch 23/40\n","1690/1690 [==============================] - 60s 36ms/step - loss: 3585.1819 - mae: 43.0674 - val_loss: 2689.6086 - val_mae: 41.4628\n","Epoch 24/40\n","1690/1690 [==============================] - 62s 37ms/step - loss: 3586.6970 - mae: 42.9815 - val_loss: 2730.7236 - val_mae: 42.1833\n","Epoch 25/40\n","1690/1690 [==============================] - 60s 35ms/step - loss: 3585.0662 - mae: 43.0017 - val_loss: 2880.3743 - val_mae: 44.6723\n","Epoch 26/40\n","1690/1690 [==============================] - 62s 37ms/step - loss: 3588.6248 - mae: 43.0926 - val_loss: 2862.2922 - val_mae: 44.1185\n","Epoch 27/40\n","1690/1690 [==============================] - 60s 36ms/step - loss: 3582.3699 - mae: 43.0101 - val_loss: 2887.4033 - val_mae: 44.6481\n","Epoch 28/40\n","1690/1690 [==============================] - 62s 37ms/step - loss: 3579.4602 - mae: 42.9573 - val_loss: 3027.3882 - val_mae: 45.5514\n","Epoch 29/40\n","1690/1690 [==============================] - 61s 36ms/step - loss: 3576.3718 - mae: 42.9470 - val_loss: 2981.9478 - val_mae: 44.9863\n","Epoch 30/40\n","1690/1690 [==============================] - 66s 39ms/step - loss: 3570.4026 - mae: 42.9011 - val_loss: 2625.7483 - val_mae: 39.8683\n","Epoch 31/40\n","1690/1690 [==============================] - 61s 36ms/step - loss: 3568.6858 - mae: 42.8619 - val_loss: 2835.3994 - val_mae: 42.7016\n","Epoch 32/40\n","1690/1690 [==============================] - 62s 37ms/step - loss: 3561.6587 - mae: 42.8643 - val_loss: 2919.9888 - val_mae: 43.2391\n","Epoch 33/40\n","1690/1690 [==============================] - 61s 36ms/step - loss: 3559.0684 - mae: 42.7917 - val_loss: 2745.2856 - val_mae: 41.6663\n","Epoch 34/40\n","1690/1690 [==============================] - 62s 37ms/step - loss: 3554.9626 - mae: 42.8010 - val_loss: 2859.1946 - val_mae: 43.6019\n","Epoch 35/40\n","1690/1690 [==============================] - 61s 36ms/step - loss: 3551.1521 - mae: 42.8217 - val_loss: 2834.9009 - val_mae: 43.3756\n","Epoch 36/40\n","1690/1690 [==============================] - 63s 37ms/step - loss: 3540.6816 - mae: 42.6730 - val_loss: 2919.1609 - val_mae: 44.3506\n","Epoch 37/40\n","1690/1690 [==============================] - 61s 36ms/step - loss: 3541.6970 - mae: 42.6922 - val_loss: 2846.6543 - val_mae: 43.4754\n","Epoch 38/40\n","1690/1690 [==============================] - 62s 37ms/step - loss: 3543.1804 - mae: 42.7015 - val_loss: 2786.4319 - val_mae: 42.6518\n","Epoch 39/40\n","1690/1690 [==============================] - 63s 37ms/step - loss: 3542.4126 - mae: 42.6359 - val_loss: 3097.9792 - val_mae: 46.5718\n","Epoch 40/40\n","1690/1690 [==============================] - 63s 37ms/step - loss: 3532.7131 - mae: 42.6088 - val_loss: 2838.3835 - val_mae: 43.2504\n","42.79630495150997\n","0.6068207110794265\n","0.8059420863510687\n","start group4,This is the experiment num: 2\n","\n","---------------------------------------------- domain num 0 is running----------------------------------\n","start training\n","Epoch 1/40\n","1690/1690 [==============================] - 65s 38ms/step - loss: 5360.6685 - mae: 53.6014 - val_loss: 2688.0200 - val_mae: 36.0006\n","Epoch 2/40\n","1690/1690 [==============================] - 65s 38ms/step - loss: 3852.5830 - mae: 44.5256 - val_loss: 2908.2070 - val_mae: 43.7772\n","Epoch 3/40\n","1690/1690 [==============================] - 71s 42ms/step - loss: 3690.2737 - mae: 43.9042 - val_loss: 2636.3457 - val_mae: 39.8984\n","Epoch 4/40\n","1690/1690 [==============================] - 71s 42ms/step - loss: 3678.9824 - mae: 43.6862 - val_loss: 3317.4590 - val_mae: 48.9302\n","Epoch 5/40\n","1690/1690 [==============================] - 68s 40ms/step - loss: 3672.8496 - mae: 43.6161 - val_loss: 3029.3115 - val_mae: 45.4658\n","Epoch 6/40\n","1690/1690 [==============================] - 70s 41ms/step - loss: 3662.8989 - mae: 43.5270 - val_loss: 2566.7339 - val_mae: 39.2292\n","Epoch 7/40\n","1690/1690 [==============================] - 66s 39ms/step - loss: 3661.9836 - mae: 43.4667 - val_loss: 2878.5586 - val_mae: 42.3768\n","Epoch 8/40\n","1690/1690 [==============================] - 68s 40ms/step - loss: 3661.4600 - mae: 43.5544 - val_loss: 2549.2102 - val_mae: 38.1225\n","Epoch 9/40\n","1690/1690 [==============================] - 68s 40ms/step - loss: 3653.1467 - mae: 43.4594 - val_loss: 2893.3984 - val_mae: 43.3943\n","Epoch 10/40\n","1690/1690 [==============================] - 66s 39ms/step - loss: 3649.8855 - mae: 43.4048 - val_loss: 2918.6357 - val_mae: 45.0881\n","Epoch 11/40\n","1690/1690 [==============================] - 68s 40ms/step - loss: 3650.6914 - mae: 43.3875 - val_loss: 3195.1582 - val_mae: 47.2865\n","Epoch 12/40\n","1690/1690 [==============================] - 66s 39ms/step - loss: 3652.0264 - mae: 43.4261 - val_loss: 3014.7537 - val_mae: 45.9257\n","Epoch 13/40\n","1690/1690 [==============================] - 66s 39ms/step - loss: 3642.6978 - mae: 43.3725 - val_loss: 2746.4001 - val_mae: 42.5387\n","Epoch 14/40\n","1690/1690 [==============================] - 66s 39ms/step - loss: 3635.0349 - mae: 43.2816 - val_loss: 2639.8452 - val_mae: 39.6468\n","Epoch 15/40\n","1690/1690 [==============================] - 65s 39ms/step - loss: 3637.6680 - mae: 43.3412 - val_loss: 2526.7363 - val_mae: 36.1513\n","Epoch 16/40\n","1690/1690 [==============================] - 66s 39ms/step - loss: 3629.8894 - mae: 43.2898 - val_loss: 2702.1560 - val_mae: 40.8479\n","Epoch 17/40\n","1690/1690 [==============================] - 66s 39ms/step - loss: 3627.8240 - mae: 43.2582 - val_loss: 2965.0996 - val_mae: 45.1093\n","Epoch 18/40\n","1690/1690 [==============================] - 66s 39ms/step - loss: 3622.0625 - mae: 43.2323 - val_loss: 2729.7542 - val_mae: 40.2058\n","Epoch 19/40\n","1690/1690 [==============================] - 69s 41ms/step - loss: 3618.6633 - mae: 43.1972 - val_loss: 2768.8687 - val_mae: 42.7789\n","Epoch 20/40\n","1690/1690 [==============================] - 66s 39ms/step - loss: 3616.1226 - mae: 43.2421 - val_loss: 2910.2698 - val_mae: 45.4549\n","Epoch 21/40\n","1690/1690 [==============================] - 66s 39ms/step - loss: 3602.1101 - mae: 43.1320 - val_loss: 2711.1497 - val_mae: 42.1406\n","Epoch 22/40\n","1690/1690 [==============================] - 66s 39ms/step - loss: 3609.4141 - mae: 43.1311 - val_loss: 2951.8467 - val_mae: 45.1069\n","Epoch 23/40\n","1690/1690 [==============================] - 67s 40ms/step - loss: 3595.5520 - mae: 43.0702 - val_loss: 2691.8679 - val_mae: 41.8820\n","Epoch 24/40\n","1690/1690 [==============================] - 66s 39ms/step - loss: 3597.7842 - mae: 43.0358 - val_loss: 2838.8655 - val_mae: 44.1348\n","Epoch 25/40\n","1690/1690 [==============================] - 66s 39ms/step - loss: 3592.3994 - mae: 42.9769 - val_loss: 2753.7319 - val_mae: 42.5951\n","Epoch 26/40\n","1690/1690 [==============================] - 67s 39ms/step - loss: 3596.3020 - mae: 43.0329 - val_loss: 3102.4302 - val_mae: 46.4728\n","Epoch 27/40\n","1690/1690 [==============================] - 66s 39ms/step - loss: 3589.2068 - mae: 43.0913 - val_loss: 2826.3174 - val_mae: 43.3637\n","Epoch 28/40\n","1690/1690 [==============================] - 65s 39ms/step - loss: 3576.7942 - mae: 42.9414 - val_loss: 2799.7905 - val_mae: 43.6235\n","Epoch 29/40\n","1690/1690 [==============================] - 66s 39ms/step - loss: 3591.1357 - mae: 43.1333 - val_loss: 2811.5903 - val_mae: 42.7099\n","Epoch 30/40\n","1690/1690 [==============================] - 66s 39ms/step - loss: 3571.1350 - mae: 42.9293 - val_loss: 2930.4155 - val_mae: 44.4699\n","Epoch 31/40\n","1690/1690 [==============================] - 66s 39ms/step - loss: 3575.1597 - mae: 43.0011 - val_loss: 2985.7373 - val_mae: 45.0661\n","Epoch 32/40\n","1690/1690 [==============================] - 66s 39ms/step - loss: 3566.5549 - mae: 42.9926 - val_loss: 2858.1548 - val_mae: 44.0242\n","Epoch 33/40\n","1690/1690 [==============================] - 66s 39ms/step - loss: 3557.4507 - mae: 42.9224 - val_loss: 2738.8682 - val_mae: 41.7566\n","Epoch 34/40\n","1690/1690 [==============================] - 65s 39ms/step - loss: 3557.6726 - mae: 42.9415 - val_loss: 2787.8025 - val_mae: 42.6892\n","Epoch 35/40\n","1690/1690 [==============================] - 67s 39ms/step - loss: 3561.1499 - mae: 42.9022 - val_loss: 2755.3364 - val_mae: 41.5579\n","Epoch 36/40\n","1690/1690 [==============================] - 65s 39ms/step - loss: 3552.3430 - mae: 42.8179 - val_loss: 2723.4839 - val_mae: 41.0827\n","Epoch 37/40\n","1690/1690 [==============================] - 65s 38ms/step - loss: 3551.9580 - mae: 42.8025 - val_loss: 2704.8547 - val_mae: 41.2184\n","Epoch 38/40\n","1690/1690 [==============================] - 65s 39ms/step - loss: 3548.5137 - mae: 42.7987 - val_loss: 2736.6316 - val_mae: 41.9490\n","Epoch 39/40\n","1690/1690 [==============================] - 65s 38ms/step - loss: 3551.9697 - mae: 42.9105 - val_loss: 2987.8069 - val_mae: 44.8272\n","Epoch 40/40\n","1690/1690 [==============================] - 65s 38ms/step - loss: 3547.0625 - mae: 42.8715 - val_loss: 2666.0769 - val_mae: 40.3715\n","40.99131293422214\n","0.5198224373826508\n","0.7801365550709579\n","start group4,This is the experiment num: 3\n","\n","---------------------------------------------- domain num 0 is running----------------------------------\n","start training\n","Epoch 1/40\n","1690/1690 [==============================] - 66s 38ms/step - loss: 5288.0337 - mae: 53.0074 - val_loss: 2624.8958 - val_mae: 38.3335\n","Epoch 2/40\n","1690/1690 [==============================] - 65s 39ms/step - loss: 3806.8496 - mae: 44.3383 - val_loss: 2732.4492 - val_mae: 42.2340\n","Epoch 3/40\n","1690/1690 [==============================] - 65s 39ms/step - loss: 3683.6765 - mae: 43.8522 - val_loss: 2844.8684 - val_mae: 44.0636\n","Epoch 4/40\n","1690/1690 [==============================] - 65s 38ms/step - loss: 3674.8057 - mae: 43.6938 - val_loss: 2615.9763 - val_mae: 39.4734\n","Epoch 5/40\n","1690/1690 [==============================] - 66s 39ms/step - loss: 3666.2537 - mae: 43.5514 - val_loss: 3094.8950 - val_mae: 46.4410\n","Epoch 6/40\n","1690/1690 [==============================] - 64s 38ms/step - loss: 3662.5374 - mae: 43.5308 - val_loss: 3105.9102 - val_mae: 46.8791\n","Epoch 7/40\n","1690/1690 [==============================] - 64s 38ms/step - loss: 3657.5046 - mae: 43.4147 - val_loss: 2926.2258 - val_mae: 44.7025\n","Epoch 8/40\n","1690/1690 [==============================] - 63s 38ms/step - loss: 3647.1982 - mae: 43.3727 - val_loss: 2905.7651 - val_mae: 43.8986\n","Epoch 9/40\n","1690/1690 [==============================] - 63s 37ms/step - loss: 3651.9958 - mae: 43.4346 - val_loss: 2932.1365 - val_mae: 44.2609\n","Epoch 10/40\n","1690/1690 [==============================] - 64s 38ms/step - loss: 3641.8359 - mae: 43.3593 - val_loss: 2952.3796 - val_mae: 44.8954\n","Epoch 11/40\n","1690/1690 [==============================] - 65s 39ms/step - loss: 3640.5613 - mae: 43.3763 - val_loss: 2576.3274 - val_mae: 37.9774\n","Epoch 12/40\n","1690/1690 [==============================] - 66s 39ms/step - loss: 3647.4219 - mae: 43.4027 - val_loss: 2994.0217 - val_mae: 45.5629\n","Epoch 13/40\n","1690/1690 [==============================] - 66s 39ms/step - loss: 3628.1907 - mae: 43.2781 - val_loss: 3066.2996 - val_mae: 46.8701\n","Epoch 14/40\n","1690/1690 [==============================] - 66s 39ms/step - loss: 3633.3103 - mae: 43.3291 - val_loss: 3116.5059 - val_mae: 47.3595\n","Epoch 15/40\n","1690/1690 [==============================] - 66s 39ms/step - loss: 3618.1138 - mae: 43.1836 - val_loss: 3229.7185 - val_mae: 47.3651\n","Epoch 16/40\n","1690/1690 [==============================] - 66s 39ms/step - loss: 3622.2126 - mae: 43.2589 - val_loss: 2984.6191 - val_mae: 45.8405\n","Epoch 17/40\n","1690/1690 [==============================] - 66s 39ms/step - loss: 3624.9348 - mae: 43.2764 - val_loss: 2803.7820 - val_mae: 43.3332\n","Epoch 18/40\n","1690/1690 [==============================] - 67s 40ms/step - loss: 3617.4497 - mae: 43.1654 - val_loss: 2874.3081 - val_mae: 43.9565\n","Epoch 19/40\n","1690/1690 [==============================] - 65s 39ms/step - loss: 3616.5356 - mae: 43.2598 - val_loss: 2734.8296 - val_mae: 41.8511\n","Epoch 20/40\n","1690/1690 [==============================] - 65s 38ms/step - loss: 3620.7126 - mae: 43.2673 - val_loss: 2643.3923 - val_mae: 37.4369\n","Epoch 21/40\n","1690/1690 [==============================] - 66s 39ms/step - loss: 3609.6284 - mae: 43.2018 - val_loss: 2852.5640 - val_mae: 44.2882\n","Epoch 22/40\n","1690/1690 [==============================] - 66s 39ms/step - loss: 3602.7075 - mae: 43.1375 - val_loss: 3112.6074 - val_mae: 45.7576\n","Epoch 23/40\n","1690/1690 [==============================] - 65s 38ms/step - loss: 3603.4006 - mae: 43.0947 - val_loss: 3358.6125 - val_mae: 48.4905\n","Epoch 24/40\n","1690/1690 [==============================] - 64s 38ms/step - loss: 3597.4788 - mae: 43.0633 - val_loss: 3171.7720 - val_mae: 47.4517\n","Epoch 25/40\n","1690/1690 [==============================] - 63s 37ms/step - loss: 3596.8665 - mae: 43.0675 - val_loss: 2914.5630 - val_mae: 44.1048\n","Epoch 26/40\n","1690/1690 [==============================] - 63s 37ms/step - loss: 3585.6492 - mae: 43.0872 - val_loss: 3075.8218 - val_mae: 46.7589\n","Epoch 27/40\n","1690/1690 [==============================] - 63s 37ms/step - loss: 3582.2908 - mae: 43.0141 - val_loss: 2929.9539 - val_mae: 45.0536\n","Epoch 28/40\n","1690/1690 [==============================] - 65s 39ms/step - loss: 3578.4351 - mae: 42.9754 - val_loss: 2726.6580 - val_mae: 40.6852\n","Epoch 29/40\n","1690/1690 [==============================] - 63s 37ms/step - loss: 3575.4790 - mae: 42.9333 - val_loss: 3151.4739 - val_mae: 47.1322\n","Epoch 30/40\n","1690/1690 [==============================] - 63s 37ms/step - loss: 3575.0151 - mae: 42.9330 - val_loss: 2991.5330 - val_mae: 45.6699\n","Epoch 31/40\n","1690/1690 [==============================] - 64s 38ms/step - loss: 3575.6650 - mae: 42.9245 - val_loss: 2828.6001 - val_mae: 43.4617\n","Epoch 32/40\n","1690/1690 [==============================] - 64s 38ms/step - loss: 3564.0347 - mae: 42.8378 - val_loss: 2795.6870 - val_mae: 42.9452\n","Epoch 33/40\n","1690/1690 [==============================] - 64s 38ms/step - loss: 3562.4309 - mae: 42.8944 - val_loss: 2614.2104 - val_mae: 37.0947\n","Epoch 34/40\n","1690/1690 [==============================] - 65s 38ms/step - loss: 3552.3665 - mae: 42.7952 - val_loss: 2892.5754 - val_mae: 44.2347\n","Epoch 35/40\n","1690/1690 [==============================] - 64s 38ms/step - loss: 3556.2661 - mae: 42.7047 - val_loss: 2777.6331 - val_mae: 41.4865\n","Epoch 36/40\n","1690/1690 [==============================] - 63s 38ms/step - loss: 3557.5518 - mae: 42.8142 - val_loss: 2998.8923 - val_mae: 45.0738\n","Epoch 37/40\n","1690/1690 [==============================] - 63s 37ms/step - loss: 3548.3928 - mae: 42.7337 - val_loss: 2817.5227 - val_mae: 42.2119\n","Epoch 38/40\n","1690/1690 [==============================] - 64s 38ms/step - loss: 3548.4695 - mae: 42.8132 - val_loss: 2887.9060 - val_mae: 44.3759\n","Epoch 39/40\n","1690/1690 [==============================] - 64s 38ms/step - loss: 3542.0525 - mae: 42.6737 - val_loss: 2683.8794 - val_mae: 40.9441\n","Epoch 40/40\n","1690/1690 [==============================] - 66s 39ms/step - loss: 3539.0188 - mae: 42.7064 - val_loss: 2900.1177 - val_mae: 43.1909\n","43.716873576256944\n","0.6453661814504263\n","0.829070763338041\n","start group4,This is the experiment num: 4\n","\n","---------------------------------------------- domain num 0 is running----------------------------------\n","start training\n","Epoch 1/40\n","1690/1690 [==============================] - 65s 38ms/step - loss: 5299.4014 - mae: 53.0964 - val_loss: 2650.4128 - val_mae: 39.6752\n","Epoch 2/40\n","1690/1690 [==============================] - 65s 38ms/step - loss: 3814.6355 - mae: 44.3049 - val_loss: 2924.4341 - val_mae: 44.3030\n","Epoch 3/40\n","1690/1690 [==============================] - 65s 39ms/step - loss: 3696.4438 - mae: 43.9224 - val_loss: 2546.9299 - val_mae: 35.9393\n","Epoch 4/40\n","1690/1690 [==============================] - 65s 39ms/step - loss: 3674.1582 - mae: 43.6073 - val_loss: 2573.6340 - val_mae: 38.9097\n","Epoch 5/40\n","1690/1690 [==============================] - 66s 39ms/step - loss: 3671.9478 - mae: 43.6609 - val_loss: 3569.3638 - val_mae: 50.7402\n","Epoch 6/40\n","1690/1690 [==============================] - 65s 39ms/step - loss: 3654.3958 - mae: 43.5102 - val_loss: 2884.3770 - val_mae: 43.9367\n","Epoch 7/40\n","1690/1690 [==============================] - 65s 39ms/step - loss: 3670.2708 - mae: 43.6512 - val_loss: 2571.3066 - val_mae: 38.5284\n","Epoch 8/40\n","1690/1690 [==============================] - 65s 38ms/step - loss: 3652.1323 - mae: 43.4095 - val_loss: 2650.1672 - val_mae: 40.9723\n","Epoch 9/40\n","1690/1690 [==============================] - 65s 38ms/step - loss: 3652.9084 - mae: 43.3804 - val_loss: 2541.7979 - val_mae: 38.1330\n","Epoch 10/40\n","1690/1690 [==============================] - 64s 38ms/step - loss: 3644.2952 - mae: 43.4058 - val_loss: 2690.7021 - val_mae: 41.1834\n","Epoch 11/40\n","1690/1690 [==============================] - 62s 37ms/step - loss: 3645.6062 - mae: 43.4328 - val_loss: 2545.9631 - val_mae: 37.6938\n","Epoch 12/40\n","1690/1690 [==============================] - 61s 36ms/step - loss: 3630.7310 - mae: 43.2363 - val_loss: 2700.1987 - val_mae: 41.2984\n","Epoch 13/40\n","1690/1690 [==============================] - 61s 36ms/step - loss: 3642.2080 - mae: 43.4172 - val_loss: 3331.2014 - val_mae: 48.9041\n","Epoch 14/40\n","1690/1690 [==============================] - 64s 38ms/step - loss: 3634.1990 - mae: 43.3244 - val_loss: 2582.1514 - val_mae: 38.9726\n","Epoch 15/40\n","1690/1690 [==============================] - 61s 36ms/step - loss: 3620.5837 - mae: 43.1455 - val_loss: 2864.2173 - val_mae: 43.4292\n","Epoch 16/40\n","1690/1690 [==============================] - 62s 37ms/step - loss: 3619.5601 - mae: 43.2382 - val_loss: 2768.2249 - val_mae: 42.9242\n","Epoch 17/40\n","1690/1690 [==============================] - 63s 37ms/step - loss: 3616.9919 - mae: 43.1192 - val_loss: 3094.3457 - val_mae: 46.9094\n","Epoch 18/40\n","1690/1690 [==============================] - 63s 37ms/step - loss: 3613.9644 - mae: 43.2377 - val_loss: 3095.4272 - val_mae: 46.8996\n","Epoch 19/40\n","1690/1690 [==============================] - 63s 37ms/step - loss: 3614.1692 - mae: 43.1355 - val_loss: 2786.5154 - val_mae: 43.2068\n","Epoch 20/40\n","1690/1690 [==============================] - 61s 36ms/step - loss: 3607.2710 - mae: 43.0496 - val_loss: 3057.2092 - val_mae: 46.1157\n","Epoch 21/40\n","1690/1690 [==============================] - 62s 36ms/step - loss: 3601.7312 - mae: 43.0744 - val_loss: 3040.8125 - val_mae: 45.7492\n","Epoch 22/40\n","1690/1690 [==============================] - 62s 36ms/step - loss: 3597.9031 - mae: 43.0725 - val_loss: 2860.1201 - val_mae: 43.4224\n","Epoch 23/40\n","1690/1690 [==============================] - 61s 36ms/step - loss: 3595.7776 - mae: 43.0975 - val_loss: 2864.5625 - val_mae: 44.1496\n","Epoch 24/40\n","1690/1690 [==============================] - 62s 37ms/step - loss: 3598.9729 - mae: 43.0896 - val_loss: 2907.1602 - val_mae: 43.5297\n","Epoch 25/40\n","1690/1690 [==============================] - 62s 37ms/step - loss: 3580.4658 - mae: 43.0473 - val_loss: 2751.3025 - val_mae: 42.5765\n","Epoch 26/40\n","1690/1690 [==============================] - 62s 37ms/step - loss: 3584.2368 - mae: 43.0217 - val_loss: 3059.7251 - val_mae: 46.0276\n","Epoch 27/40\n","1690/1690 [==============================] - 63s 37ms/step - loss: 3580.6560 - mae: 42.9236 - val_loss: 2736.8933 - val_mae: 42.2943\n","Epoch 28/40\n","1690/1690 [==============================] - 66s 39ms/step - loss: 3575.2573 - mae: 42.9912 - val_loss: 2980.6160 - val_mae: 44.8644\n","Epoch 29/40\n","1690/1690 [==============================] - 66s 39ms/step - loss: 3578.4431 - mae: 42.9576 - val_loss: 2835.5308 - val_mae: 43.3863\n","Epoch 30/40\n","1690/1690 [==============================] - 66s 39ms/step - loss: 3577.4380 - mae: 42.9914 - val_loss: 2952.3760 - val_mae: 44.9486\n","Epoch 31/40\n","1690/1690 [==============================] - 65s 39ms/step - loss: 3559.9033 - mae: 42.8361 - val_loss: 2953.8828 - val_mae: 44.9647\n","Epoch 32/40\n","1690/1690 [==============================] - 65s 38ms/step - loss: 3560.9709 - mae: 42.8237 - val_loss: 2978.9561 - val_mae: 45.3935\n","Epoch 33/40\n","1690/1690 [==============================] - 64s 38ms/step - loss: 3549.0437 - mae: 42.7902 - val_loss: 2882.7876 - val_mae: 44.1886\n","Epoch 34/40\n","1690/1690 [==============================] - 64s 38ms/step - loss: 3556.6709 - mae: 42.8305 - val_loss: 2981.9602 - val_mae: 45.7719\n","Epoch 35/40\n","1690/1690 [==============================] - 62s 37ms/step - loss: 3551.5681 - mae: 42.8067 - val_loss: 2697.4653 - val_mae: 41.0336\n","Epoch 36/40\n","1690/1690 [==============================] - 62s 37ms/step - loss: 3543.5654 - mae: 42.7150 - val_loss: 3180.4775 - val_mae: 47.0512\n","Epoch 37/40\n","1690/1690 [==============================] - 62s 37ms/step - loss: 3535.6421 - mae: 42.6435 - val_loss: 3138.8757 - val_mae: 47.0445\n","Epoch 38/40\n","1690/1690 [==============================] - 63s 37ms/step - loss: 3526.9746 - mae: 42.5575 - val_loss: 3274.8870 - val_mae: 48.2857\n","Epoch 39/40\n","1690/1690 [==============================] - 62s 37ms/step - loss: 3539.7478 - mae: 42.6939 - val_loss: 2539.0520 - val_mae: 38.4255\n","Epoch 40/40\n","1690/1690 [==============================] - 63s 37ms/step - loss: 3536.3503 - mae: 42.7259 - val_loss: 3046.2397 - val_mae: 45.3400\n","44.33896660326562\n","0.7270628857241148\n","0.8487183109985736\n"]}]},{"cell_type":"code","source":["# ######################################Fridge###############################################################\n","trainfile1=\"/content/drive/MyDrive/ukdale_training/washingmachine_house_1_training_.csv\"\n","trainfile2=\"/content/drive/MyDrive/training_data/washingmachine_house_2_training_.csv\"\n","trainfile3=\"/content/drive/MyDrive/refit_training/washingmachine/washingmachine_house_9_training_.csv\"\n","trainfile4=\"/content/drive/MyDrive/refit_training/washingmachine/washingmachine_house_15_training_.csv\"\n","\n","trainfile5=\"/content/drive/MyDrive/ukdale_training/washingmachine_house_2_training_.csv\"\n","trainfile6=\"/content/drive/MyDrive/training_data/washingmachine_test_.csv\"\n","trainfile7=\"/content/drive/MyDrive/refit_training/washingmachine/washingmachine_house_16_training_.csv\"\n","trainfile8=\"/content/drive/MyDrive/refit_training/washingmachine/washingmachine_house_17_training_.csv\"\n","trainfile9=\"/content/drive/MyDrive/refit_training/washingmachine/washingmachine_house_18_training_.csv\"\n","trainfile10=\"/content/drive/MyDrive/training_data/washingmachine_house_3_training_.csv\"\n","\n","\n","\n","file=[trainfile1,trainfile2,trainfile3,trainfile4,trainfile5,trainfile6,trainfile7,trainfile8,trainfile9,trainfile10]\n","stepsizeList=[16,2,16,16,16,2,16,16,16,2]\n","list_x=[]\n","list_y=[]\n","for k in [2,4,6,8,10]:\n","    data_insts, data_labels, num_insts,on = [], [], [],[]\n","    threshold=20\n","    fileList=[]\n","    for a in range(k):\n","        fileList.append(file[a])\n","    for i in range(len(fileList)):\n","        X,Y=dataProvider(fileList[i], 19, stepsizeList[i], threshold)\n","        Y=Y.reshape(-1,1)\n","        data_insts.append(X)\n","        data_labels.append(Y)\n","        num_insts.append(X.shape[0])\n","\n","    min_size=min(num_insts)\n","    x_tem, y_tem=[],[]\n","    for j in range(len(fileList)):\n","      ridx = np.random.choice(num_insts[j], min_size)\n","      x_tem.append(data_insts[j][ridx, :])\n","      y_tem.append(data_labels[j][ridx, :])\n","      num_insts[j]=x_tem[j].shape[0]\n","    data_insts=x_tem\n","    data_labels=y_tem \n","    list_x.append(data_insts)\n","    list_y.append(data_labels)\n","    "],"metadata":{"id":"5uewEc7KgSNx","executionInfo":{"status":"ok","timestamp":1661771409461,"user_tz":-600,"elapsed":64822,"user":{"displayName":"XIAOMIN CHANG","userId":"17429039977919006081"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["\n","expnum=5\n","\n","for num in range(len(list_x)):\n","    for n in range(expnum):\n","        print(\"start group\"+str(num)+\",This is the experiment num:\", n )\n","        num_data_sets=len(list_x[num])\n","        data_insts=list_x[num]\n","        data_labels=list_y[num]\n","        num_domains=num_data_sets-1\n","        for i in [0]:\n","                print('\\n---------------------------------------------- domain num %i is running----------------------------------'%(i))\n","                # Build source instances.\n","                source_insts = []\n","                source_labels = []\n","                for j in range(num_data_sets):\n","                    if j != i:\n","                        source_insts.append(data_insts[j])\n","                        source_labels.append(data_labels[j])\n","                # Build target instances.\n","                target_idx = i\n","                target_insts = data_insts[i]\n","                target_labels = data_labels[i]\n","                target_insts0, X_t, target_labels0, y_t =train_test_split(target_insts, target_labels, test_size=0.2,random_state=100)\n","                \n","                X=np.concatenate(source_insts, axis=0)\n","                Y=np.concatenate(source_labels, axis=0)\n","                \n","                x_train_all, x_test, y_train_all, y_test =train_test_split(X, Y, test_size=0.2,random_state=100)\n","                model=CNN_training_best(X,Y)\n","                prediction=model.predict(X_t)\n","                stopT=get_mae(y_t, prediction)\n","                print(stopT)\n","                print(get_sae(y_t, prediction))\n","                print(get_nde(y_t, prediction))\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qZP_55u_gS0A","executionInfo":{"status":"ok","timestamp":1661818978901,"user_tz":-600,"elapsed":24651675,"user":{"displayName":"XIAOMIN CHANG","userId":"17429039977919006081"}},"outputId":"4885e442-d043-47d0-ad79-530cd8d52339"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["start group0,This is the experiment num: 0\n","\n","---------------------------------------------- domain num 0 is running----------------------------------\n","start training\n","Epoch 1/40\n","188/188 [==============================] - 10s 43ms/step - loss: 6.3972e-04 - mae: 0.0120 - val_loss: 3.5926e-06 - val_mae: 0.0019\n","Epoch 2/40\n","188/188 [==============================] - 8s 42ms/step - loss: 2.5549e-05 - mae: 0.0027 - val_loss: 1.3275e-07 - val_mae: 2.9713e-04\n","Epoch 3/40\n","188/188 [==============================] - 8s 42ms/step - loss: 6.2905e-06 - mae: 0.0013 - val_loss: 2.8836e-06 - val_mae: 0.0016\n","Epoch 4/40\n","188/188 [==============================] - 8s 42ms/step - loss: 2.8822e-06 - mae: 9.1068e-04 - val_loss: 7.3769e-05 - val_mae: 0.0085\n","Epoch 5/40\n","188/188 [==============================] - 8s 42ms/step - loss: 1.7359e-06 - mae: 6.6063e-04 - val_loss: 8.2584e-05 - val_mae: 0.0089\n","Epoch 6/40\n","188/188 [==============================] - 8s 41ms/step - loss: 1.1189e-06 - mae: 5.6189e-04 - val_loss: 1.5187e-05 - val_mae: 0.0037\n","Epoch 7/40\n","188/188 [==============================] - 8s 42ms/step - loss: 8.2745e-07 - mae: 4.8328e-04 - val_loss: 1.0962e-06 - val_mae: 6.1812e-04\n","Epoch 8/40\n","188/188 [==============================] - 8s 41ms/step - loss: 6.9856e-07 - mae: 4.2813e-04 - val_loss: 1.2691e-05 - val_mae: 0.0035\n","Epoch 9/40\n","188/188 [==============================] - 8s 42ms/step - loss: 6.9959e-07 - mae: 4.2658e-04 - val_loss: 1.7855e-06 - val_mae: 0.0011\n","Epoch 10/40\n","188/188 [==============================] - 8s 42ms/step - loss: 5.2642e-07 - mae: 3.7619e-04 - val_loss: 2.7091e-06 - val_mae: 0.0015\n","Epoch 11/40\n","188/188 [==============================] - 8s 41ms/step - loss: 4.8499e-07 - mae: 3.6771e-04 - val_loss: 2.6971e-06 - val_mae: 0.0014\n","Epoch 12/40\n","188/188 [==============================] - 8s 42ms/step - loss: 4.9881e-07 - mae: 3.8284e-04 - val_loss: 2.0065e-05 - val_mae: 0.0044\n","Epoch 13/40\n","188/188 [==============================] - 8s 41ms/step - loss: 3.5688e-07 - mae: 3.0525e-04 - val_loss: 6.3523e-06 - val_mae: 0.0025\n","Epoch 14/40\n","188/188 [==============================] - 8s 41ms/step - loss: 2.8348e-07 - mae: 2.8962e-04 - val_loss: 2.0417e-06 - val_mae: 0.0013\n","Epoch 15/40\n","188/188 [==============================] - 8s 42ms/step - loss: 2.6892e-07 - mae: 2.9955e-04 - val_loss: 1.4941e-05 - val_mae: 0.0038\n","Epoch 16/40\n","188/188 [==============================] - 9s 50ms/step - loss: 2.4066e-07 - mae: 2.6178e-04 - val_loss: 2.3312e-05 - val_mae: 0.0048\n","Epoch 17/40\n","188/188 [==============================] - 8s 41ms/step - loss: 2.1821e-07 - mae: 2.3500e-04 - val_loss: 2.4530e-05 - val_mae: 0.0049\n","Epoch 18/40\n","188/188 [==============================] - 8s 42ms/step - loss: 2.4250e-07 - mae: 2.4046e-04 - val_loss: 2.3038e-05 - val_mae: 0.0047\n","Epoch 19/40\n","188/188 [==============================] - 8s 42ms/step - loss: 2.1357e-07 - mae: 2.2188e-04 - val_loss: 1.9659e-05 - val_mae: 0.0044\n","Epoch 20/40\n","188/188 [==============================] - 8s 41ms/step - loss: 2.2139e-07 - mae: 2.1940e-04 - val_loss: 2.7865e-06 - val_mae: 0.0016\n","Epoch 21/40\n","188/188 [==============================] - 8s 41ms/step - loss: 1.7974e-07 - mae: 2.0991e-04 - val_loss: 2.4118e-05 - val_mae: 0.0048\n","Epoch 22/40\n","188/188 [==============================] - 8s 42ms/step - loss: 1.5136e-07 - mae: 1.8880e-04 - val_loss: 6.7453e-07 - val_mae: 4.5964e-04\n","Epoch 23/40\n","188/188 [==============================] - 8s 42ms/step - loss: 1.3146e-07 - mae: 1.8093e-04 - val_loss: 3.6084e-05 - val_mae: 0.0059\n","Epoch 24/40\n","188/188 [==============================] - 8s 42ms/step - loss: 1.2967e-07 - mae: 1.9095e-04 - val_loss: 2.7158e-05 - val_mae: 0.0051\n","Epoch 25/40\n","188/188 [==============================] - 8s 41ms/step - loss: 9.9791e-08 - mae: 1.6133e-04 - val_loss: 6.8828e-07 - val_mae: 5.6929e-04\n","Epoch 26/40\n","188/188 [==============================] - 8s 42ms/step - loss: 1.1114e-07 - mae: 1.6635e-04 - val_loss: 1.0739e-05 - val_mae: 0.0032\n","Epoch 27/40\n","188/188 [==============================] - 8s 42ms/step - loss: 1.7818e-07 - mae: 2.0643e-04 - val_loss: 7.1836e-05 - val_mae: 0.0084\n","Epoch 28/40\n","188/188 [==============================] - 8s 42ms/step - loss: 1.7212e-07 - mae: 2.0024e-04 - val_loss: 1.6068e-05 - val_mae: 0.0039\n","Epoch 29/40\n","188/188 [==============================] - 8s 41ms/step - loss: 1.1569e-07 - mae: 1.6454e-04 - val_loss: 4.4248e-05 - val_mae: 0.0066\n","Epoch 30/40\n","188/188 [==============================] - 8s 42ms/step - loss: 1.6938e-07 - mae: 1.9482e-04 - val_loss: 3.7566e-07 - val_mae: 2.7644e-04\n","Epoch 31/40\n","188/188 [==============================] - 8s 42ms/step - loss: 1.5603e-07 - mae: 2.0054e-04 - val_loss: 7.7606e-05 - val_mae: 0.0088\n","Epoch 32/40\n","188/188 [==============================] - 8s 42ms/step - loss: 8.9604e-08 - mae: 1.5523e-04 - val_loss: 6.3793e-07 - val_mae: 7.3690e-04\n","Epoch 33/40\n","188/188 [==============================] - 10s 51ms/step - loss: 8.3000e-08 - mae: 1.6869e-04 - val_loss: 1.3228e-07 - val_mae: 1.8081e-04\n","Epoch 34/40\n","188/188 [==============================] - 8s 42ms/step - loss: 7.7041e-08 - mae: 1.8511e-04 - val_loss: 3.8201e-06 - val_mae: 0.0019\n","Epoch 35/40\n","188/188 [==============================] - 8s 41ms/step - loss: 5.8254e-08 - mae: 1.6225e-04 - val_loss: 5.6339e-06 - val_mae: 0.0024\n","Epoch 36/40\n","188/188 [==============================] - 8s 41ms/step - loss: 4.7726e-08 - mae: 1.5988e-04 - val_loss: 9.2259e-07 - val_mae: 9.3438e-04\n","Epoch 37/40\n","188/188 [==============================] - 8s 42ms/step - loss: 2.7292e-08 - mae: 1.0148e-04 - val_loss: 5.4192e-05 - val_mae: 0.0074\n","Epoch 38/40\n","188/188 [==============================] - 8s 41ms/step - loss: 2.1733e-08 - mae: 8.1232e-05 - val_loss: 7.8585e-05 - val_mae: 0.0089\n","Epoch 39/40\n","188/188 [==============================] - 8s 42ms/step - loss: 1.8130e-08 - mae: 6.6605e-05 - val_loss: 1.7143e-04 - val_mae: 0.0131\n","Epoch 40/40\n","188/188 [==============================] - 8s 42ms/step - loss: 1.3862e-08 - mae: 6.7433e-05 - val_loss: 1.0725e-04 - val_mae: 0.0104\n","23.72102152910657\n","0.9995488851769202\n","0.9999900355457019\n","start group0,This is the experiment num: 1\n","\n","---------------------------------------------- domain num 0 is running----------------------------------\n","start training\n","Epoch 1/40\n","188/188 [==============================] - 10s 45ms/step - loss: 0.0021 - mae: 0.0221 - val_loss: 3.8642e-06 - val_mae: 0.0019\n","Epoch 2/40\n","188/188 [==============================] - 8s 44ms/step - loss: 1.4934e-04 - mae: 0.0079 - val_loss: 6.4393e-07 - val_mae: 6.4118e-04\n","Epoch 3/40\n","188/188 [==============================] - 8s 44ms/step - loss: 4.5418e-05 - mae: 0.0042 - val_loss: 8.3920e-06 - val_mae: 0.0022\n","Epoch 4/40\n","188/188 [==============================] - 8s 44ms/step - loss: 1.6542e-05 - mae: 0.0023 - val_loss: 2.2430e-05 - val_mae: 0.0033\n","Epoch 5/40\n","188/188 [==============================] - 8s 44ms/step - loss: 9.7203e-06 - mae: 0.0018 - val_loss: 2.2671e-04 - val_mae: 0.0144\n","Epoch 6/40\n","188/188 [==============================] - 8s 44ms/step - loss: 8.2098e-06 - mae: 0.0018 - val_loss: 3.3394e-04 - val_mae: 0.0174\n","Epoch 7/40\n","188/188 [==============================] - 8s 44ms/step - loss: 6.6263e-06 - mae: 0.0015 - val_loss: 8.2606e-05 - val_mae: 0.0082\n","Epoch 8/40\n","188/188 [==============================] - 8s 44ms/step - loss: 4.1063e-06 - mae: 0.0012 - val_loss: 1.2243e-04 - val_mae: 0.0096\n","Epoch 9/40\n","188/188 [==============================] - 10s 51ms/step - loss: 3.9791e-06 - mae: 0.0013 - val_loss: 7.0366e-05 - val_mae: 0.0070\n","Epoch 10/40\n","188/188 [==============================] - 8s 44ms/step - loss: 3.9240e-06 - mae: 0.0014 - val_loss: 1.8206e-04 - val_mae: 0.0131\n","Epoch 11/40\n","188/188 [==============================] - 8s 43ms/step - loss: 5.4783e-06 - mae: 0.0017 - val_loss: 8.1756e-04 - val_mae: 0.0267\n","Epoch 12/40\n","188/188 [==============================] - 8s 44ms/step - loss: 3.4719e-06 - mae: 0.0011 - val_loss: 4.2166e-05 - val_mae: 0.0055\n","Epoch 13/40\n","188/188 [==============================] - 8s 45ms/step - loss: 2.4989e-06 - mae: 8.7587e-04 - val_loss: 1.0882e-05 - val_mae: 0.0025\n","Epoch 14/40\n","188/188 [==============================] - 8s 44ms/step - loss: 2.8392e-06 - mae: 9.9706e-04 - val_loss: 2.6834e-05 - val_mae: 0.0038\n","Epoch 15/40\n","188/188 [==============================] - 8s 41ms/step - loss: 2.5396e-06 - mae: 9.6047e-04 - val_loss: 8.8892e-05 - val_mae: 0.0076\n","Epoch 16/40\n","188/188 [==============================] - 8s 41ms/step - loss: 2.5154e-06 - mae: 9.9447e-04 - val_loss: 2.5083e-05 - val_mae: 0.0028\n","Epoch 17/40\n","188/188 [==============================] - 8s 42ms/step - loss: 1.9618e-06 - mae: 7.7481e-04 - val_loss: 0.0011 - val_mae: 0.0312\n","Epoch 18/40\n","188/188 [==============================] - 8s 42ms/step - loss: 2.0673e-06 - mae: 7.7113e-04 - val_loss: 4.3940e-05 - val_mae: 0.0057\n","Epoch 19/40\n","188/188 [==============================] - 8s 41ms/step - loss: 2.3951e-06 - mae: 8.5126e-04 - val_loss: 7.8804e-04 - val_mae: 0.0270\n","Epoch 20/40\n","188/188 [==============================] - 8s 40ms/step - loss: 3.7786e-06 - mae: 0.0012 - val_loss: 0.0080 - val_mae: 0.0888\n","Epoch 21/40\n","188/188 [==============================] - 8s 40ms/step - loss: 4.6267e-06 - mae: 0.0012 - val_loss: 0.0025 - val_mae: 0.0475\n","Epoch 22/40\n","188/188 [==============================] - 8s 41ms/step - loss: 3.1460e-06 - mae: 9.1444e-04 - val_loss: 0.0032 - val_mae: 0.0557\n","Epoch 23/40\n","188/188 [==============================] - 8s 42ms/step - loss: 2.2543e-06 - mae: 8.0101e-04 - val_loss: 0.0053 - val_mae: 0.0725\n","Epoch 24/40\n","188/188 [==============================] - 8s 41ms/step - loss: 1.4917e-06 - mae: 6.3490e-04 - val_loss: 5.4722e-05 - val_mae: 0.0071\n","Epoch 25/40\n","188/188 [==============================] - 8s 41ms/step - loss: 1.3042e-06 - mae: 5.7404e-04 - val_loss: 9.7297e-05 - val_mae: 0.0094\n","Epoch 26/40\n","188/188 [==============================] - 9s 50ms/step - loss: 9.0692e-07 - mae: 4.6518e-04 - val_loss: 6.0810e-04 - val_mae: 0.0245\n","Epoch 27/40\n","188/188 [==============================] - 8s 42ms/step - loss: 5.4842e-07 - mae: 3.4863e-04 - val_loss: 1.2651e-04 - val_mae: 0.0112\n","Epoch 28/40\n","188/188 [==============================] - 8s 42ms/step - loss: 3.8545e-07 - mae: 3.0972e-04 - val_loss: 5.4468e-06 - val_mae: 0.0021\n","Epoch 29/40\n","188/188 [==============================] - 8s 42ms/step - loss: 3.0381e-07 - mae: 2.7995e-04 - val_loss: 4.8865e-05 - val_mae: 0.0069\n","Epoch 30/40\n","188/188 [==============================] - 8s 41ms/step - loss: 5.6036e-07 - mae: 3.8891e-04 - val_loss: 1.9081e-04 - val_mae: 0.0138\n","Epoch 31/40\n","188/188 [==============================] - 11s 57ms/step - loss: 4.8099e-07 - mae: 3.5556e-04 - val_loss: 0.0035 - val_mae: 0.0593\n","Epoch 32/40\n","188/188 [==============================] - 8s 44ms/step - loss: 2.9006e-07 - mae: 2.7434e-04 - val_loss: 0.0017 - val_mae: 0.0416\n","Epoch 33/40\n","188/188 [==============================] - 8s 41ms/step - loss: 2.2976e-07 - mae: 2.5209e-04 - val_loss: 1.9562e-04 - val_mae: 0.0139\n","Epoch 34/40\n","188/188 [==============================] - 8s 41ms/step - loss: 2.7108e-07 - mae: 2.9042e-04 - val_loss: 8.4799e-05 - val_mae: 0.0092\n","Epoch 35/40\n","188/188 [==============================] - 8s 41ms/step - loss: 2.3399e-07 - mae: 2.5522e-04 - val_loss: 8.7847e-05 - val_mae: 0.0093\n","Epoch 36/40\n","188/188 [==============================] - 8s 41ms/step - loss: 2.2778e-07 - mae: 2.4396e-04 - val_loss: 3.2592e-04 - val_mae: 0.0180\n","Epoch 37/40\n","188/188 [==============================] - 8s 41ms/step - loss: 2.4455e-07 - mae: 2.4798e-04 - val_loss: 2.0141e-04 - val_mae: 0.0142\n","Epoch 38/40\n","188/188 [==============================] - 8s 41ms/step - loss: 3.5399e-07 - mae: 2.7613e-04 - val_loss: 4.5503e-04 - val_mae: 0.0213\n","Epoch 39/40\n","188/188 [==============================] - 8s 41ms/step - loss: 4.4055e-07 - mae: 3.4315e-04 - val_loss: 8.2055e-04 - val_mae: 0.0286\n","Epoch 40/40\n","188/188 [==============================] - 8s 41ms/step - loss: 2.7254e-07 - mae: 2.4232e-04 - val_loss: 7.2429e-04 - val_mae: 0.0268\n","23.73646707517546\n","0.9988454103680723\n","0.9999770123437007\n","start group0,This is the experiment num: 2\n","\n","---------------------------------------------- domain num 0 is running----------------------------------\n","start training\n","Epoch 1/40\n","188/188 [==============================] - 10s 43ms/step - loss: 6.2933e-04 - mae: 0.0120 - val_loss: 6.9431e-06 - val_mae: 0.0026\n","Epoch 2/40\n","188/188 [==============================] - 8s 42ms/step - loss: 1.7419e-05 - mae: 0.0025 - val_loss: 2.7249e-05 - val_mae: 0.0052\n","Epoch 3/40\n","188/188 [==============================] - 8s 42ms/step - loss: 3.3762e-06 - mae: 9.7096e-04 - val_loss: 3.1867e-05 - val_mae: 0.0056\n","Epoch 4/40\n","188/188 [==============================] - 8s 42ms/step - loss: 1.2851e-06 - mae: 6.2214e-04 - val_loss: 4.5165e-05 - val_mae: 0.0066\n","Epoch 5/40\n","188/188 [==============================] - 8s 43ms/step - loss: 8.6634e-07 - mae: 5.2353e-04 - val_loss: 3.8629e-06 - val_mae: 0.0018\n","Epoch 6/40\n","188/188 [==============================] - 8s 43ms/step - loss: 6.5734e-07 - mae: 4.3337e-04 - val_loss: 1.2144e-06 - val_mae: 9.4594e-04\n","Epoch 7/40\n","188/188 [==============================] - 8s 43ms/step - loss: 4.8933e-07 - mae: 3.7156e-04 - val_loss: 2.1060e-06 - val_mae: 0.0013\n","Epoch 8/40\n","188/188 [==============================] - 8s 43ms/step - loss: 4.7668e-07 - mae: 3.2513e-04 - val_loss: 3.3067e-06 - val_mae: 0.0017\n","Epoch 9/40\n","188/188 [==============================] - 8s 42ms/step - loss: 4.0901e-07 - mae: 3.5914e-04 - val_loss: 4.6259e-06 - val_mae: 0.0021\n","Epoch 10/40\n","188/188 [==============================] - 8s 42ms/step - loss: 3.5921e-07 - mae: 3.2835e-04 - val_loss: 5.2057e-07 - val_mae: 5.4168e-04\n","Epoch 11/40\n","188/188 [==============================] - 8s 42ms/step - loss: 3.2052e-07 - mae: 3.1103e-04 - val_loss: 4.0126e-06 - val_mae: 0.0019\n","Epoch 12/40\n","188/188 [==============================] - 8s 42ms/step - loss: 3.1995e-07 - mae: 2.8149e-04 - val_loss: 5.1537e-07 - val_mae: 6.3619e-04\n","Epoch 13/40\n","188/188 [==============================] - 8s 42ms/step - loss: 2.5645e-07 - mae: 2.5990e-04 - val_loss: 2.8398e-05 - val_mae: 0.0053\n","Epoch 14/40\n","188/188 [==============================] - 10s 51ms/step - loss: 2.7318e-07 - mae: 2.9632e-04 - val_loss: 1.7021e-05 - val_mae: 0.0041\n","Epoch 15/40\n","188/188 [==============================] - 8s 42ms/step - loss: 2.4625e-07 - mae: 2.6320e-04 - val_loss: 9.6502e-07 - val_mae: 8.9781e-04\n","Epoch 16/40\n","188/188 [==============================] - 8s 42ms/step - loss: 2.0103e-07 - mae: 2.3522e-04 - val_loss: 4.9142e-05 - val_mae: 0.0070\n","Epoch 17/40\n","188/188 [==============================] - 8s 41ms/step - loss: 1.6741e-07 - mae: 2.3202e-04 - val_loss: 2.7937e-05 - val_mae: 0.0052\n","Epoch 18/40\n","188/188 [==============================] - 8s 42ms/step - loss: 1.5653e-07 - mae: 2.3579e-04 - val_loss: 5.1968e-07 - val_mae: 5.7402e-04\n","Epoch 19/40\n","188/188 [==============================] - 8s 42ms/step - loss: 1.9818e-07 - mae: 2.8111e-04 - val_loss: 1.7711e-05 - val_mae: 0.0042\n","Epoch 20/40\n","188/188 [==============================] - 8s 41ms/step - loss: 1.8062e-07 - mae: 2.4107e-04 - val_loss: 6.0063e-05 - val_mae: 0.0077\n","Epoch 21/40\n","188/188 [==============================] - 8s 41ms/step - loss: 1.4629e-07 - mae: 2.0915e-04 - val_loss: 1.5475e-05 - val_mae: 0.0039\n","Epoch 22/40\n","188/188 [==============================] - 8s 42ms/step - loss: 1.7333e-07 - mae: 2.3137e-04 - val_loss: 1.3591e-04 - val_mae: 0.0116\n","Epoch 23/40\n","188/188 [==============================] - 8s 42ms/step - loss: 1.4253e-07 - mae: 2.1652e-04 - val_loss: 1.2485e-05 - val_mae: 0.0035\n","Epoch 24/40\n","188/188 [==============================] - 8s 42ms/step - loss: 1.1430e-07 - mae: 1.9142e-04 - val_loss: 3.8561e-05 - val_mae: 0.0062\n","Epoch 25/40\n","188/188 [==============================] - 8s 42ms/step - loss: 1.6476e-07 - mae: 2.4248e-04 - val_loss: 2.6300e-06 - val_mae: 0.0016\n","Epoch 26/40\n","188/188 [==============================] - 8s 41ms/step - loss: 9.9736e-08 - mae: 2.0219e-04 - val_loss: 1.3420e-04 - val_mae: 0.0116\n","Epoch 27/40\n","188/188 [==============================] - 8s 42ms/step - loss: 1.0910e-07 - mae: 2.0538e-04 - val_loss: 2.7492e-05 - val_mae: 0.0052\n","Epoch 28/40\n","188/188 [==============================] - 8s 41ms/step - loss: 1.0660e-07 - mae: 1.8776e-04 - val_loss: 2.4275e-07 - val_mae: 3.2970e-04\n","Epoch 29/40\n","188/188 [==============================] - 8s 42ms/step - loss: 8.7126e-08 - mae: 1.7158e-04 - val_loss: 7.1977e-08 - val_mae: 1.3492e-04\n","Epoch 30/40\n","188/188 [==============================] - 8s 42ms/step - loss: 5.3574e-08 - mae: 1.3131e-04 - val_loss: 5.1041e-05 - val_mae: 0.0071\n","Epoch 31/40\n","188/188 [==============================] - 8s 42ms/step - loss: 5.7463e-08 - mae: 1.3872e-04 - val_loss: 7.3695e-05 - val_mae: 0.0086\n","Epoch 32/40\n","188/188 [==============================] - 10s 51ms/step - loss: 7.4555e-08 - mae: 1.5590e-04 - val_loss: 1.3774e-05 - val_mae: 0.0037\n","Epoch 33/40\n","188/188 [==============================] - 8s 42ms/step - loss: 8.6158e-08 - mae: 1.8697e-04 - val_loss: 4.7432e-05 - val_mae: 0.0069\n","Epoch 34/40\n","188/188 [==============================] - 8s 42ms/step - loss: 4.8329e-08 - mae: 1.2751e-04 - val_loss: 1.5165e-07 - val_mae: 3.5508e-04\n","Epoch 35/40\n","188/188 [==============================] - 8s 42ms/step - loss: 3.5839e-08 - mae: 1.1117e-04 - val_loss: 3.2166e-07 - val_mae: 5.4796e-04\n","Epoch 36/40\n","188/188 [==============================] - 8s 41ms/step - loss: 1.9105e-08 - mae: 7.4240e-05 - val_loss: 1.2314e-06 - val_mae: 0.0011\n","Epoch 37/40\n","188/188 [==============================] - 8s 42ms/step - loss: 1.9616e-08 - mae: 7.3870e-05 - val_loss: 1.0176e-07 - val_mae: 3.0119e-04\n","Epoch 38/40\n","188/188 [==============================] - 8s 43ms/step - loss: 1.6397e-08 - mae: 6.8654e-05 - val_loss: 3.3548e-05 - val_mae: 0.0058\n","Epoch 39/40\n","188/188 [==============================] - 8s 42ms/step - loss: 2.0566e-08 - mae: 8.8686e-05 - val_loss: 1.3857e-05 - val_mae: 0.0037\n","Epoch 40/40\n","188/188 [==============================] - 8s 42ms/step - loss: 2.7061e-08 - mae: 9.7148e-05 - val_loss: 3.2159e-05 - val_mae: 0.0057\n","23.717124624003095\n","1.000240852216606\n","1.0000040735353493\n","start group0,This is the experiment num: 3\n","\n","---------------------------------------------- domain num 0 is running----------------------------------\n","start training\n","Epoch 1/40\n","188/188 [==============================] - 10s 44ms/step - loss: 0.0031 - mae: 0.0291 - val_loss: 6.6428e-06 - val_mae: 0.0026\n","Epoch 2/40\n","188/188 [==============================] - 8s 42ms/step - loss: 1.6769e-04 - mae: 0.0085 - val_loss: 7.9473e-06 - val_mae: 0.0028\n","Epoch 3/40\n","188/188 [==============================] - 8s 42ms/step - loss: 1.6026e-05 - mae: 0.0023 - val_loss: 2.3675e-05 - val_mae: 0.0047\n","Epoch 4/40\n","188/188 [==============================] - 8s 42ms/step - loss: 5.8097e-06 - mae: 0.0013 - val_loss: 1.3068e-05 - val_mae: 0.0030\n","Epoch 5/40\n","188/188 [==============================] - 8s 42ms/step - loss: 3.3018e-06 - mae: 8.5827e-04 - val_loss: 7.7718e-06 - val_mae: 0.0014\n","Epoch 6/40\n","188/188 [==============================] - 8s 42ms/step - loss: 2.7654e-06 - mae: 7.2186e-04 - val_loss: 7.9201e-06 - val_mae: 0.0015\n","Epoch 7/40\n","188/188 [==============================] - 8s 42ms/step - loss: 2.0318e-06 - mae: 6.5224e-04 - val_loss: 5.7198e-06 - val_mae: 7.5863e-04\n","Epoch 8/40\n","188/188 [==============================] - 8s 42ms/step - loss: 1.6095e-06 - mae: 5.9052e-04 - val_loss: 8.1884e-06 - val_mae: 0.0022\n","Epoch 9/40\n","188/188 [==============================] - 9s 50ms/step - loss: 1.3481e-06 - mae: 5.5942e-04 - val_loss: 1.0772e-05 - val_mae: 0.0028\n","Epoch 10/40\n","188/188 [==============================] - 8s 41ms/step - loss: 1.0346e-06 - mae: 5.1568e-04 - val_loss: 4.2131e-06 - val_mae: 0.0012\n","Epoch 11/40\n","188/188 [==============================] - 8s 41ms/step - loss: 1.1065e-06 - mae: 4.8175e-04 - val_loss: 4.9504e-06 - val_mae: 0.0017\n","Epoch 12/40\n","188/188 [==============================] - 8s 41ms/step - loss: 8.5865e-07 - mae: 4.4403e-04 - val_loss: 4.7716e-06 - val_mae: 0.0018\n","Epoch 13/40\n","188/188 [==============================] - 8s 42ms/step - loss: 7.3205e-07 - mae: 4.2894e-04 - val_loss: 1.1960e-06 - val_mae: 3.9051e-04\n","Epoch 14/40\n","188/188 [==============================] - 8s 41ms/step - loss: 7.5985e-07 - mae: 4.3078e-04 - val_loss: 1.9456e-06 - val_mae: 7.8080e-04\n","Epoch 15/40\n","188/188 [==============================] - 8s 41ms/step - loss: 9.8947e-07 - mae: 4.6259e-04 - val_loss: 1.6326e-06 - val_mae: 8.7894e-04\n","Epoch 16/40\n","188/188 [==============================] - 8s 41ms/step - loss: 8.5354e-07 - mae: 4.3060e-04 - val_loss: 2.7437e-06 - val_mae: 9.3402e-04\n","Epoch 17/40\n","188/188 [==============================] - 8s 42ms/step - loss: 6.2173e-07 - mae: 3.9136e-04 - val_loss: 1.9951e-06 - val_mae: 7.8056e-04\n","Epoch 18/40\n","188/188 [==============================] - 8s 41ms/step - loss: 5.9303e-07 - mae: 3.6257e-04 - val_loss: 2.7145e-06 - val_mae: 0.0012\n","Epoch 19/40\n","188/188 [==============================] - 8s 42ms/step - loss: 5.7506e-07 - mae: 3.7131e-04 - val_loss: 1.3521e-05 - val_mae: 0.0031\n","Epoch 20/40\n","188/188 [==============================] - 8s 41ms/step - loss: 4.8908e-07 - mae: 3.3595e-04 - val_loss: 1.1038e-05 - val_mae: 0.0029\n","Epoch 21/40\n","188/188 [==============================] - 8s 41ms/step - loss: 5.5249e-07 - mae: 3.4613e-04 - val_loss: 5.1095e-05 - val_mae: 0.0069\n","Epoch 22/40\n","188/188 [==============================] - 8s 42ms/step - loss: 4.3814e-07 - mae: 3.4031e-04 - val_loss: 1.7247e-06 - val_mae: 5.5030e-04\n","Epoch 23/40\n","188/188 [==============================] - 8s 42ms/step - loss: 4.0149e-07 - mae: 3.0964e-04 - val_loss: 9.1181e-07 - val_mae: 4.9097e-04\n","Epoch 24/40\n","188/188 [==============================] - 8s 42ms/step - loss: 3.9935e-07 - mae: 2.9067e-04 - val_loss: 2.4915e-06 - val_mae: 0.0011\n","Epoch 25/40\n","188/188 [==============================] - 8s 42ms/step - loss: 3.4687e-07 - mae: 2.7055e-04 - val_loss: 1.0551e-05 - val_mae: 0.0030\n","Epoch 26/40\n","188/188 [==============================] - 8s 42ms/step - loss: 4.9767e-07 - mae: 3.1649e-04 - val_loss: 1.7864e-04 - val_mae: 0.0133\n","Epoch 27/40\n","188/188 [==============================] - 9s 50ms/step - loss: 4.7138e-07 - mae: 3.0409e-04 - val_loss: 4.4238e-05 - val_mae: 0.0066\n","Epoch 28/40\n","188/188 [==============================] - 8s 42ms/step - loss: 4.6053e-07 - mae: 3.2120e-04 - val_loss: 2.1698e-05 - val_mae: 0.0046\n","Epoch 29/40\n","188/188 [==============================] - 8s 42ms/step - loss: 3.8472e-07 - mae: 2.6455e-04 - val_loss: 3.8065e-06 - val_mae: 0.0018\n","Epoch 30/40\n","188/188 [==============================] - 8s 42ms/step - loss: 7.7111e-07 - mae: 3.1217e-04 - val_loss: 9.8730e-06 - val_mae: 0.0030\n","Epoch 31/40\n","188/188 [==============================] - 8s 42ms/step - loss: 6.8290e-07 - mae: 3.6023e-04 - val_loss: 3.5541e-04 - val_mae: 0.0188\n","Epoch 32/40\n","188/188 [==============================] - 8s 42ms/step - loss: 3.4925e-07 - mae: 2.6618e-04 - val_loss: 1.5582e-06 - val_mae: 0.0011\n","Epoch 33/40\n","188/188 [==============================] - 8s 42ms/step - loss: 1.4194e-07 - mae: 1.8002e-04 - val_loss: 6.2366e-07 - val_mae: 7.3332e-04\n","Epoch 34/40\n","188/188 [==============================] - 8s 42ms/step - loss: 1.0136e-07 - mae: 1.4443e-04 - val_loss: 1.9664e-06 - val_mae: 0.0014\n","Epoch 35/40\n","188/188 [==============================] - 8s 43ms/step - loss: 6.3907e-08 - mae: 1.1641e-04 - val_loss: 1.4647e-06 - val_mae: 0.0012\n","Epoch 36/40\n","188/188 [==============================] - 8s 42ms/step - loss: 5.3296e-08 - mae: 1.1166e-04 - val_loss: 9.2550e-08 - val_mae: 2.3729e-04\n","Epoch 37/40\n","188/188 [==============================] - 8s 43ms/step - loss: 5.6013e-08 - mae: 1.1693e-04 - val_loss: 5.6973e-07 - val_mae: 7.2379e-04\n","Epoch 38/40\n","188/188 [==============================] - 8s 45ms/step - loss: 4.6680e-08 - mae: 1.1296e-04 - val_loss: 4.8316e-07 - val_mae: 6.7342e-04\n","Epoch 39/40\n","188/188 [==============================] - 8s 43ms/step - loss: 3.5977e-08 - mae: 9.5324e-05 - val_loss: 3.1222e-08 - val_mae: 9.8522e-05\n","Epoch 40/40\n","188/188 [==============================] - 8s 42ms/step - loss: 2.9268e-08 - mae: 8.4490e-05 - val_loss: 1.4864e-07 - val_mae: 3.3898e-04\n","23.71222114191128\n","1.0000231874210188\n","1.0000074781900656\n","start group0,This is the experiment num: 4\n","\n","---------------------------------------------- domain num 0 is running----------------------------------\n","start training\n","Epoch 1/40\n","188/188 [==============================] - 10s 44ms/step - loss: 0.0056 - mae: 0.0349 - val_loss: 2.6725e-06 - val_mae: 0.0016\n","Epoch 2/40\n","188/188 [==============================] - 8s 42ms/step - loss: 2.5535e-04 - mae: 0.0107 - val_loss: 2.0619e-06 - val_mae: 9.5820e-04\n","Epoch 3/40\n","188/188 [==============================] - 8s 42ms/step - loss: 7.6077e-05 - mae: 0.0065 - val_loss: 2.0444e-05 - val_mae: 0.0038\n","Epoch 4/40\n","188/188 [==============================] - 10s 52ms/step - loss: 3.0777e-05 - mae: 0.0038 - val_loss: 2.7000e-04 - val_mae: 0.0152\n","Epoch 5/40\n","188/188 [==============================] - 8s 42ms/step - loss: 1.5164e-05 - mae: 0.0024 - val_loss: 3.4844e-04 - val_mae: 0.0151\n","Epoch 6/40\n","188/188 [==============================] - 8s 42ms/step - loss: 1.1656e-05 - mae: 0.0020 - val_loss: 2.5251e-04 - val_mae: 0.0130\n","Epoch 7/40\n","188/188 [==============================] - 8s 42ms/step - loss: 8.5750e-06 - mae: 0.0016 - val_loss: 3.1438e-05 - val_mae: 0.0045\n","Epoch 8/40\n","188/188 [==============================] - 9s 48ms/step - loss: 6.9259e-06 - mae: 0.0015 - val_loss: 1.2259e-05 - val_mae: 0.0018\n","Epoch 9/40\n","188/188 [==============================] - 8s 43ms/step - loss: 6.2792e-06 - mae: 0.0016 - val_loss: 9.2264e-06 - val_mae: 0.0014\n","Epoch 10/40\n","188/188 [==============================] - 8s 42ms/step - loss: 5.1236e-06 - mae: 0.0014 - val_loss: 3.2600e-05 - val_mae: 0.0050\n","Epoch 11/40\n","188/188 [==============================] - 8s 42ms/step - loss: 4.2202e-06 - mae: 0.0012 - val_loss: 5.7391e-05 - val_mae: 0.0063\n","Epoch 12/40\n","188/188 [==============================] - 8s 41ms/step - loss: 3.3740e-06 - mae: 0.0010 - val_loss: 7.2709e-06 - val_mae: 0.0015\n","Epoch 13/40\n","188/188 [==============================] - 8s 40ms/step - loss: 4.0708e-06 - mae: 0.0014 - val_loss: 7.2094e-06 - val_mae: 0.0014\n","Epoch 14/40\n","188/188 [==============================] - 8s 41ms/step - loss: 3.0802e-06 - mae: 0.0011 - val_loss: 6.7687e-05 - val_mae: 0.0079\n","Epoch 15/40\n","188/188 [==============================] - 8s 42ms/step - loss: 2.7262e-06 - mae: 0.0010 - val_loss: 1.9483e-05 - val_mae: 0.0037\n","Epoch 16/40\n","188/188 [==============================] - 8s 42ms/step - loss: 2.6222e-06 - mae: 0.0010 - val_loss: 7.6164e-05 - val_mae: 0.0080\n","Epoch 17/40\n","188/188 [==============================] - 8s 40ms/step - loss: 2.9375e-06 - mae: 0.0011 - val_loss: 4.2363e-05 - val_mae: 0.0061\n","Epoch 18/40\n","188/188 [==============================] - 8s 40ms/step - loss: 2.8929e-06 - mae: 0.0011 - val_loss: 4.2441e-05 - val_mae: 0.0061\n","Epoch 19/40\n","188/188 [==============================] - 8s 41ms/step - loss: 2.1922e-06 - mae: 9.8346e-04 - val_loss: 2.9046e-05 - val_mae: 0.0050\n","Epoch 20/40\n","188/188 [==============================] - 8s 41ms/step - loss: 2.2033e-06 - mae: 0.0010 - val_loss: 5.9288e-05 - val_mae: 0.0072\n","Epoch 21/40\n","188/188 [==============================] - 8s 41ms/step - loss: 1.7895e-06 - mae: 8.2644e-04 - val_loss: 6.9384e-05 - val_mae: 0.0080\n","Epoch 22/40\n","188/188 [==============================] - 9s 49ms/step - loss: 1.5054e-06 - mae: 7.4496e-04 - val_loss: 1.1156e-04 - val_mae: 0.0097\n","Epoch 23/40\n","188/188 [==============================] - 7s 40ms/step - loss: 1.4788e-06 - mae: 7.6715e-04 - val_loss: 2.1159e-05 - val_mae: 0.0036\n","Epoch 24/40\n","188/188 [==============================] - 8s 41ms/step - loss: 1.4745e-06 - mae: 7.8185e-04 - val_loss: 1.2929e-05 - val_mae: 0.0032\n","Epoch 25/40\n","188/188 [==============================] - 8s 41ms/step - loss: 1.2881e-06 - mae: 7.3340e-04 - val_loss: 8.8709e-06 - val_mae: 0.0025\n","Epoch 26/40\n","188/188 [==============================] - 8s 41ms/step - loss: 1.8283e-06 - mae: 8.8095e-04 - val_loss: 1.6912e-05 - val_mae: 0.0038\n","Epoch 27/40\n","188/188 [==============================] - 8s 41ms/step - loss: 1.9083e-06 - mae: 8.8651e-04 - val_loss: 2.5271e-05 - val_mae: 0.0047\n","Epoch 28/40\n","188/188 [==============================] - 8s 40ms/step - loss: 1.3986e-06 - mae: 7.2908e-04 - val_loss: 3.1152e-05 - val_mae: 0.0052\n","Epoch 29/40\n","188/188 [==============================] - 8s 41ms/step - loss: 1.9566e-06 - mae: 0.0010 - val_loss: 9.8338e-05 - val_mae: 0.0098\n","Epoch 30/40\n","188/188 [==============================] - 8s 40ms/step - loss: 1.4376e-06 - mae: 8.0488e-04 - val_loss: 1.8893e-05 - val_mae: 0.0040\n","Epoch 31/40\n","188/188 [==============================] - 8s 41ms/step - loss: 1.3110e-06 - mae: 7.4051e-04 - val_loss: 2.2416e-05 - val_mae: 0.0043\n","Epoch 32/40\n","188/188 [==============================] - 8s 41ms/step - loss: 1.3338e-06 - mae: 7.2106e-04 - val_loss: 1.0604e-04 - val_mae: 0.0100\n","Epoch 33/40\n","188/188 [==============================] - 8s 40ms/step - loss: 1.3595e-06 - mae: 7.5816e-04 - val_loss: 3.5667e-05 - val_mae: 0.0057\n","Epoch 34/40\n","188/188 [==============================] - 8s 40ms/step - loss: 1.0779e-06 - mae: 6.6751e-04 - val_loss: 5.1867e-05 - val_mae: 0.0071\n","Epoch 35/40\n","188/188 [==============================] - 8s 41ms/step - loss: 5.7947e-07 - mae: 4.3560e-04 - val_loss: 1.1542e-05 - val_mae: 0.0033\n","Epoch 36/40\n","188/188 [==============================] - 8s 41ms/step - loss: 4.7312e-07 - mae: 3.4244e-04 - val_loss: 3.9011e-05 - val_mae: 0.0061\n","Epoch 37/40\n","188/188 [==============================] - 8s 41ms/step - loss: 4.8734e-07 - mae: 3.5626e-04 - val_loss: 2.1059e-05 - val_mae: 0.0045\n","Epoch 38/40\n","188/188 [==============================] - 8s 41ms/step - loss: 4.0574e-07 - mae: 3.7630e-04 - val_loss: 2.8216e-05 - val_mae: 0.0053\n","Epoch 39/40\n","188/188 [==============================] - 8s 40ms/step - loss: 2.7351e-07 - mae: 3.0798e-04 - val_loss: 3.7665e-05 - val_mae: 0.0061\n","Epoch 40/40\n","188/188 [==============================] - 9s 50ms/step - loss: 2.6434e-07 - mae: 2.9230e-04 - val_loss: 6.7539e-06 - val_mae: 0.0025\n","23.714542895569497\n","0.9999306032733237\n","0.999930909758132\n","start group1,This is the experiment num: 0\n","\n","---------------------------------------------- domain num 0 is running----------------------------------\n","start training\n","Epoch 1/40\n","564/564 [==============================] - 25s 41ms/step - loss: 13931.7266 - mae: 17.4330 - val_loss: 33573.0977 - val_mae: 23.5512\n","Epoch 2/40\n","564/564 [==============================] - 23s 41ms/step - loss: 13394.0898 - mae: 17.9860 - val_loss: 31546.6094 - val_mae: 33.5380\n","Epoch 3/40\n","564/564 [==============================] - 23s 40ms/step - loss: 13335.0996 - mae: 17.4516 - val_loss: 31565.6543 - val_mae: 20.7931\n","Epoch 4/40\n","564/564 [==============================] - 22s 40ms/step - loss: 13249.4941 - mae: 16.1866 - val_loss: 30472.8281 - val_mae: 23.9348\n","Epoch 5/40\n","564/564 [==============================] - 22s 40ms/step - loss: 13215.6230 - mae: 15.8358 - val_loss: 30680.5176 - val_mae: 20.7208\n","Epoch 6/40\n","564/564 [==============================] - 25s 44ms/step - loss: 13216.5137 - mae: 16.0011 - val_loss: 31238.0664 - val_mae: 19.9615\n","Epoch 7/40\n","564/564 [==============================] - 23s 41ms/step - loss: 13225.7559 - mae: 15.6649 - val_loss: 31074.7480 - val_mae: 23.8447\n","Epoch 8/40\n","564/564 [==============================] - 23s 41ms/step - loss: 12896.2891 - mae: 15.3294 - val_loss: 31624.0195 - val_mae: 22.3376\n","Epoch 9/40\n","564/564 [==============================] - 23s 41ms/step - loss: 12898.5703 - mae: 15.5543 - val_loss: 30401.0332 - val_mae: 21.3467\n","Epoch 10/40\n","564/564 [==============================] - 23s 41ms/step - loss: 12915.4082 - mae: 15.7517 - val_loss: 30519.7266 - val_mae: 22.0386\n","Epoch 11/40\n","564/564 [==============================] - 23s 41ms/step - loss: 12837.2803 - mae: 15.8641 - val_loss: 31162.4102 - val_mae: 20.8460\n","Epoch 12/40\n","564/564 [==============================] - 25s 44ms/step - loss: 12893.9580 - mae: 15.9149 - val_loss: 29687.6738 - val_mae: 20.2786\n","Epoch 13/40\n","564/564 [==============================] - 24s 42ms/step - loss: 13012.2627 - mae: 16.1399 - val_loss: 30724.0527 - val_mae: 27.2513\n","Epoch 14/40\n","564/564 [==============================] - 24s 43ms/step - loss: 12764.9727 - mae: 15.9115 - val_loss: 31029.4883 - val_mae: 22.8590\n","Epoch 15/40\n","564/564 [==============================] - 24s 42ms/step - loss: 12879.9365 - mae: 16.0064 - val_loss: 30786.3535 - val_mae: 20.1256\n","Epoch 16/40\n","564/564 [==============================] - 24s 42ms/step - loss: 12898.8457 - mae: 16.4461 - val_loss: 31409.3691 - val_mae: 24.7951\n","Epoch 17/40\n","564/564 [==============================] - 23s 41ms/step - loss: 13092.3877 - mae: 16.6740 - val_loss: 31448.5000 - val_mae: 25.7943\n","Epoch 18/40\n","564/564 [==============================] - 25s 44ms/step - loss: 13043.5723 - mae: 16.3346 - val_loss: 31127.0156 - val_mae: 20.3859\n","Epoch 19/40\n","564/564 [==============================] - 23s 41ms/step - loss: 12996.9004 - mae: 16.9360 - val_loss: 29976.5645 - val_mae: 33.5587\n","Epoch 20/40\n","564/564 [==============================] - 24s 42ms/step - loss: 13102.8945 - mae: 16.8329 - val_loss: 30576.5195 - val_mae: 26.6248\n","Epoch 21/40\n","564/564 [==============================] - 24s 42ms/step - loss: 12964.6143 - mae: 17.4693 - val_loss: 32132.4648 - val_mae: 32.2582\n","Epoch 22/40\n","564/564 [==============================] - 24s 42ms/step - loss: 12809.6777 - mae: 16.4827 - val_loss: 31889.5430 - val_mae: 20.1644\n","Epoch 23/40\n","564/564 [==============================] - 25s 45ms/step - loss: 12770.9873 - mae: 16.9930 - val_loss: 31155.0195 - val_mae: 28.7527\n","Epoch 24/40\n","564/564 [==============================] - 24s 42ms/step - loss: 12789.5811 - mae: 16.3941 - val_loss: 30226.4512 - val_mae: 24.0798\n","Epoch 25/40\n","564/564 [==============================] - 24s 42ms/step - loss: 12712.3643 - mae: 16.7647 - val_loss: 31429.6035 - val_mae: 23.3418\n","Epoch 26/40\n","564/564 [==============================] - 24s 42ms/step - loss: 12878.2471 - mae: 16.3341 - val_loss: 29933.2363 - val_mae: 24.1659\n","Epoch 27/40\n","564/564 [==============================] - 24s 42ms/step - loss: 12757.6406 - mae: 16.8855 - val_loss: 30210.6602 - val_mae: 19.8610\n","Epoch 28/40\n","564/564 [==============================] - 23s 41ms/step - loss: 12846.8369 - mae: 17.0222 - val_loss: 30898.9023 - val_mae: 29.9100\n","Epoch 29/40\n","564/564 [==============================] - 25s 45ms/step - loss: 12524.0654 - mae: 16.3961 - val_loss: 30933.1934 - val_mae: 30.0943\n","Epoch 30/40\n","564/564 [==============================] - 24s 43ms/step - loss: 12860.6582 - mae: 17.4970 - val_loss: 30762.8105 - val_mae: 27.0810\n","Epoch 31/40\n","564/564 [==============================] - 24s 42ms/step - loss: 12663.6582 - mae: 17.0038 - val_loss: 31050.3477 - val_mae: 19.7099\n","Epoch 32/40\n","564/564 [==============================] - 24s 42ms/step - loss: 12710.2822 - mae: 16.6877 - val_loss: 30892.5000 - val_mae: 26.9398\n","Epoch 33/40\n","564/564 [==============================] - 23s 42ms/step - loss: 12686.8340 - mae: 16.9528 - val_loss: 31466.5391 - val_mae: 24.7144\n","Epoch 34/40\n","564/564 [==============================] - 23s 42ms/step - loss: 12591.5010 - mae: 17.1106 - val_loss: 31364.4258 - val_mae: 29.2095\n","Epoch 35/40\n","564/564 [==============================] - 25s 45ms/step - loss: 12579.6260 - mae: 16.3991 - val_loss: 30303.9688 - val_mae: 21.8102\n","Epoch 36/40\n","564/564 [==============================] - 24s 42ms/step - loss: 12717.1924 - mae: 17.1550 - val_loss: 30954.1875 - val_mae: 27.8870\n","Epoch 37/40\n","564/564 [==============================] - 24s 42ms/step - loss: 12536.3271 - mae: 16.6852 - val_loss: 30360.3516 - val_mae: 21.0694\n","Epoch 38/40\n","564/564 [==============================] - 24s 42ms/step - loss: 12465.2646 - mae: 17.0219 - val_loss: 31039.4355 - val_mae: 28.0173\n","Epoch 39/40\n","564/564 [==============================] - 24s 42ms/step - loss: 12524.5820 - mae: 16.8483 - val_loss: 30834.0586 - val_mae: 19.4587\n","Epoch 40/40\n","564/564 [==============================] - 24s 42ms/step - loss: 12649.6436 - mae: 16.8791 - val_loss: 30892.3086 - val_mae: 33.0761\n","45.1519348303553\n","0.4196489230040025\n","0.9371513512699378\n","start group1,This is the experiment num: 1\n","\n","---------------------------------------------- domain num 0 is running----------------------------------\n","start training\n","Epoch 1/40\n","564/564 [==============================] - 25s 42ms/step - loss: 13928.1279 - mae: 16.5841 - val_loss: 33349.1484 - val_mae: 25.5875\n","Epoch 2/40\n","564/564 [==============================] - 23s 41ms/step - loss: 13581.1240 - mae: 18.0435 - val_loss: 30904.9648 - val_mae: 23.5383\n","Epoch 3/40\n","564/564 [==============================] - 23s 41ms/step - loss: 13395.9775 - mae: 16.8669 - val_loss: 31515.7910 - val_mae: 24.1206\n","Epoch 4/40\n","564/564 [==============================] - 23s 41ms/step - loss: 13244.9365 - mae: 15.3075 - val_loss: 29646.5117 - val_mae: 32.0177\n","Epoch 5/40\n","564/564 [==============================] - 26s 46ms/step - loss: 13151.5547 - mae: 15.6395 - val_loss: 31961.0352 - val_mae: 19.7237\n","Epoch 6/40\n","564/564 [==============================] - 23s 41ms/step - loss: 13228.1904 - mae: 15.2797 - val_loss: 29804.9375 - val_mae: 25.4331\n","Epoch 7/40\n","564/564 [==============================] - 24s 42ms/step - loss: 13157.1387 - mae: 15.6536 - val_loss: 31770.8262 - val_mae: 25.7364\n","Epoch 8/40\n","564/564 [==============================] - 24s 43ms/step - loss: 13018.2715 - mae: 15.5758 - val_loss: 31308.8086 - val_mae: 21.1926\n","Epoch 9/40\n","564/564 [==============================] - 24s 43ms/step - loss: 13122.9678 - mae: 16.2660 - val_loss: 31006.3066 - val_mae: 24.3181\n","Epoch 10/40\n","564/564 [==============================] - 24s 42ms/step - loss: 13054.0557 - mae: 16.1141 - val_loss: 30331.5723 - val_mae: 29.3779\n","Epoch 11/40\n","564/564 [==============================] - 26s 46ms/step - loss: 13244.4268 - mae: 16.0426 - val_loss: 30876.6406 - val_mae: 35.3221\n","Epoch 12/40\n","564/564 [==============================] - 24s 42ms/step - loss: 13188.4121 - mae: 16.3967 - val_loss: 30637.9531 - val_mae: 19.9394\n","Epoch 13/40\n","564/564 [==============================] - 24s 43ms/step - loss: 12992.2539 - mae: 16.2341 - val_loss: 30819.2598 - val_mae: 31.2815\n","Epoch 14/40\n","564/564 [==============================] - 25s 44ms/step - loss: 13077.3643 - mae: 16.2604 - val_loss: 29594.1445 - val_mae: 23.4864\n","Epoch 15/40\n","564/564 [==============================] - 25s 44ms/step - loss: 12935.9766 - mae: 16.6362 - val_loss: 29975.7285 - val_mae: 26.9506\n","Epoch 16/40\n","564/564 [==============================] - 26s 46ms/step - loss: 13033.1904 - mae: 16.7666 - val_loss: 29679.5898 - val_mae: 21.0608\n","Epoch 17/40\n","564/564 [==============================] - 24s 43ms/step - loss: 13022.0029 - mae: 16.7869 - val_loss: 31325.9766 - val_mae: 34.5879\n","Epoch 18/40\n","564/564 [==============================] - 24s 43ms/step - loss: 12993.3105 - mae: 16.6620 - val_loss: 30891.9316 - val_mae: 19.4924\n","Epoch 19/40\n","564/564 [==============================] - 24s 43ms/step - loss: 12894.7529 - mae: 16.5216 - val_loss: 29910.3555 - val_mae: 27.2622\n","Epoch 20/40\n","564/564 [==============================] - 24s 43ms/step - loss: 12875.5410 - mae: 16.4768 - val_loss: 30098.2988 - val_mae: 20.6895\n","Epoch 21/40\n","564/564 [==============================] - 24s 42ms/step - loss: 12894.8301 - mae: 16.7362 - val_loss: 30137.9492 - val_mae: 26.8142\n","Epoch 22/40\n","564/564 [==============================] - 26s 45ms/step - loss: 12857.0410 - mae: 16.7757 - val_loss: 30808.1270 - val_mae: 27.4943\n","Epoch 23/40\n","564/564 [==============================] - 24s 42ms/step - loss: 12787.3623 - mae: 16.7179 - val_loss: 29487.2305 - val_mae: 22.2721\n","Epoch 24/40\n","564/564 [==============================] - 24s 42ms/step - loss: 12787.1182 - mae: 16.7569 - val_loss: 30395.6465 - val_mae: 27.9921\n","Epoch 25/40\n","564/564 [==============================] - 24s 43ms/step - loss: 12774.1934 - mae: 17.0650 - val_loss: 29966.4746 - val_mae: 25.3015\n","Epoch 26/40\n","564/564 [==============================] - 24s 43ms/step - loss: 12679.6641 - mae: 16.6188 - val_loss: 30541.1816 - val_mae: 27.9695\n","Epoch 27/40\n","564/564 [==============================] - 24s 42ms/step - loss: 12536.1875 - mae: 16.6548 - val_loss: 30435.7363 - val_mae: 20.0617\n","Epoch 28/40\n","564/564 [==============================] - 26s 46ms/step - loss: 12669.6494 - mae: 16.5314 - val_loss: 30076.5586 - val_mae: 20.4732\n","Epoch 29/40\n","564/564 [==============================] - 24s 42ms/step - loss: 12670.8916 - mae: 16.6745 - val_loss: 30810.5273 - val_mae: 21.2973\n","Epoch 30/40\n","564/564 [==============================] - 24s 42ms/step - loss: 12503.0146 - mae: 17.3658 - val_loss: 32088.7734 - val_mae: 31.2622\n","Epoch 31/40\n","564/564 [==============================] - 23s 42ms/step - loss: 12540.1699 - mae: 16.8018 - val_loss: 31767.6934 - val_mae: 27.3869\n","Epoch 32/40\n","564/564 [==============================] - 23s 42ms/step - loss: 12556.5527 - mae: 16.9393 - val_loss: 30706.4336 - val_mae: 23.2471\n","Epoch 33/40\n","564/564 [==============================] - 24s 42ms/step - loss: 12474.8496 - mae: 16.8558 - val_loss: 30847.6699 - val_mae: 24.8005\n","Epoch 34/40\n","564/564 [==============================] - 25s 45ms/step - loss: 12552.2598 - mae: 17.0663 - val_loss: 30005.8438 - val_mae: 21.3084\n","Epoch 35/40\n","564/564 [==============================] - 24s 42ms/step - loss: 12567.2275 - mae: 17.0434 - val_loss: 30752.5547 - val_mae: 28.3701\n","Epoch 36/40\n","564/564 [==============================] - 23s 41ms/step - loss: 12558.0312 - mae: 16.9900 - val_loss: 30567.8555 - val_mae: 26.5257\n","Epoch 37/40\n","564/564 [==============================] - 23s 41ms/step - loss: 12498.3076 - mae: 16.8779 - val_loss: 31062.8848 - val_mae: 19.6227\n","Epoch 38/40\n","564/564 [==============================] - 23s 41ms/step - loss: 12370.6357 - mae: 17.0176 - val_loss: 31856.1406 - val_mae: 25.5048\n","Epoch 39/40\n","564/564 [==============================] - 25s 45ms/step - loss: 12447.3682 - mae: 16.9447 - val_loss: 31059.1797 - val_mae: 26.0079\n","Epoch 40/40\n","564/564 [==============================] - 26s 46ms/step - loss: 12627.8320 - mae: 17.4264 - val_loss: 29952.5254 - val_mae: 21.4790\n","34.2748001742855\n","0.7550950353512745\n","0.9234220428081984\n","start group1,This is the experiment num: 2\n","\n","---------------------------------------------- domain num 0 is running----------------------------------\n","start training\n","Epoch 1/40\n","564/564 [==============================] - 29s 49ms/step - loss: 13966.5840 - mae: 17.0613 - val_loss: 33630.6758 - val_mae: 22.6374\n","Epoch 2/40\n","564/564 [==============================] - 28s 50ms/step - loss: 13477.3330 - mae: 18.1978 - val_loss: 31546.8262 - val_mae: 25.3516\n","Epoch 3/40\n","564/564 [==============================] - 27s 48ms/step - loss: 13491.0029 - mae: 16.8712 - val_loss: 30697.6797 - val_mae: 25.7275\n","Epoch 4/40\n","564/564 [==============================] - 29s 52ms/step - loss: 13441.3320 - mae: 16.1348 - val_loss: 30038.5547 - val_mae: 24.1688\n","Epoch 5/40\n","564/564 [==============================] - 27s 47ms/step - loss: 13295.5020 - mae: 16.0871 - val_loss: 31322.7617 - val_mae: 27.7713\n","Epoch 6/40\n","564/564 [==============================] - 28s 50ms/step - loss: 13130.3916 - mae: 15.5245 - val_loss: 31287.5371 - val_mae: 23.9489\n","Epoch 7/40\n","564/564 [==============================] - 28s 49ms/step - loss: 13164.0986 - mae: 15.3748 - val_loss: 29835.7402 - val_mae: 28.2112\n","Epoch 8/40\n","564/564 [==============================] - 28s 49ms/step - loss: 13031.2656 - mae: 15.9557 - val_loss: 30729.0527 - val_mae: 22.0296\n","Epoch 9/40\n","564/564 [==============================] - 30s 54ms/step - loss: 13071.4668 - mae: 16.0341 - val_loss: 31446.5469 - val_mae: 24.3315\n","Epoch 10/40\n","564/564 [==============================] - 28s 50ms/step - loss: 12965.7588 - mae: 15.8496 - val_loss: 29337.3203 - val_mae: 19.8802\n","Epoch 11/40\n","564/564 [==============================] - 31s 54ms/step - loss: 12911.9131 - mae: 16.2209 - val_loss: 31230.0605 - val_mae: 22.8276\n","Epoch 12/40\n","564/564 [==============================] - 32s 56ms/step - loss: 12983.0039 - mae: 16.3582 - val_loss: 30800.9648 - val_mae: 25.0023\n","Epoch 13/40\n","564/564 [==============================] - 30s 53ms/step - loss: 13021.4199 - mae: 16.4566 - val_loss: 29403.4062 - val_mae: 35.6466\n","Epoch 14/40\n","564/564 [==============================] - 28s 50ms/step - loss: 13071.8975 - mae: 16.8048 - val_loss: 31035.3906 - val_mae: 33.1921\n","Epoch 15/40\n","564/564 [==============================] - 29s 51ms/step - loss: 12964.1836 - mae: 16.5869 - val_loss: 30763.1230 - val_mae: 22.5144\n","Epoch 16/40\n","564/564 [==============================] - 31s 56ms/step - loss: 12820.1846 - mae: 16.5849 - val_loss: 30499.6758 - val_mae: 19.9891\n","Epoch 17/40\n","564/564 [==============================] - 30s 52ms/step - loss: 12866.4014 - mae: 16.6623 - val_loss: 30575.9668 - val_mae: 23.3715\n","Epoch 18/40\n","564/564 [==============================] - 30s 53ms/step - loss: 12720.4414 - mae: 16.6422 - val_loss: 30008.9375 - val_mae: 20.2939\n","Epoch 19/40\n","564/564 [==============================] - 29s 52ms/step - loss: 12694.1191 - mae: 16.5347 - val_loss: 30898.9023 - val_mae: 20.3144\n","Epoch 20/40\n","564/564 [==============================] - 30s 54ms/step - loss: 12953.3867 - mae: 16.9483 - val_loss: 30331.2656 - val_mae: 33.2565\n","Epoch 21/40\n","564/564 [==============================] - 29s 52ms/step - loss: 12811.4014 - mae: 16.8381 - val_loss: 31060.9062 - val_mae: 19.7898\n","Epoch 22/40\n","564/564 [==============================] - 31s 55ms/step - loss: 12848.4424 - mae: 16.7026 - val_loss: 30126.3965 - val_mae: 19.5464\n","Epoch 23/40\n","564/564 [==============================] - 29s 51ms/step - loss: 12611.4170 - mae: 16.6853 - val_loss: 30701.7832 - val_mae: 25.2225\n","Epoch 24/40\n","564/564 [==============================] - 28s 50ms/step - loss: 12741.8125 - mae: 16.9061 - val_loss: 29965.9453 - val_mae: 20.0758\n","Epoch 25/40\n","564/564 [==============================] - 29s 51ms/step - loss: 12809.3848 - mae: 17.1373 - val_loss: 29705.2051 - val_mae: 20.2726\n","Epoch 26/40\n","564/564 [==============================] - 31s 55ms/step - loss: 12718.3135 - mae: 17.0294 - val_loss: 30718.3848 - val_mae: 25.5105\n","Epoch 27/40\n","564/564 [==============================] - 33s 58ms/step - loss: 12778.4072 - mae: 17.4446 - val_loss: 30637.7246 - val_mae: 29.2021\n","Epoch 28/40\n","564/564 [==============================] - 31s 55ms/step - loss: 12679.6611 - mae: 17.3750 - val_loss: 30614.8203 - val_mae: 25.7951\n","Epoch 29/40\n","564/564 [==============================] - 31s 55ms/step - loss: 12560.5918 - mae: 17.0298 - val_loss: 29905.0879 - val_mae: 27.9668\n","Epoch 30/40\n","564/564 [==============================] - 31s 55ms/step - loss: 12626.2334 - mae: 17.9079 - val_loss: 30142.5117 - val_mae: 20.3631\n","Epoch 31/40\n","564/564 [==============================] - 33s 58ms/step - loss: 12703.7881 - mae: 17.0800 - val_loss: 31067.0879 - val_mae: 25.7965\n","Epoch 32/40\n","564/564 [==============================] - 31s 55ms/step - loss: 12571.8770 - mae: 17.4919 - val_loss: 30267.4902 - val_mae: 20.9007\n","Epoch 33/40\n","564/564 [==============================] - 31s 54ms/step - loss: 12576.0049 - mae: 17.2552 - val_loss: 30931.3477 - val_mae: 33.5972\n","Epoch 34/40\n","564/564 [==============================] - 30s 53ms/step - loss: 12495.4326 - mae: 17.4984 - val_loss: 30836.9316 - val_mae: 29.3530\n","Epoch 35/40\n","564/564 [==============================] - 29s 51ms/step - loss: 12554.1523 - mae: 17.0095 - val_loss: 30363.8164 - val_mae: 21.3375\n","Epoch 36/40\n","564/564 [==============================] - 32s 57ms/step - loss: 12599.4541 - mae: 18.0170 - val_loss: 29961.0977 - val_mae: 20.0236\n","Epoch 37/40\n","564/564 [==============================] - 34s 60ms/step - loss: 12504.1602 - mae: 17.2951 - val_loss: 31491.9199 - val_mae: 21.8557\n","Epoch 38/40\n","564/564 [==============================] - 32s 56ms/step - loss: 12409.1396 - mae: 17.6499 - val_loss: 31571.3301 - val_mae: 27.8002\n","Epoch 39/40\n","564/564 [==============================] - 31s 55ms/step - loss: 12321.5518 - mae: 17.2543 - val_loss: 31145.6523 - val_mae: 31.5298\n","Epoch 40/40\n","564/564 [==============================] - 30s 54ms/step - loss: 12403.7803 - mae: 17.5025 - val_loss: 30843.5645 - val_mae: 29.7317\n","42.56162144665355\n","0.5081105089398568\n","0.9377134711170092\n","start group1,This is the experiment num: 3\n","\n","---------------------------------------------- domain num 0 is running----------------------------------\n","start training\n","Epoch 1/40\n","564/564 [==============================] - 39s 67ms/step - loss: 13874.0176 - mae: 16.5050 - val_loss: 33824.6758 - val_mae: 26.6142\n","Epoch 2/40\n","564/564 [==============================] - 35s 62ms/step - loss: 13731.9141 - mae: 19.6753 - val_loss: 32119.4883 - val_mae: 29.5072\n","Epoch 3/40\n","564/564 [==============================] - 34s 60ms/step - loss: 13309.4316 - mae: 16.2574 - val_loss: 31899.9727 - val_mae: 26.0173\n","Epoch 4/40\n","564/564 [==============================] - 36s 64ms/step - loss: 13311.6328 - mae: 16.5276 - val_loss: 32421.3203 - val_mae: 25.1223\n","Epoch 5/40\n","564/564 [==============================] - 35s 62ms/step - loss: 13229.0654 - mae: 16.3429 - val_loss: 29504.5234 - val_mae: 20.1190\n","Epoch 6/40\n","564/564 [==============================] - 35s 62ms/step - loss: 13214.0811 - mae: 15.7398 - val_loss: 30044.0586 - val_mae: 19.7575\n","Epoch 7/40\n","564/564 [==============================] - 35s 63ms/step - loss: 13124.8271 - mae: 15.6839 - val_loss: 31646.5898 - val_mae: 25.2068\n","Epoch 8/40\n","564/564 [==============================] - 37s 66ms/step - loss: 13101.8545 - mae: 15.3868 - val_loss: 29904.8887 - val_mae: 24.3521\n","Epoch 9/40\n","564/564 [==============================] - 35s 61ms/step - loss: 13009.2451 - mae: 15.6965 - val_loss: 31003.0352 - val_mae: 21.7692\n","Epoch 10/40\n","564/564 [==============================] - 35s 62ms/step - loss: 12963.5830 - mae: 15.9597 - val_loss: 30746.2402 - val_mae: 23.9912\n","Epoch 11/40\n","564/564 [==============================] - 35s 62ms/step - loss: 12876.5400 - mae: 16.2231 - val_loss: 31134.3633 - val_mae: 31.1079\n","Epoch 12/40\n","564/564 [==============================] - 37s 65ms/step - loss: 13141.7852 - mae: 16.3462 - val_loss: 30802.0039 - val_mae: 24.5762\n","Epoch 13/40\n","564/564 [==============================] - 35s 62ms/step - loss: 13020.5879 - mae: 16.0708 - val_loss: 29804.0352 - val_mae: 21.1207\n","Epoch 14/40\n","564/564 [==============================] - 36s 63ms/step - loss: 12899.0684 - mae: 16.4848 - val_loss: 31683.6367 - val_mae: 20.2437\n","Epoch 15/40\n","564/564 [==============================] - 35s 62ms/step - loss: 13114.8018 - mae: 16.7032 - val_loss: 31055.6680 - val_mae: 22.9397\n","Epoch 16/40\n","564/564 [==============================] - 37s 66ms/step - loss: 12990.4307 - mae: 16.7064 - val_loss: 30113.4375 - val_mae: 20.9545\n","Epoch 17/40\n","564/564 [==============================] - 36s 64ms/step - loss: 13087.7266 - mae: 16.5183 - val_loss: 30810.8125 - val_mae: 20.5199\n","Epoch 18/40\n","564/564 [==============================] - 36s 64ms/step - loss: 12906.8076 - mae: 16.9857 - val_loss: 31126.5938 - val_mae: 31.9987\n","Epoch 19/40\n","564/564 [==============================] - 35s 63ms/step - loss: 12912.2559 - mae: 16.6038 - val_loss: 30519.7500 - val_mae: 23.2693\n","Epoch 20/40\n","564/564 [==============================] - 38s 68ms/step - loss: 12760.1904 - mae: 16.8623 - val_loss: 30813.6387 - val_mae: 40.0730\n","Epoch 21/40\n","564/564 [==============================] - 36s 63ms/step - loss: 12666.5264 - mae: 17.0262 - val_loss: 31051.3008 - val_mae: 27.4666\n","Epoch 22/40\n","564/564 [==============================] - 35s 62ms/step - loss: 12848.3184 - mae: 17.3231 - val_loss: 31994.3887 - val_mae: 30.6949\n","Epoch 23/40\n","564/564 [==============================] - 34s 61ms/step - loss: 12533.7764 - mae: 16.3578 - val_loss: 29962.3984 - val_mae: 25.4242\n","Epoch 24/40\n","564/564 [==============================] - 36s 63ms/step - loss: 12693.5947 - mae: 16.6742 - val_loss: 31081.0547 - val_mae: 24.0269\n","Epoch 25/40\n","564/564 [==============================] - 34s 61ms/step - loss: 12773.2549 - mae: 17.4018 - val_loss: 30890.2422 - val_mae: 20.1619\n","Epoch 26/40\n","564/564 [==============================] - 34s 60ms/step - loss: 12767.1611 - mae: 17.2630 - val_loss: 30691.7148 - val_mae: 19.8151\n","Epoch 27/40\n","564/564 [==============================] - 33s 59ms/step - loss: 12597.4717 - mae: 17.1310 - val_loss: 30658.9824 - val_mae: 23.0276\n","Epoch 28/40\n","564/564 [==============================] - 35s 62ms/step - loss: 12593.8350 - mae: 17.2588 - val_loss: 30963.2441 - val_mae: 20.0295\n","Epoch 29/40\n","564/564 [==============================] - 34s 60ms/step - loss: 12633.5088 - mae: 17.2835 - val_loss: 30634.6680 - val_mae: 19.8257\n","Epoch 30/40\n","564/564 [==============================] - 34s 61ms/step - loss: 12496.3555 - mae: 16.9354 - val_loss: 30749.2266 - val_mae: 20.3426\n","Epoch 31/40\n","564/564 [==============================] - 34s 61ms/step - loss: 12588.4766 - mae: 17.1636 - val_loss: 31446.0273 - val_mae: 24.9598\n","Epoch 32/40\n","564/564 [==============================] - 36s 64ms/step - loss: 12539.7070 - mae: 17.7898 - val_loss: 30323.0840 - val_mae: 26.7465\n","Epoch 33/40\n","564/564 [==============================] - 34s 61ms/step - loss: 12573.4414 - mae: 17.0730 - val_loss: 30881.8105 - val_mae: 22.5639\n","Epoch 34/40\n","564/564 [==============================] - 34s 61ms/step - loss: 12552.7266 - mae: 17.4628 - val_loss: 31505.2305 - val_mae: 29.1793\n","Epoch 35/40\n","564/564 [==============================] - 34s 60ms/step - loss: 12589.6729 - mae: 18.1141 - val_loss: 31057.0703 - val_mae: 22.0152\n","Epoch 36/40\n","564/564 [==============================] - 35s 62ms/step - loss: 12571.2812 - mae: 17.5286 - val_loss: 30805.2793 - val_mae: 23.5356\n","Epoch 37/40\n","564/564 [==============================] - 36s 63ms/step - loss: 12651.2529 - mae: 17.1662 - val_loss: 31674.0898 - val_mae: 26.3088\n","Epoch 38/40\n","564/564 [==============================] - 34s 61ms/step - loss: 12493.5410 - mae: 17.9671 - val_loss: 30836.3867 - val_mae: 22.8167\n","Epoch 39/40\n","564/564 [==============================] - 35s 62ms/step - loss: 12651.5244 - mae: 17.4711 - val_loss: 30625.1289 - val_mae: 22.1530\n","Epoch 40/40\n","564/564 [==============================] - 35s 62ms/step - loss: 12563.0527 - mae: 17.5459 - val_loss: 31663.5371 - val_mae: 21.0414\n","33.155599101703274\n","0.9388666114783021\n","0.9512237933464041\n","start group1,This is the experiment num: 4\n","\n","---------------------------------------------- domain num 0 is running----------------------------------\n","start training\n","Epoch 1/40\n","564/564 [==============================] - 39s 66ms/step - loss: 13957.5098 - mae: 16.4558 - val_loss: 34024.1445 - val_mae: 24.7505\n","Epoch 2/40\n","564/564 [==============================] - 37s 65ms/step - loss: 13514.4893 - mae: 17.6012 - val_loss: 31340.2207 - val_mae: 27.8970\n","Epoch 3/40\n","564/564 [==============================] - 38s 68ms/step - loss: 13384.3779 - mae: 16.7124 - val_loss: 30651.4395 - val_mae: 24.3436\n","Epoch 4/40\n","564/564 [==============================] - 37s 65ms/step - loss: 13336.1143 - mae: 17.0320 - val_loss: 31862.6680 - val_mae: 19.8612\n","Epoch 5/40\n","564/564 [==============================] - 36s 65ms/step - loss: 13070.8105 - mae: 14.9923 - val_loss: 30986.8984 - val_mae: 21.0980\n","Epoch 6/40\n","564/564 [==============================] - 37s 66ms/step - loss: 13312.0137 - mae: 15.7256 - val_loss: 30323.5176 - val_mae: 22.6577\n","Epoch 7/40\n","564/564 [==============================] - 39s 68ms/step - loss: 13071.2744 - mae: 15.7592 - val_loss: 30627.3809 - val_mae: 21.4057\n","Epoch 8/40\n","564/564 [==============================] - 37s 66ms/step - loss: 12997.6221 - mae: 15.5965 - val_loss: 32501.3848 - val_mae: 27.5965\n","Epoch 9/40\n","564/564 [==============================] - 38s 67ms/step - loss: 13042.1055 - mae: 16.2018 - val_loss: 31816.8027 - val_mae: 29.6215\n","Epoch 10/40\n","564/564 [==============================] - 37s 66ms/step - loss: 12862.4170 - mae: 15.9979 - val_loss: 31437.1973 - val_mae: 23.5066\n","Epoch 11/40\n","564/564 [==============================] - 39s 70ms/step - loss: 13021.6680 - mae: 16.2882 - val_loss: 31008.7461 - val_mae: 21.1676\n","Epoch 12/40\n","564/564 [==============================] - 37s 66ms/step - loss: 13013.0303 - mae: 16.5034 - val_loss: 31584.5215 - val_mae: 29.0897\n","Epoch 13/40\n","564/564 [==============================] - 37s 66ms/step - loss: 13051.9844 - mae: 16.8254 - val_loss: 32159.4961 - val_mae: 27.3106\n","Epoch 14/40\n","564/564 [==============================] - 37s 66ms/step - loss: 12974.1992 - mae: 16.1951 - val_loss: 30393.0039 - val_mae: 25.4370\n","Epoch 15/40\n","564/564 [==============================] - 38s 68ms/step - loss: 13074.8604 - mae: 16.8095 - val_loss: 30303.8145 - val_mae: 28.9460\n","Epoch 16/40\n","564/564 [==============================] - 37s 65ms/step - loss: 13139.1934 - mae: 16.9797 - val_loss: 31115.9258 - val_mae: 25.0685\n","Epoch 17/40\n","564/564 [==============================] - 37s 65ms/step - loss: 13011.5254 - mae: 16.7029 - val_loss: 29984.0293 - val_mae: 21.5206\n","Epoch 18/40\n","564/564 [==============================] - 37s 65ms/step - loss: 12813.4443 - mae: 16.7298 - val_loss: 30488.8789 - val_mae: 24.3530\n","Epoch 19/40\n","564/564 [==============================] - 37s 66ms/step - loss: 12745.3838 - mae: 16.5456 - val_loss: 29771.2227 - val_mae: 21.2164\n","Epoch 20/40\n","564/564 [==============================] - 36s 64ms/step - loss: 12896.1992 - mae: 17.1160 - val_loss: 30353.1738 - val_mae: 30.2864\n","Epoch 21/40\n","564/564 [==============================] - 36s 64ms/step - loss: 12638.3262 - mae: 16.5028 - val_loss: 29961.7559 - val_mae: 21.2489\n","Epoch 22/40\n","564/564 [==============================] - 34s 61ms/step - loss: 12812.0947 - mae: 16.8572 - val_loss: 29274.5137 - val_mae: 21.5101\n","Epoch 23/40\n","564/564 [==============================] - 36s 64ms/step - loss: 12755.0957 - mae: 16.8053 - val_loss: 29649.3594 - val_mae: 25.3951\n","Epoch 24/40\n","564/564 [==============================] - 35s 61ms/step - loss: 12643.1191 - mae: 17.4500 - val_loss: 31702.3262 - val_mae: 20.8852\n","Epoch 25/40\n","564/564 [==============================] - 35s 61ms/step - loss: 12783.6992 - mae: 16.8520 - val_loss: 30298.1094 - val_mae: 20.5811\n","Epoch 26/40\n","564/564 [==============================] - 35s 62ms/step - loss: 12733.5127 - mae: 16.9061 - val_loss: 30535.3965 - val_mae: 24.6663\n","Epoch 27/40\n","564/564 [==============================] - 36s 64ms/step - loss: 12747.0674 - mae: 17.3011 - val_loss: 30178.0410 - val_mae: 20.0039\n","Epoch 28/40\n","564/564 [==============================] - 35s 62ms/step - loss: 12548.0166 - mae: 17.0212 - val_loss: 30435.8066 - val_mae: 30.6229\n","Epoch 29/40\n","564/564 [==============================] - 34s 61ms/step - loss: 12618.2812 - mae: 17.0900 - val_loss: 31254.3867 - val_mae: 27.4652\n","Epoch 30/40\n","564/564 [==============================] - 35s 62ms/step - loss: 12531.3789 - mae: 16.7606 - val_loss: 32013.4023 - val_mae: 26.0723\n","Epoch 31/40\n","564/564 [==============================] - 37s 66ms/step - loss: 12525.6270 - mae: 17.4665 - val_loss: 31185.0488 - val_mae: 30.9911\n","Epoch 32/40\n","564/564 [==============================] - 36s 64ms/step - loss: 12631.2822 - mae: 17.0452 - val_loss: 30598.1074 - val_mae: 20.0760\n","Epoch 33/40\n","564/564 [==============================] - 36s 64ms/step - loss: 12510.8076 - mae: 17.2696 - val_loss: 32834.5000 - val_mae: 22.1706\n","Epoch 34/40\n","564/564 [==============================] - 36s 63ms/step - loss: 12483.2520 - mae: 17.1547 - val_loss: 30362.6348 - val_mae: 24.1175\n","Epoch 35/40\n","564/564 [==============================] - 38s 68ms/step - loss: 12378.2061 - mae: 17.2391 - val_loss: 31677.0215 - val_mae: 24.0809\n","Epoch 36/40\n","564/564 [==============================] - 37s 65ms/step - loss: 12571.4570 - mae: 16.9412 - val_loss: 30157.4336 - val_mae: 19.5949\n","Epoch 37/40\n","564/564 [==============================] - 37s 66ms/step - loss: 12534.7090 - mae: 17.7321 - val_loss: 30791.2969 - val_mae: 25.6832\n","Epoch 38/40\n","564/564 [==============================] - 38s 67ms/step - loss: 12513.2666 - mae: 17.5251 - val_loss: 31252.2383 - val_mae: 20.3710\n","Epoch 39/40\n","564/564 [==============================] - 39s 69ms/step - loss: 12481.8760 - mae: 17.6534 - val_loss: 31929.7148 - val_mae: 24.8479\n","Epoch 40/40\n","564/564 [==============================] - 38s 67ms/step - loss: 12512.7715 - mae: 18.0092 - val_loss: 30941.5391 - val_mae: 22.1278\n","35.37287491752696\n","0.9767472486735043\n","0.9392753249176269\n","start group2,This is the experiment num: 0\n","\n","---------------------------------------------- domain num 0 is running----------------------------------\n","start training\n","Epoch 1/40\n","939/939 [==============================] - 65s 67ms/step - loss: 14208.2217 - mae: 18.6312 - val_loss: 61769.8633 - val_mae: 29.6898\n","Epoch 2/40\n","939/939 [==============================] - 60s 64ms/step - loss: 14069.8691 - mae: 18.2326 - val_loss: 58688.7070 - val_mae: 48.3495\n","Epoch 3/40\n","939/939 [==============================] - 59s 63ms/step - loss: 13967.0264 - mae: 16.9819 - val_loss: 62359.1953 - val_mae: 40.2794\n","Epoch 4/40\n","939/939 [==============================] - 58s 62ms/step - loss: 13904.3008 - mae: 16.4691 - val_loss: 65417.4492 - val_mae: 39.6675\n","Epoch 5/40\n","939/939 [==============================] - 60s 64ms/step - loss: 13825.2871 - mae: 16.1994 - val_loss: 67317.0703 - val_mae: 31.1871\n","Epoch 6/40\n","939/939 [==============================] - 60s 64ms/step - loss: 13856.1436 - mae: 16.7391 - val_loss: 64961.0664 - val_mae: 44.5841\n","Epoch 7/40\n","939/939 [==============================] - 56s 60ms/step - loss: 13761.2773 - mae: 16.7235 - val_loss: 66449.8750 - val_mae: 41.4579\n","Epoch 8/40\n","939/939 [==============================] - 58s 61ms/step - loss: 13844.0693 - mae: 16.9141 - val_loss: 64862.1914 - val_mae: 33.9872\n","Epoch 9/40\n","939/939 [==============================] - 59s 63ms/step - loss: 13743.7090 - mae: 16.9860 - val_loss: 70394.4453 - val_mae: 41.9217\n","Epoch 10/40\n","939/939 [==============================] - 60s 64ms/step - loss: 13744.4365 - mae: 17.1102 - val_loss: 63040.4375 - val_mae: 35.6278\n","Epoch 11/40\n","939/939 [==============================] - 60s 64ms/step - loss: 13711.3047 - mae: 17.1345 - val_loss: 67084.0547 - val_mae: 34.4185\n","Epoch 12/40\n","939/939 [==============================] - 57s 61ms/step - loss: 13661.3467 - mae: 16.8255 - val_loss: 61964.8711 - val_mae: 32.1677\n","Epoch 13/40\n","939/939 [==============================] - 53s 57ms/step - loss: 13592.8594 - mae: 17.2156 - val_loss: 67151.6328 - val_mae: 40.7451\n","Epoch 14/40\n","939/939 [==============================] - 55s 58ms/step - loss: 13728.9395 - mae: 17.2073 - val_loss: 65246.5703 - val_mae: 33.3160\n","Epoch 15/40\n","939/939 [==============================] - 55s 58ms/step - loss: 13700.2070 - mae: 17.2239 - val_loss: 62680.7812 - val_mae: 51.7476\n","Epoch 16/40\n","939/939 [==============================] - 54s 58ms/step - loss: 13655.6934 - mae: 17.3944 - val_loss: 63027.8398 - val_mae: 32.1899\n","Epoch 17/40\n","939/939 [==============================] - 53s 56ms/step - loss: 13687.7549 - mae: 17.5622 - val_loss: 66502.6328 - val_mae: 60.7590\n","Epoch 18/40\n","939/939 [==============================] - 56s 59ms/step - loss: 13664.9600 - mae: 17.4250 - val_loss: 67632.2891 - val_mae: 33.0577\n","Epoch 19/40\n","939/939 [==============================] - 58s 62ms/step - loss: 13630.7314 - mae: 17.3633 - val_loss: 64914.2578 - val_mae: 35.3298\n","Epoch 20/40\n","939/939 [==============================] - 57s 61ms/step - loss: 13527.5283 - mae: 17.3452 - val_loss: 65474.4023 - val_mae: 44.4355\n","Epoch 21/40\n","939/939 [==============================] - 56s 60ms/step - loss: 13537.9590 - mae: 17.7240 - val_loss: 68682.9141 - val_mae: 38.8004\n","Epoch 22/40\n","939/939 [==============================] - 49s 52ms/step - loss: 13560.3604 - mae: 17.9268 - val_loss: 69093.0859 - val_mae: 37.6387\n","Epoch 23/40\n","939/939 [==============================] - 45s 48ms/step - loss: 13490.9141 - mae: 17.6359 - val_loss: 69270.7734 - val_mae: 53.0774\n","Epoch 24/40\n","939/939 [==============================] - 46s 49ms/step - loss: 13514.4531 - mae: 17.6235 - val_loss: 66717.1562 - val_mae: 40.8099\n","Epoch 25/40\n","939/939 [==============================] - 49s 53ms/step - loss: 13522.4307 - mae: 18.0226 - val_loss: 68222.8125 - val_mae: 34.2354\n","Epoch 26/40\n","939/939 [==============================] - 46s 48ms/step - loss: 13585.3564 - mae: 17.7012 - val_loss: 64514.5781 - val_mae: 44.7980\n","Epoch 27/40\n","939/939 [==============================] - 46s 49ms/step - loss: 13466.5947 - mae: 18.2002 - val_loss: 68073.2969 - val_mae: 44.7686\n","Epoch 28/40\n","939/939 [==============================] - 44s 47ms/step - loss: 13442.7549 - mae: 17.8357 - val_loss: 71999.5703 - val_mae: 33.0487\n","Epoch 29/40\n","939/939 [==============================] - 46s 49ms/step - loss: 13473.7783 - mae: 17.8601 - val_loss: 77920.4531 - val_mae: 51.6555\n","Epoch 30/40\n","939/939 [==============================] - 44s 47ms/step - loss: 13443.5215 - mae: 18.1372 - val_loss: 74732.2812 - val_mae: 41.3746\n","Epoch 31/40\n","939/939 [==============================] - 45s 47ms/step - loss: 13393.9473 - mae: 18.1118 - val_loss: 68564.1953 - val_mae: 37.0204\n","Epoch 32/40\n","939/939 [==============================] - 47s 50ms/step - loss: 13447.8584 - mae: 18.2907 - val_loss: 72340.4297 - val_mae: 44.6276\n","Epoch 33/40\n","939/939 [==============================] - 45s 48ms/step - loss: 13363.2031 - mae: 18.1446 - val_loss: 69292.1484 - val_mae: 42.0962\n","Epoch 34/40\n","939/939 [==============================] - 46s 49ms/step - loss: 13382.9727 - mae: 18.0841 - val_loss: 67245.7734 - val_mae: 34.2217\n","Epoch 35/40\n","939/939 [==============================] - 43s 46ms/step - loss: 13302.6602 - mae: 18.0634 - val_loss: 71528.8672 - val_mae: 36.4285\n","Epoch 36/40\n","939/939 [==============================] - 48s 51ms/step - loss: 13410.4150 - mae: 18.5933 - val_loss: 75490.6406 - val_mae: 34.8034\n","Epoch 37/40\n","939/939 [==============================] - 47s 50ms/step - loss: 13427.4316 - mae: 18.3862 - val_loss: 68880.0859 - val_mae: 35.8903\n","Epoch 38/40\n","939/939 [==============================] - 46s 49ms/step - loss: 13324.4160 - mae: 18.2859 - val_loss: 70773.3359 - val_mae: 36.4585\n","Epoch 39/40\n","939/939 [==============================] - 47s 50ms/step - loss: 13082.0898 - mae: 18.0724 - val_loss: 71586.3984 - val_mae: 34.3408\n","Epoch 40/40\n","939/939 [==============================] - 47s 50ms/step - loss: 13299.9941 - mae: 18.2282 - val_loss: 73090.2344 - val_mae: 35.0973\n","34.97199996188531\n","0.915569211077305\n","0.9136446862421658\n","start group2,This is the experiment num: 1\n","\n","---------------------------------------------- domain num 0 is running----------------------------------\n","start training\n","Epoch 1/40\n","939/939 [==============================] - 43s 44ms/step - loss: 14286.0605 - mae: 18.1942 - val_loss: 62677.1719 - val_mae: 35.0076\n","Epoch 2/40\n","939/939 [==============================] - 44s 47ms/step - loss: 14103.7637 - mae: 18.1632 - val_loss: 64596.7930 - val_mae: 33.9900\n","Epoch 3/40\n","939/939 [==============================] - 43s 46ms/step - loss: 13992.7500 - mae: 16.4286 - val_loss: 61594.5625 - val_mae: 36.9855\n","Epoch 4/40\n","939/939 [==============================] - 42s 45ms/step - loss: 13813.8457 - mae: 15.9156 - val_loss: 64337.9453 - val_mae: 33.6419\n","Epoch 5/40\n","939/939 [==============================] - 45s 48ms/step - loss: 13888.2441 - mae: 16.5718 - val_loss: 66566.0703 - val_mae: 38.0178\n","Epoch 6/40\n","939/939 [==============================] - 43s 46ms/step - loss: 13821.6133 - mae: 16.3096 - val_loss: 67150.9219 - val_mae: 32.2868\n","Epoch 7/40\n","939/939 [==============================] - 43s 46ms/step - loss: 13745.2236 - mae: 16.6571 - val_loss: 63155.0898 - val_mae: 33.4730\n","Epoch 8/40\n","939/939 [==============================] - 44s 46ms/step - loss: 13826.7959 - mae: 16.9270 - val_loss: 65494.4219 - val_mae: 31.4964\n","Epoch 9/40\n","939/939 [==============================] - 47s 51ms/step - loss: 13766.8789 - mae: 16.8385 - val_loss: 67125.8281 - val_mae: 37.8822\n","Epoch 10/40\n","939/939 [==============================] - 43s 46ms/step - loss: 13763.4736 - mae: 16.8689 - val_loss: 66270.4922 - val_mae: 40.7807\n","Epoch 11/40\n","939/939 [==============================] - 44s 47ms/step - loss: 13785.0205 - mae: 17.5873 - val_loss: 69839.0625 - val_mae: 31.9461\n","Epoch 12/40\n","939/939 [==============================] - 45s 48ms/step - loss: 13758.5166 - mae: 17.4075 - val_loss: 72499.9297 - val_mae: 33.2400\n","Epoch 13/40\n","939/939 [==============================] - 44s 47ms/step - loss: 13718.6250 - mae: 17.0186 - val_loss: 65508.3047 - val_mae: 39.7720\n","Epoch 14/40\n","939/939 [==============================] - 44s 46ms/step - loss: 13703.8887 - mae: 17.2869 - val_loss: 69187.8047 - val_mae: 34.6049\n","Epoch 15/40\n","939/939 [==============================] - 45s 48ms/step - loss: 13701.0264 - mae: 17.3702 - val_loss: 67580.1484 - val_mae: 43.9507\n","Epoch 16/40\n","939/939 [==============================] - 47s 50ms/step - loss: 13667.5967 - mae: 17.5679 - val_loss: 68777.7344 - val_mae: 38.1968\n","Epoch 17/40\n","939/939 [==============================] - 46s 49ms/step - loss: 13638.9844 - mae: 17.6373 - val_loss: 67582.3047 - val_mae: 36.2494\n","Epoch 18/40\n","939/939 [==============================] - 46s 49ms/step - loss: 13572.3984 - mae: 17.4544 - val_loss: 75558.5000 - val_mae: 43.5580\n","Epoch 19/40\n","939/939 [==============================] - 47s 50ms/step - loss: 13632.8057 - mae: 17.4303 - val_loss: 68077.1719 - val_mae: 34.7550\n","Epoch 20/40\n","939/939 [==============================] - 46s 49ms/step - loss: 13541.1729 - mae: 17.3431 - val_loss: 71808.6562 - val_mae: 35.0472\n","Epoch 21/40\n","939/939 [==============================] - 45s 47ms/step - loss: 13593.6318 - mae: 17.6274 - val_loss: 69969.2812 - val_mae: 33.9315\n","Epoch 22/40\n","939/939 [==============================] - 44s 47ms/step - loss: 13673.9062 - mae: 17.9124 - val_loss: 68651.1641 - val_mae: 32.0349\n","Epoch 23/40\n","939/939 [==============================] - 47s 50ms/step - loss: 13460.6592 - mae: 17.6495 - val_loss: 74475.9062 - val_mae: 42.8497\n","Epoch 24/40\n","939/939 [==============================] - 45s 48ms/step - loss: 13458.8604 - mae: 17.4185 - val_loss: 68963.3125 - val_mae: 43.0312\n","Epoch 25/40\n","939/939 [==============================] - 45s 48ms/step - loss: 13443.9932 - mae: 17.9277 - val_loss: 67242.2422 - val_mae: 34.4040\n","Epoch 26/40\n","939/939 [==============================] - 46s 49ms/step - loss: 13540.4863 - mae: 17.8340 - val_loss: 71380.1094 - val_mae: 42.8952\n","Epoch 27/40\n","939/939 [==============================] - 45s 48ms/step - loss: 13474.2354 - mae: 18.1506 - val_loss: 67891.7031 - val_mae: 36.1463\n","Epoch 28/40\n","939/939 [==============================] - 44s 47ms/step - loss: 13572.3936 - mae: 17.9465 - val_loss: 70803.6094 - val_mae: 36.0108\n","Epoch 29/40\n","939/939 [==============================] - 44s 47ms/step - loss: 13446.8271 - mae: 17.8849 - val_loss: 71307.9766 - val_mae: 35.4597\n","Epoch 30/40\n","939/939 [==============================] - 46s 49ms/step - loss: 13334.1025 - mae: 17.9332 - val_loss: 73192.6016 - val_mae: 36.1670\n","Epoch 31/40\n","939/939 [==============================] - 48s 51ms/step - loss: 13479.1504 - mae: 17.9934 - val_loss: 71234.1016 - val_mae: 31.2555\n","Epoch 32/40\n","939/939 [==============================] - 45s 48ms/step - loss: 13489.9766 - mae: 18.1635 - val_loss: 75860.5781 - val_mae: 36.0838\n","Epoch 33/40\n","939/939 [==============================] - 46s 49ms/step - loss: 13433.3584 - mae: 18.2210 - val_loss: 66203.1719 - val_mae: 46.9933\n","Epoch 34/40\n","939/939 [==============================] - 45s 48ms/step - loss: 13319.8818 - mae: 18.0758 - val_loss: 71628.2188 - val_mae: 31.9533\n","Epoch 35/40\n","939/939 [==============================] - 46s 49ms/step - loss: 13415.2061 - mae: 17.8794 - val_loss: 72468.0156 - val_mae: 41.0209\n","Epoch 36/40\n","939/939 [==============================] - 47s 50ms/step - loss: 13383.7910 - mae: 18.3106 - val_loss: 81308.0859 - val_mae: 40.8557\n","Epoch 37/40\n","939/939 [==============================] - 48s 52ms/step - loss: 13375.4619 - mae: 18.0991 - val_loss: 70564.4609 - val_mae: 34.0028\n","Epoch 38/40\n","939/939 [==============================] - 45s 48ms/step - loss: 13303.9199 - mae: 17.8766 - val_loss: 72605.3359 - val_mae: 36.7589\n","Epoch 39/40\n","939/939 [==============================] - 44s 47ms/step - loss: 13423.0049 - mae: 18.3518 - val_loss: 72489.2578 - val_mae: 34.1411\n","Epoch 40/40\n","939/939 [==============================] - 46s 49ms/step - loss: 13242.6777 - mae: 18.4240 - val_loss: 76346.5469 - val_mae: 39.1234\n","37.36002511480518\n","0.6123710774306874\n","0.9355219631603454\n","start group2,This is the experiment num: 2\n","\n","---------------------------------------------- domain num 0 is running----------------------------------\n","start training\n","Epoch 1/40\n","939/939 [==============================] - 49s 51ms/step - loss: 14243.0518 - mae: 18.2732 - val_loss: 60815.9531 - val_mae: 39.3289\n","Epoch 2/40\n","939/939 [==============================] - 48s 51ms/step - loss: 14046.1924 - mae: 18.4003 - val_loss: 63622.1484 - val_mae: 31.0573\n","Epoch 3/40\n","939/939 [==============================] - 49s 53ms/step - loss: 13961.2148 - mae: 16.7201 - val_loss: 61170.9219 - val_mae: 31.7007\n","Epoch 4/40\n","939/939 [==============================] - 51s 54ms/step - loss: 13871.7061 - mae: 16.4858 - val_loss: 62121.1328 - val_mae: 31.0552\n","Epoch 5/40\n","939/939 [==============================] - 53s 57ms/step - loss: 13806.7354 - mae: 16.7838 - val_loss: 63831.7773 - val_mae: 30.2507\n","Epoch 6/40\n","939/939 [==============================] - 52s 55ms/step - loss: 13775.8125 - mae: 16.6393 - val_loss: 62767.3398 - val_mae: 31.5224\n","Epoch 7/40\n","939/939 [==============================] - 50s 53ms/step - loss: 13792.3096 - mae: 16.8477 - val_loss: 64787.3281 - val_mae: 38.4484\n","Epoch 8/40\n","939/939 [==============================] - 50s 54ms/step - loss: 13827.7344 - mae: 17.3076 - val_loss: 70857.9375 - val_mae: 44.2755\n","Epoch 9/40\n","939/939 [==============================] - 50s 53ms/step - loss: 13644.3486 - mae: 17.0627 - val_loss: 63689.6016 - val_mae: 32.3237\n","Epoch 10/40\n","939/939 [==============================] - 53s 56ms/step - loss: 13646.8760 - mae: 16.9963 - val_loss: 64470.6211 - val_mae: 44.3919\n","Epoch 11/40\n","939/939 [==============================] - 51s 54ms/step - loss: 13703.8398 - mae: 17.1830 - val_loss: 67578.3047 - val_mae: 33.7645\n","Epoch 12/40\n","939/939 [==============================] - 53s 56ms/step - loss: 13731.5566 - mae: 17.5246 - val_loss: 65900.5859 - val_mae: 33.7810\n","Epoch 13/40\n","939/939 [==============================] - 54s 57ms/step - loss: 13737.0488 - mae: 17.4095 - val_loss: 71380.5078 - val_mae: 39.7692\n","Epoch 14/40\n","939/939 [==============================] - 51s 55ms/step - loss: 13719.1123 - mae: 17.0924 - val_loss: 66434.5000 - val_mae: 48.2215\n","Epoch 15/40\n","939/939 [==============================] - 51s 55ms/step - loss: 13638.6318 - mae: 17.3105 - val_loss: 71228.6094 - val_mae: 32.4322\n","Epoch 16/40\n","939/939 [==============================] - 53s 56ms/step - loss: 13591.8721 - mae: 17.1583 - val_loss: 69677.1719 - val_mae: 55.9200\n","Epoch 17/40\n","939/939 [==============================] - 54s 57ms/step - loss: 13620.9502 - mae: 17.3058 - val_loss: 70985.4375 - val_mae: 32.1746\n","Epoch 18/40\n","939/939 [==============================] - 53s 56ms/step - loss: 13547.6025 - mae: 17.2528 - val_loss: 68560.8750 - val_mae: 49.1644\n","Epoch 19/40\n","939/939 [==============================] - 54s 58ms/step - loss: 13532.5508 - mae: 17.5038 - val_loss: 72160.7188 - val_mae: 42.8654\n","Epoch 20/40\n","939/939 [==============================] - 52s 55ms/step - loss: 13578.9805 - mae: 17.5447 - val_loss: 69330.3906 - val_mae: 35.0834\n","Epoch 21/40\n","939/939 [==============================] - 51s 54ms/step - loss: 13547.9883 - mae: 17.5692 - val_loss: 70910.7031 - val_mae: 31.5801\n","Epoch 22/40\n","939/939 [==============================] - 53s 57ms/step - loss: 13503.1475 - mae: 17.7999 - val_loss: 69020.1172 - val_mae: 30.8481\n","Epoch 23/40\n","939/939 [==============================] - 52s 55ms/step - loss: 13511.5156 - mae: 17.5638 - val_loss: 72150.2109 - val_mae: 40.0174\n","Epoch 24/40\n","939/939 [==============================] - 53s 56ms/step - loss: 13461.7402 - mae: 17.8600 - val_loss: 70757.9922 - val_mae: 48.5830\n","Epoch 25/40\n","939/939 [==============================] - 53s 57ms/step - loss: 13521.4170 - mae: 17.9503 - val_loss: 74262.7266 - val_mae: 44.6484\n","Epoch 26/40\n","939/939 [==============================] - 52s 55ms/step - loss: 13434.8398 - mae: 17.8497 - val_loss: 72249.6250 - val_mae: 31.8024\n","Epoch 27/40\n","939/939 [==============================] - 52s 55ms/step - loss: 13340.2227 - mae: 18.0555 - val_loss: 70911.6953 - val_mae: 37.3478\n","Epoch 28/40\n","939/939 [==============================] - 51s 54ms/step - loss: 13421.6377 - mae: 18.0858 - val_loss: 72090.3047 - val_mae: 39.2675\n","Epoch 29/40\n","939/939 [==============================] - 51s 54ms/step - loss: 13486.9668 - mae: 18.1054 - val_loss: 73527.2812 - val_mae: 36.3556\n","Epoch 30/40\n","939/939 [==============================] - 51s 54ms/step - loss: 13436.9697 - mae: 17.8576 - val_loss: 70548.1641 - val_mae: 42.8909\n","Epoch 31/40\n","939/939 [==============================] - 51s 54ms/step - loss: 13422.0684 - mae: 17.8982 - val_loss: 67722.8203 - val_mae: 33.0864\n","Epoch 32/40\n","939/939 [==============================] - 53s 56ms/step - loss: 13426.5938 - mae: 18.4862 - val_loss: 70947.5312 - val_mae: 42.4163\n","Epoch 33/40\n","939/939 [==============================] - 50s 53ms/step - loss: 13340.6533 - mae: 18.1147 - val_loss: 72395.7656 - val_mae: 37.7486\n","Epoch 34/40\n","939/939 [==============================] - 50s 53ms/step - loss: 13350.0049 - mae: 18.0443 - val_loss: 68595.9766 - val_mae: 45.0332\n","Epoch 35/40\n","939/939 [==============================] - 52s 55ms/step - loss: 13487.7725 - mae: 18.3040 - val_loss: 64436.3047 - val_mae: 38.7927\n","Epoch 36/40\n","939/939 [==============================] - 50s 53ms/step - loss: 13311.2695 - mae: 17.9171 - val_loss: 71927.6328 - val_mae: 34.4077\n","Epoch 37/40\n","939/939 [==============================] - 50s 53ms/step - loss: 13281.1436 - mae: 17.9125 - val_loss: 75752.9375 - val_mae: 37.0793\n","Epoch 38/40\n","939/939 [==============================] - 51s 54ms/step - loss: 13385.3555 - mae: 18.3802 - val_loss: 72582.0469 - val_mae: 32.0790\n","Epoch 39/40\n","939/939 [==============================] - 48s 51ms/step - loss: 13320.2949 - mae: 18.2648 - val_loss: 69666.2500 - val_mae: 30.1184\n","Epoch 40/40\n","939/939 [==============================] - 51s 54ms/step - loss: 13349.9248 - mae: 18.3901 - val_loss: 75093.1172 - val_mae: 42.8288\n","41.44389362000276\n","0.46341611559169815\n","0.9338991353537965\n","start group2,This is the experiment num: 3\n","\n","---------------------------------------------- domain num 0 is running----------------------------------\n","start training\n","Epoch 1/40\n","939/939 [==============================] - 50s 52ms/step - loss: 14341.4424 - mae: 17.8561 - val_loss: 61896.7227 - val_mae: 46.9238\n","Epoch 2/40\n","939/939 [==============================] - 50s 53ms/step - loss: 14028.3389 - mae: 18.2629 - val_loss: 59745.5039 - val_mae: 44.0816\n","Epoch 3/40\n","939/939 [==============================] - 51s 55ms/step - loss: 13995.1025 - mae: 16.3859 - val_loss: 61363.8242 - val_mae: 56.6684\n","Epoch 4/40\n","939/939 [==============================] - 53s 56ms/step - loss: 13860.0342 - mae: 16.4537 - val_loss: 64857.1094 - val_mae: 38.5470\n","Epoch 5/40\n","939/939 [==============================] - 53s 56ms/step - loss: 13866.0098 - mae: 16.3641 - val_loss: 64346.1875 - val_mae: 34.0118\n","Epoch 6/40\n","939/939 [==============================] - 48s 51ms/step - loss: 13878.8242 - mae: 16.3442 - val_loss: 66253.0078 - val_mae: 43.1844\n","Epoch 7/40\n","939/939 [==============================] - 50s 53ms/step - loss: 13801.7354 - mae: 16.4441 - val_loss: 64558.7383 - val_mae: 33.3195\n","Epoch 8/40\n","939/939 [==============================] - 52s 55ms/step - loss: 13799.6934 - mae: 16.7459 - val_loss: 71858.3359 - val_mae: 33.8605\n","Epoch 9/40\n","939/939 [==============================] - 48s 51ms/step - loss: 13797.0186 - mae: 16.6529 - val_loss: 67632.5078 - val_mae: 36.9640\n","Epoch 10/40\n","939/939 [==============================] - 48s 51ms/step - loss: 13756.1387 - mae: 16.6657 - val_loss: 68643.0078 - val_mae: 37.8609\n","Epoch 11/40\n","939/939 [==============================] - 48s 51ms/step - loss: 13867.5410 - mae: 17.2674 - val_loss: 64623.3047 - val_mae: 49.8565\n","Epoch 12/40\n","939/939 [==============================] - 50s 53ms/step - loss: 13719.3838 - mae: 16.6444 - val_loss: 72561.7422 - val_mae: 36.9715\n","Epoch 13/40\n","939/939 [==============================] - 47s 51ms/step - loss: 13661.5410 - mae: 16.9441 - val_loss: 77614.6875 - val_mae: 60.1046\n","Epoch 14/40\n","939/939 [==============================] - 50s 53ms/step - loss: 13764.6221 - mae: 16.5974 - val_loss: 72501.9062 - val_mae: 40.1455\n","Epoch 15/40\n","939/939 [==============================] - 51s 54ms/step - loss: 13753.7900 - mae: 17.1189 - val_loss: 71995.4766 - val_mae: 50.3032\n","Epoch 16/40\n","939/939 [==============================] - 48s 51ms/step - loss: 13812.2959 - mae: 17.5860 - val_loss: 80576.4844 - val_mae: 41.7005\n","Epoch 17/40\n","939/939 [==============================] - 54s 57ms/step - loss: 13744.8447 - mae: 16.7649 - val_loss: 68901.6719 - val_mae: 45.9005\n","Epoch 18/40\n","939/939 [==============================] - 55s 58ms/step - loss: 13734.5908 - mae: 17.1476 - val_loss: 68771.8984 - val_mae: 32.9028\n","Epoch 19/40\n","939/939 [==============================] - 50s 54ms/step - loss: 13735.9902 - mae: 17.1210 - val_loss: 77406.4844 - val_mae: 41.5660\n","Epoch 20/40\n","939/939 [==============================] - 52s 56ms/step - loss: 13515.0029 - mae: 17.1539 - val_loss: 72449.7109 - val_mae: 32.3753\n","Epoch 21/40\n","939/939 [==============================] - 51s 54ms/step - loss: 13599.2607 - mae: 17.0864 - val_loss: 70875.2422 - val_mae: 37.9281\n","Epoch 22/40\n","939/939 [==============================] - 49s 52ms/step - loss: 13695.8271 - mae: 17.2295 - val_loss: 69751.2969 - val_mae: 34.5751\n","Epoch 23/40\n","939/939 [==============================] - 49s 53ms/step - loss: 13630.5732 - mae: 17.4827 - val_loss: 70590.6484 - val_mae: 32.2826\n","Epoch 24/40\n","939/939 [==============================] - 51s 54ms/step - loss: 13556.1748 - mae: 17.1783 - val_loss: 71863.0703 - val_mae: 40.9822\n","Epoch 25/40\n","939/939 [==============================] - 54s 57ms/step - loss: 13573.0576 - mae: 17.6285 - val_loss: 67592.8672 - val_mae: 32.7026\n","Epoch 26/40\n","939/939 [==============================] - 51s 55ms/step - loss: 13525.7471 - mae: 17.0530 - val_loss: 76098.2109 - val_mae: 37.9753\n","Epoch 27/40\n","939/939 [==============================] - 51s 54ms/step - loss: 13609.9414 - mae: 17.3826 - val_loss: 72133.2578 - val_mae: 38.2719\n","Epoch 28/40\n","939/939 [==============================] - 53s 56ms/step - loss: 13507.8633 - mae: 17.8838 - val_loss: 71251.2109 - val_mae: 43.3714\n","Epoch 29/40\n","939/939 [==============================] - 51s 54ms/step - loss: 13516.5449 - mae: 17.4803 - val_loss: 75454.5625 - val_mae: 37.8461\n","Epoch 30/40\n","939/939 [==============================] - 52s 56ms/step - loss: 13541.1289 - mae: 18.2437 - val_loss: 73401.5234 - val_mae: 34.5053\n","Epoch 31/40\n","939/939 [==============================] - 53s 57ms/step - loss: 13543.5781 - mae: 17.8456 - val_loss: 67672.7734 - val_mae: 38.2525\n","Epoch 32/40\n","939/939 [==============================] - 51s 54ms/step - loss: 13504.2275 - mae: 17.8881 - val_loss: 68759.3984 - val_mae: 32.6906\n","Epoch 33/40\n","939/939 [==============================] - 50s 53ms/step - loss: 13482.5332 - mae: 17.8919 - val_loss: 71138.5625 - val_mae: 35.1740\n","Epoch 34/40\n","939/939 [==============================] - 51s 55ms/step - loss: 13386.8652 - mae: 17.8975 - val_loss: 72113.7344 - val_mae: 45.8295\n","Epoch 35/40\n","939/939 [==============================] - 49s 52ms/step - loss: 13330.3311 - mae: 17.8603 - val_loss: 74964.1484 - val_mae: 41.3592\n","Epoch 36/40\n","939/939 [==============================] - 48s 51ms/step - loss: 13369.2393 - mae: 17.9365 - val_loss: 72203.8125 - val_mae: 43.4825\n","Epoch 37/40\n","939/939 [==============================] - 47s 50ms/step - loss: 13434.4277 - mae: 18.0337 - val_loss: 73205.9062 - val_mae: 38.1354\n","Epoch 38/40\n","939/939 [==============================] - 49s 52ms/step - loss: 13334.5508 - mae: 18.0599 - val_loss: 68800.0547 - val_mae: 39.8477\n","Epoch 39/40\n","939/939 [==============================] - 48s 51ms/step - loss: 13265.1309 - mae: 18.0769 - val_loss: 84274.5859 - val_mae: 54.1466\n","Epoch 40/40\n","939/939 [==============================] - 46s 49ms/step - loss: 13495.1582 - mae: 18.2238 - val_loss: 75296.7578 - val_mae: 42.3746\n","40.84771695729102\n","0.5179433896137262\n","0.9558759025423047\n","start group2,This is the experiment num: 4\n","\n","---------------------------------------------- domain num 0 is running----------------------------------\n","start training\n","Epoch 1/40\n","939/939 [==============================] - 44s 45ms/step - loss: 14261.9453 - mae: 18.8969 - val_loss: 61974.1758 - val_mae: 35.3597\n","Epoch 2/40\n","939/939 [==============================] - 41s 44ms/step - loss: 13995.2344 - mae: 17.9886 - val_loss: 61649.3906 - val_mae: 33.4286\n","Epoch 3/40\n","939/939 [==============================] - 40s 43ms/step - loss: 14006.5713 - mae: 17.1977 - val_loss: 69439.1797 - val_mae: 43.4832\n","Epoch 4/40\n","939/939 [==============================] - 44s 47ms/step - loss: 13906.3145 - mae: 16.3315 - val_loss: 64839.9180 - val_mae: 33.5573\n","Epoch 5/40\n","939/939 [==============================] - 45s 48ms/step - loss: 13778.3779 - mae: 16.5986 - val_loss: 59636.2930 - val_mae: 35.1590\n","Epoch 6/40\n","939/939 [==============================] - 42s 45ms/step - loss: 13857.4150 - mae: 16.8583 - val_loss: 64030.4375 - val_mae: 35.8643\n","Epoch 7/40\n","939/939 [==============================] - 42s 44ms/step - loss: 13817.4102 - mae: 16.6343 - val_loss: 66573.1016 - val_mae: 37.8011\n","Epoch 8/40\n","939/939 [==============================] - 42s 44ms/step - loss: 13693.8818 - mae: 16.9552 - val_loss: 63567.1523 - val_mae: 31.5582\n","Epoch 9/40\n","939/939 [==============================] - 43s 46ms/step - loss: 13811.6719 - mae: 16.9770 - val_loss: 62568.5234 - val_mae: 40.6391\n","Epoch 10/40\n","939/939 [==============================] - 40s 42ms/step - loss: 13708.8008 - mae: 17.4005 - val_loss: 65179.0117 - val_mae: 38.8970\n","Epoch 11/40\n","939/939 [==============================] - 41s 43ms/step - loss: 13674.5762 - mae: 16.9878 - val_loss: 66971.5547 - val_mae: 34.7460\n","Epoch 12/40\n","939/939 [==============================] - 40s 43ms/step - loss: 13721.7529 - mae: 17.0828 - val_loss: 70004.7109 - val_mae: 47.4787\n","Epoch 13/40\n","939/939 [==============================] - 42s 45ms/step - loss: 13728.5684 - mae: 17.4754 - val_loss: 67293.1250 - val_mae: 34.7340\n","Epoch 14/40\n","939/939 [==============================] - 41s 43ms/step - loss: 13667.9492 - mae: 17.3291 - val_loss: 70150.3047 - val_mae: 37.4654\n","Epoch 15/40\n","939/939 [==============================] - 41s 43ms/step - loss: 13661.5908 - mae: 17.4744 - val_loss: 72447.3125 - val_mae: 34.7923\n","Epoch 16/40\n","939/939 [==============================] - 41s 43ms/step - loss: 13585.9590 - mae: 17.6352 - val_loss: 70456.3281 - val_mae: 45.0701\n","Epoch 17/40\n","939/939 [==============================] - 42s 45ms/step - loss: 13631.4883 - mae: 17.5925 - val_loss: 67053.2656 - val_mae: 32.0265\n","Epoch 18/40\n","939/939 [==============================] - 40s 43ms/step - loss: 13476.1875 - mae: 17.5967 - val_loss: 59984.2969 - val_mae: 42.8154\n","Epoch 19/40\n","939/939 [==============================] - 40s 42ms/step - loss: 13665.6650 - mae: 17.5724 - val_loss: 64942.3906 - val_mae: 30.4041\n","Epoch 20/40\n","939/939 [==============================] - 42s 44ms/step - loss: 13566.1309 - mae: 17.5182 - val_loss: 65137.3438 - val_mae: 29.8673\n","Epoch 21/40\n","939/939 [==============================] - 45s 48ms/step - loss: 13576.1436 - mae: 17.6637 - val_loss: 65757.1484 - val_mae: 36.9239\n","Epoch 22/40\n","939/939 [==============================] - 43s 46ms/step - loss: 13486.9648 - mae: 17.7309 - val_loss: 66242.7812 - val_mae: 38.5361\n","Epoch 23/40\n","939/939 [==============================] - 43s 45ms/step - loss: 13426.0166 - mae: 17.8353 - val_loss: 63523.5664 - val_mae: 47.8430\n","Epoch 24/40\n","939/939 [==============================] - 44s 47ms/step - loss: 13403.5420 - mae: 18.4034 - val_loss: 72818.8594 - val_mae: 34.2714\n","Epoch 25/40\n","939/939 [==============================] - 45s 47ms/step - loss: 13319.6553 - mae: 17.9140 - val_loss: 73839.3203 - val_mae: 41.2111\n","Epoch 26/40\n","939/939 [==============================] - 42s 45ms/step - loss: 13476.5771 - mae: 17.8321 - val_loss: 67427.3281 - val_mae: 33.2797\n","Epoch 27/40\n","939/939 [==============================] - 44s 47ms/step - loss: 13376.9180 - mae: 17.9994 - val_loss: 74972.1562 - val_mae: 36.5703\n","Epoch 28/40\n","939/939 [==============================] - 46s 49ms/step - loss: 13424.4746 - mae: 18.0418 - val_loss: 69892.2109 - val_mae: 43.2761\n","Epoch 29/40\n","939/939 [==============================] - 44s 47ms/step - loss: 13469.2812 - mae: 18.4286 - val_loss: 72759.8203 - val_mae: 41.2809\n","Epoch 30/40\n","939/939 [==============================] - 44s 47ms/step - loss: 13342.2197 - mae: 18.2233 - val_loss: 79282.5703 - val_mae: 47.0228\n","Epoch 31/40\n","939/939 [==============================] - 43s 45ms/step - loss: 13320.6748 - mae: 18.2083 - val_loss: 74441.2969 - val_mae: 32.8433\n","Epoch 32/40\n","939/939 [==============================] - 44s 47ms/step - loss: 13457.4268 - mae: 18.4544 - val_loss: 68227.0156 - val_mae: 35.0074\n","Epoch 33/40\n","939/939 [==============================] - 42s 45ms/step - loss: 13270.2480 - mae: 18.0086 - val_loss: 66144.2422 - val_mae: 31.7704\n","Epoch 34/40\n","939/939 [==============================] - 43s 46ms/step - loss: 13306.4053 - mae: 17.9510 - val_loss: 65334.5586 - val_mae: 35.3709\n","Epoch 35/40\n","939/939 [==============================] - 42s 45ms/step - loss: 13338.4336 - mae: 18.4884 - val_loss: 67847.5312 - val_mae: 32.4941\n","Epoch 36/40\n","939/939 [==============================] - 43s 46ms/step - loss: 13264.1484 - mae: 17.8764 - val_loss: 72929.1797 - val_mae: 31.5050\n","Epoch 37/40\n","939/939 [==============================] - 41s 44ms/step - loss: 13310.1348 - mae: 18.7470 - val_loss: 74055.6406 - val_mae: 33.4597\n","Epoch 38/40\n","939/939 [==============================] - 42s 45ms/step - loss: 13212.8994 - mae: 18.1148 - val_loss: 75662.4609 - val_mae: 33.6192\n","Epoch 39/40\n","939/939 [==============================] - 42s 45ms/step - loss: 13180.3711 - mae: 18.3415 - val_loss: 74963.2656 - val_mae: 41.1751\n","Epoch 40/40\n","939/939 [==============================] - 44s 47ms/step - loss: 13152.3730 - mae: 18.2752 - val_loss: 69287.0078 - val_mae: 31.4942\n","31.902433915345245\n","0.8287829541027625\n","0.9467995774167245\n","start group3,This is the experiment num: 0\n","\n","---------------------------------------------- domain num 0 is running----------------------------------\n","start training\n","Epoch 1/40\n","1314/1314 [==============================] - 60s 45ms/step - loss: 27323.0645 - mae: 26.6486 - val_loss: 20345.3398 - val_mae: 25.7742\n","Epoch 2/40\n","1314/1314 [==============================] - 58s 44ms/step - loss: 25815.3906 - mae: 26.2534 - val_loss: 22128.2480 - val_mae: 28.8294\n","Epoch 3/40\n","1314/1314 [==============================] - 56s 42ms/step - loss: 25042.2207 - mae: 25.2267 - val_loss: 26157.5859 - val_mae: 27.0923\n","Epoch 4/40\n","1314/1314 [==============================] - 55s 42ms/step - loss: 24872.7734 - mae: 25.7646 - val_loss: 25183.8418 - val_mae: 25.5073\n","Epoch 5/40\n","1314/1314 [==============================] - 58s 44ms/step - loss: 23770.3867 - mae: 26.1832 - val_loss: 26398.6387 - val_mae: 24.6134\n","Epoch 6/40\n","1314/1314 [==============================] - 56s 43ms/step - loss: 23364.9746 - mae: 26.9303 - val_loss: 26640.5781 - val_mae: 26.5409\n","Epoch 7/40\n","1314/1314 [==============================] - 58s 44ms/step - loss: 23312.0898 - mae: 27.3600 - val_loss: 28007.7441 - val_mae: 30.1449\n","Epoch 8/40\n","1314/1314 [==============================] - 60s 45ms/step - loss: 22943.4883 - mae: 27.8188 - val_loss: 23431.5957 - val_mae: 22.1236\n","Epoch 9/40\n","1314/1314 [==============================] - 57s 43ms/step - loss: 22203.8164 - mae: 27.4460 - val_loss: 25014.6309 - val_mae: 31.6367\n","Epoch 10/40\n","1314/1314 [==============================] - 57s 43ms/step - loss: 22381.8711 - mae: 28.0898 - val_loss: 20989.4414 - val_mae: 25.3962\n","Epoch 11/40\n","1314/1314 [==============================] - 60s 45ms/step - loss: 21969.9922 - mae: 28.7834 - val_loss: 21887.2715 - val_mae: 33.6066\n","Epoch 12/40\n","1314/1314 [==============================] - 57s 44ms/step - loss: 22101.5254 - mae: 28.7929 - val_loss: 22629.6445 - val_mae: 23.9159\n","Epoch 13/40\n","1314/1314 [==============================] - 59s 45ms/step - loss: 22330.0059 - mae: 29.1418 - val_loss: 22374.8418 - val_mae: 27.1301\n","Epoch 14/40\n","1314/1314 [==============================] - 57s 44ms/step - loss: 21752.9688 - mae: 29.2337 - val_loss: 19976.1094 - val_mae: 26.7844\n","Epoch 15/40\n","1314/1314 [==============================] - 58s 44ms/step - loss: 21757.5996 - mae: 28.8037 - val_loss: 19950.3516 - val_mae: 26.7036\n","Epoch 16/40\n","1314/1314 [==============================] - 61s 46ms/step - loss: 21831.3633 - mae: 28.8319 - val_loss: 22471.5723 - val_mae: 21.6628\n","Epoch 17/40\n","1314/1314 [==============================] - 59s 45ms/step - loss: 21592.1934 - mae: 29.0732 - val_loss: 19774.5332 - val_mae: 28.0286\n","Epoch 18/40\n","1314/1314 [==============================] - 60s 46ms/step - loss: 21803.3125 - mae: 28.9459 - val_loss: 19689.7461 - val_mae: 18.2437\n","Epoch 19/40\n","1314/1314 [==============================] - 62s 47ms/step - loss: 21637.0449 - mae: 28.7707 - val_loss: 20401.6016 - val_mae: 26.7656\n","Epoch 20/40\n","1314/1314 [==============================] - 58s 44ms/step - loss: 21441.1328 - mae: 28.7631 - val_loss: 21059.8906 - val_mae: 27.5095\n","Epoch 21/40\n","1314/1314 [==============================] - 61s 47ms/step - loss: 21690.1719 - mae: 29.5504 - val_loss: 19225.6426 - val_mae: 17.8728\n","Epoch 22/40\n","1314/1314 [==============================] - 60s 45ms/step - loss: 21610.3184 - mae: 28.8386 - val_loss: 20138.0117 - val_mae: 27.1153\n","Epoch 23/40\n","1314/1314 [==============================] - 59s 45ms/step - loss: 21556.6660 - mae: 29.8909 - val_loss: 19231.0039 - val_mae: 33.1550\n","Epoch 24/40\n","1314/1314 [==============================] - 61s 47ms/step - loss: 21254.2637 - mae: 28.5766 - val_loss: 20586.5156 - val_mae: 21.1470\n","Epoch 25/40\n","1314/1314 [==============================] - 58s 44ms/step - loss: 21379.7422 - mae: 29.0914 - val_loss: 20428.7305 - val_mae: 24.0131\n","Epoch 26/40\n","1314/1314 [==============================] - 62s 47ms/step - loss: 21279.1133 - mae: 29.1955 - val_loss: 19884.0664 - val_mae: 24.2372\n","Epoch 27/40\n","1314/1314 [==============================] - 59s 45ms/step - loss: 21105.2930 - mae: 28.9334 - val_loss: 18211.5957 - val_mae: 25.3307\n","Epoch 28/40\n","1314/1314 [==============================] - 59s 45ms/step - loss: 21859.4551 - mae: 29.5872 - val_loss: 19198.9551 - val_mae: 22.6209\n","Epoch 29/40\n","1314/1314 [==============================] - 62s 47ms/step - loss: 21715.8496 - mae: 29.7115 - val_loss: 20104.8262 - val_mae: 30.2271\n","Epoch 30/40\n","1314/1314 [==============================] - 62s 47ms/step - loss: 20833.6777 - mae: 28.7821 - val_loss: 19462.7754 - val_mae: 28.3100\n","Epoch 31/40\n","1314/1314 [==============================] - 61s 46ms/step - loss: 21130.9492 - mae: 28.3254 - val_loss: 19024.4629 - val_mae: 27.5883\n","Epoch 32/40\n","1314/1314 [==============================] - 62s 47ms/step - loss: 20966.0352 - mae: 28.5634 - val_loss: 19306.2480 - val_mae: 23.2728\n","Epoch 33/40\n","1314/1314 [==============================] - 60s 46ms/step - loss: 20740.1133 - mae: 28.8359 - val_loss: 19228.5195 - val_mae: 29.8472\n","Epoch 34/40\n","1314/1314 [==============================] - 61s 47ms/step - loss: 21480.3613 - mae: 28.8426 - val_loss: 18935.8301 - val_mae: 18.2626\n","Epoch 35/40\n","1314/1314 [==============================] - 58s 44ms/step - loss: 21009.3418 - mae: 28.9022 - val_loss: 18733.9766 - val_mae: 32.8780\n","Epoch 36/40\n","1314/1314 [==============================] - 59s 45ms/step - loss: 21026.2617 - mae: 29.2450 - val_loss: 18427.9531 - val_mae: 34.8060\n","Epoch 37/40\n","1314/1314 [==============================] - 60s 46ms/step - loss: 20581.8105 - mae: 29.1862 - val_loss: 18121.5645 - val_mae: 28.6718\n","Epoch 38/40\n","1314/1314 [==============================] - 59s 45ms/step - loss: 20692.2891 - mae: 29.3187 - val_loss: 18574.0469 - val_mae: 29.4716\n","Epoch 39/40\n","1314/1314 [==============================] - 62s 47ms/step - loss: 20737.0371 - mae: 29.1855 - val_loss: 18404.5449 - val_mae: 30.6202\n","Epoch 40/40\n","1314/1314 [==============================] - 58s 44ms/step - loss: 20932.6250 - mae: 28.8501 - val_loss: 18360.6309 - val_mae: 24.1430\n","42.315797921185805\n","0.691294582941887\n","0.9419464029911949\n","start group3,This is the experiment num: 1\n","\n","---------------------------------------------- domain num 0 is running----------------------------------\n","start training\n","Epoch 1/40\n","1314/1314 [==============================] - 64s 48ms/step - loss: 27132.5938 - mae: 26.7337 - val_loss: 22175.7422 - val_mae: 39.7968\n","Epoch 2/40\n","1314/1314 [==============================] - 64s 49ms/step - loss: 25573.1777 - mae: 27.0736 - val_loss: 22063.0215 - val_mae: 30.5689\n","Epoch 3/40\n","1314/1314 [==============================] - 58s 44ms/step - loss: 25483.3809 - mae: 25.2586 - val_loss: 23991.9902 - val_mae: 31.8513\n","Epoch 4/40\n","1314/1314 [==============================] - 59s 45ms/step - loss: 24522.8281 - mae: 24.5609 - val_loss: 32703.8633 - val_mae: 28.5478\n","Epoch 5/40\n","1314/1314 [==============================] - 58s 44ms/step - loss: 24529.6719 - mae: 25.4909 - val_loss: 30399.1133 - val_mae: 35.4927\n","Epoch 6/40\n","1314/1314 [==============================] - 58s 44ms/step - loss: 24313.0605 - mae: 25.4446 - val_loss: 54730.6562 - val_mae: 47.0557\n","Epoch 7/40\n","1314/1314 [==============================] - 59s 45ms/step - loss: 25140.4707 - mae: 26.7108 - val_loss: 35638.2266 - val_mae: 27.6567\n","Epoch 8/40\n","1314/1314 [==============================] - 56s 43ms/step - loss: 24482.1484 - mae: 26.2365 - val_loss: 44691.4453 - val_mae: 31.6479\n","Epoch 9/40\n","1314/1314 [==============================] - 55s 42ms/step - loss: 24321.0234 - mae: 26.4184 - val_loss: 45890.7148 - val_mae: 29.3821\n","Epoch 10/40\n","1314/1314 [==============================] - 58s 44ms/step - loss: 24256.2754 - mae: 26.2555 - val_loss: 42028.9375 - val_mae: 29.0879\n","Epoch 11/40\n","1314/1314 [==============================] - 56s 43ms/step - loss: 24096.9551 - mae: 26.3005 - val_loss: 52516.6680 - val_mae: 44.2810\n","Epoch 12/40\n","1314/1314 [==============================] - 58s 44ms/step - loss: 23643.7852 - mae: 26.3091 - val_loss: 61076.6680 - val_mae: 41.8687\n","Epoch 13/40\n","1314/1314 [==============================] - 57s 43ms/step - loss: 23101.6895 - mae: 26.5418 - val_loss: 46295.9961 - val_mae: 30.3521\n","Epoch 14/40\n","1314/1314 [==============================] - 59s 45ms/step - loss: 23228.0039 - mae: 27.3397 - val_loss: 41605.0859 - val_mae: 37.8844\n","Epoch 15/40\n","1314/1314 [==============================] - 61s 47ms/step - loss: 22536.3496 - mae: 27.4933 - val_loss: 34524.8359 - val_mae: 26.2571\n","Epoch 16/40\n","1314/1314 [==============================] - 62s 47ms/step - loss: 22174.1230 - mae: 27.2349 - val_loss: 49478.1328 - val_mae: 46.8728\n","Epoch 17/40\n","1314/1314 [==============================] - 59s 45ms/step - loss: 22344.5918 - mae: 28.4082 - val_loss: 37547.5781 - val_mae: 29.2733\n","Epoch 18/40\n","1314/1314 [==============================] - 58s 44ms/step - loss: 22296.1719 - mae: 28.4341 - val_loss: 37444.3203 - val_mae: 34.4251\n","Epoch 19/40\n","1314/1314 [==============================] - 58s 44ms/step - loss: 21897.0938 - mae: 28.4211 - val_loss: 28535.9688 - val_mae: 25.9648\n","Epoch 20/40\n","1314/1314 [==============================] - 60s 46ms/step - loss: 21784.9941 - mae: 28.2740 - val_loss: 34410.0391 - val_mae: 28.8519\n","Epoch 21/40\n","1314/1314 [==============================] - 58s 44ms/step - loss: 21885.9727 - mae: 28.6480 - val_loss: 29690.3066 - val_mae: 39.1033\n","Epoch 22/40\n","1314/1314 [==============================] - 57s 43ms/step - loss: 21501.1895 - mae: 28.5312 - val_loss: 23308.2891 - val_mae: 27.1728\n","Epoch 23/40\n","1314/1314 [==============================] - 60s 45ms/step - loss: 21512.2227 - mae: 28.6458 - val_loss: 22267.1406 - val_mae: 21.1577\n","Epoch 24/40\n","1314/1314 [==============================] - 58s 44ms/step - loss: 21395.0273 - mae: 29.1639 - val_loss: 22978.1172 - val_mae: 28.4271\n","Epoch 25/40\n","1314/1314 [==============================] - 59s 45ms/step - loss: 21255.3926 - mae: 28.8709 - val_loss: 23866.5430 - val_mae: 29.2096\n","Epoch 26/40\n","1314/1314 [==============================] - 57s 44ms/step - loss: 21164.3867 - mae: 29.1359 - val_loss: 22384.6914 - val_mae: 20.3953\n","Epoch 27/40\n","1314/1314 [==============================] - 62s 47ms/step - loss: 21186.3379 - mae: 29.0240 - val_loss: 21761.1992 - val_mae: 31.3655\n","Epoch 28/40\n","1314/1314 [==============================] - 61s 47ms/step - loss: 21169.7578 - mae: 29.2838 - val_loss: 20486.9082 - val_mae: 24.8892\n","Epoch 29/40\n","1314/1314 [==============================] - 58s 44ms/step - loss: 21300.7988 - mae: 28.9200 - val_loss: 20937.7344 - val_mae: 29.9194\n","Epoch 30/40\n","1314/1314 [==============================] - 60s 46ms/step - loss: 20908.1992 - mae: 28.6848 - val_loss: 19975.6719 - val_mae: 21.8353\n","Epoch 31/40\n","1314/1314 [==============================] - 58s 44ms/step - loss: 21918.9492 - mae: 29.2782 - val_loss: 19554.9707 - val_mae: 31.4363\n","Epoch 32/40\n","1314/1314 [==============================] - 57s 43ms/step - loss: 20969.8984 - mae: 28.8194 - val_loss: 19462.4668 - val_mae: 28.0158\n","Epoch 33/40\n","1314/1314 [==============================] - 60s 46ms/step - loss: 20672.8789 - mae: 29.2046 - val_loss: 19786.9414 - val_mae: 34.9820\n","Epoch 34/40\n","1314/1314 [==============================] - 58s 44ms/step - loss: 20904.5020 - mae: 29.4248 - val_loss: 19153.9922 - val_mae: 27.4737\n","Epoch 35/40\n","1314/1314 [==============================] - 59s 45ms/step - loss: 21001.5098 - mae: 29.1254 - val_loss: 19926.9590 - val_mae: 24.9543\n","Epoch 36/40\n","1314/1314 [==============================] - 57s 44ms/step - loss: 20586.7617 - mae: 28.7052 - val_loss: 18504.3555 - val_mae: 29.5013\n","Epoch 37/40\n","1314/1314 [==============================] - 56s 43ms/step - loss: 20844.5000 - mae: 28.9938 - val_loss: 19214.8301 - val_mae: 21.9453\n","Epoch 38/40\n","1314/1314 [==============================] - 59s 45ms/step - loss: 20221.4004 - mae: 28.9558 - val_loss: 19126.3438 - val_mae: 43.3502\n","Epoch 39/40\n","1314/1314 [==============================] - 66s 50ms/step - loss: 20446.9102 - mae: 28.7667 - val_loss: 18916.9082 - val_mae: 26.2425\n","Epoch 40/40\n","1314/1314 [==============================] - 64s 49ms/step - loss: 20358.4434 - mae: 28.7521 - val_loss: 19540.9336 - val_mae: 30.3792\n","47.39153494498384\n","0.5315616987884061\n","0.9384760365437254\n","start group3,This is the experiment num: 2\n","\n","---------------------------------------------- domain num 0 is running----------------------------------\n","start training\n","Epoch 1/40\n","1314/1314 [==============================] - 65s 48ms/step - loss: 26968.7949 - mae: 27.0805 - val_loss: 21543.5137 - val_mae: 31.6019\n","Epoch 2/40\n","1314/1314 [==============================] - 64s 49ms/step - loss: 25438.9492 - mae: 26.2508 - val_loss: 22439.0938 - val_mae: 34.4338\n","Epoch 3/40\n","1314/1314 [==============================] - 64s 49ms/step - loss: 25019.7480 - mae: 24.8415 - val_loss: 27111.6582 - val_mae: 32.6706\n","Epoch 4/40\n","1314/1314 [==============================] - 63s 48ms/step - loss: 25068.4316 - mae: 24.9814 - val_loss: 26784.5957 - val_mae: 25.1636\n","Epoch 5/40\n","1314/1314 [==============================] - 61s 47ms/step - loss: 24810.4551 - mae: 25.6013 - val_loss: 36555.3906 - val_mae: 31.8146\n","Epoch 6/40\n","1314/1314 [==============================] - 63s 48ms/step - loss: 24328.0586 - mae: 25.7200 - val_loss: 37550.1016 - val_mae: 34.4384\n","Epoch 7/40\n","1314/1314 [==============================] - 63s 48ms/step - loss: 23695.5996 - mae: 25.7386 - val_loss: 41993.1758 - val_mae: 39.4199\n","Epoch 8/40\n","1314/1314 [==============================] - 63s 48ms/step - loss: 23271.4668 - mae: 26.2196 - val_loss: 37962.4102 - val_mae: 28.2206\n","Epoch 9/40\n","1314/1314 [==============================] - 62s 47ms/step - loss: 23157.5371 - mae: 27.2992 - val_loss: 39307.7070 - val_mae: 31.3206\n","Epoch 10/40\n","1314/1314 [==============================] - 66s 50ms/step - loss: 22971.5449 - mae: 27.3833 - val_loss: 31445.7832 - val_mae: 25.4012\n","Epoch 11/40\n","1314/1314 [==============================] - 65s 50ms/step - loss: 22734.2695 - mae: 27.4234 - val_loss: 30636.0117 - val_mae: 35.0101\n","Epoch 12/40\n","1314/1314 [==============================] - 66s 50ms/step - loss: 22624.0098 - mae: 28.1372 - val_loss: 27724.3984 - val_mae: 27.9244\n","Epoch 13/40\n","1314/1314 [==============================] - 66s 50ms/step - loss: 22110.4746 - mae: 28.2899 - val_loss: 23141.3301 - val_mae: 25.4297\n","Epoch 14/40\n","1314/1314 [==============================] - 66s 50ms/step - loss: 22526.8125 - mae: 28.3192 - val_loss: 23309.0898 - val_mae: 21.0989\n","Epoch 15/40\n","1314/1314 [==============================] - 65s 49ms/step - loss: 22079.7715 - mae: 28.2726 - val_loss: 22519.1914 - val_mae: 27.5735\n","Epoch 16/40\n","1314/1314 [==============================] - 63s 48ms/step - loss: 21914.0156 - mae: 28.8608 - val_loss: 22093.6641 - val_mae: 32.6718\n","Epoch 17/40\n","1314/1314 [==============================] - 66s 50ms/step - loss: 21445.3105 - mae: 28.1884 - val_loss: 20393.5449 - val_mae: 20.4249\n","Epoch 18/40\n","1314/1314 [==============================] - 66s 51ms/step - loss: 21449.1797 - mae: 28.8525 - val_loss: 21996.2129 - val_mae: 29.7642\n","Epoch 19/40\n","1314/1314 [==============================] - 69s 52ms/step - loss: 21836.0898 - mae: 28.9961 - val_loss: 21892.9824 - val_mae: 26.5356\n","Epoch 20/40\n","1314/1314 [==============================] - 66s 50ms/step - loss: 21572.0605 - mae: 28.8372 - val_loss: 21319.4004 - val_mae: 22.9708\n","Epoch 21/40\n","1314/1314 [==============================] - 66s 50ms/step - loss: 21682.2480 - mae: 28.6595 - val_loss: 20038.5156 - val_mae: 24.9002\n","Epoch 22/40\n","1314/1314 [==============================] - 68s 52ms/step - loss: 21359.7695 - mae: 28.9932 - val_loss: 21045.5332 - val_mae: 32.6401\n","Epoch 23/40\n","1314/1314 [==============================] - 66s 50ms/step - loss: 20945.0547 - mae: 28.5908 - val_loss: 20737.2754 - val_mae: 22.3432\n","Epoch 24/40\n","1314/1314 [==============================] - 64s 48ms/step - loss: 20954.2695 - mae: 29.0147 - val_loss: 21072.9355 - val_mae: 23.2073\n","Epoch 25/40\n","1314/1314 [==============================] - 63s 48ms/step - loss: 20989.4434 - mae: 28.7320 - val_loss: 19814.4004 - val_mae: 31.5426\n","Epoch 26/40\n","1314/1314 [==============================] - 64s 49ms/step - loss: 21277.8203 - mae: 29.0834 - val_loss: 20786.6914 - val_mae: 22.1443\n","Epoch 27/40\n","1314/1314 [==============================] - 62s 47ms/step - loss: 21332.5137 - mae: 29.4079 - val_loss: 19923.8867 - val_mae: 31.4529\n","Epoch 28/40\n","1314/1314 [==============================] - 63s 48ms/step - loss: 21307.6543 - mae: 29.2915 - val_loss: 19575.4180 - val_mae: 32.5150\n","Epoch 29/40\n","1314/1314 [==============================] - 61s 47ms/step - loss: 20804.6328 - mae: 28.9312 - val_loss: 19323.6797 - val_mae: 20.2947\n","Epoch 30/40\n","1314/1314 [==============================] - 63s 48ms/step - loss: 20899.4316 - mae: 29.0265 - val_loss: 18888.4414 - val_mae: 25.0557\n","Epoch 31/40\n","1314/1314 [==============================] - 61s 46ms/step - loss: 20639.0449 - mae: 28.4149 - val_loss: 19477.1133 - val_mae: 29.8131\n","Epoch 32/40\n","1314/1314 [==============================] - 61s 46ms/step - loss: 21069.0645 - mae: 29.6164 - val_loss: 18931.4375 - val_mae: 36.9503\n","Epoch 33/40\n","1314/1314 [==============================] - 61s 46ms/step - loss: 21116.7344 - mae: 28.8015 - val_loss: 19599.0938 - val_mae: 21.1693\n","Epoch 34/40\n","1314/1314 [==============================] - 61s 47ms/step - loss: 21278.8770 - mae: 28.8532 - val_loss: 19090.8398 - val_mae: 25.6007\n","Epoch 35/40\n","1314/1314 [==============================] - 62s 47ms/step - loss: 21035.7480 - mae: 29.2370 - val_loss: 18556.6445 - val_mae: 31.0764\n","Epoch 36/40\n","1314/1314 [==============================] - 62s 47ms/step - loss: 20578.4570 - mae: 28.9698 - val_loss: 19138.4785 - val_mae: 23.7101\n","Epoch 37/40\n","1314/1314 [==============================] - 63s 48ms/step - loss: 20526.3008 - mae: 28.6761 - val_loss: 19134.1113 - val_mae: 36.8735\n","Epoch 38/40\n","1314/1314 [==============================] - 62s 47ms/step - loss: 20519.6328 - mae: 28.8649 - val_loss: 20180.3516 - val_mae: 31.3448\n","Epoch 39/40\n","1314/1314 [==============================] - 63s 48ms/step - loss: 20655.2188 - mae: 28.9904 - val_loss: 19473.7695 - val_mae: 20.9786\n","Epoch 40/40\n","1314/1314 [==============================] - 62s 47ms/step - loss: 20765.3496 - mae: 28.8026 - val_loss: 19452.7266 - val_mae: 34.8554\n","49.54709636926968\n","0.41194442339375875\n","0.9138230907528495\n","start group3,This is the experiment num: 3\n","\n","---------------------------------------------- domain num 0 is running----------------------------------\n","start training\n","Epoch 1/40\n","1314/1314 [==============================] - 61s 45ms/step - loss: 27046.2734 - mae: 27.1960 - val_loss: 21653.4180 - val_mae: 43.5403\n","Epoch 2/40\n","1314/1314 [==============================] - 61s 47ms/step - loss: 25524.6816 - mae: 26.1962 - val_loss: 22187.4648 - val_mae: 29.3669\n","Epoch 3/40\n","1314/1314 [==============================] - 60s 45ms/step - loss: 24844.5977 - mae: 23.8371 - val_loss: 36171.7969 - val_mae: 34.4952\n","Epoch 4/40\n","1314/1314 [==============================] - 61s 47ms/step - loss: 24745.8457 - mae: 24.9863 - val_loss: 38347.1836 - val_mae: 30.6771\n","Epoch 5/40\n","1314/1314 [==============================] - 60s 45ms/step - loss: 24245.9629 - mae: 25.7852 - val_loss: 31736.0547 - val_mae: 29.3188\n","Epoch 6/40\n","1314/1314 [==============================] - 60s 46ms/step - loss: 24007.3594 - mae: 26.4135 - val_loss: 36987.4023 - val_mae: 30.0672\n","Epoch 7/40\n","1314/1314 [==============================] - 61s 46ms/step - loss: 23628.9551 - mae: 26.9619 - val_loss: 28331.8789 - val_mae: 30.7589\n","Epoch 8/40\n","1314/1314 [==============================] - 58s 44ms/step - loss: 22956.6562 - mae: 27.0061 - val_loss: 31215.3008 - val_mae: 26.1566\n","Epoch 9/40\n","1314/1314 [==============================] - 60s 45ms/step - loss: 23031.6387 - mae: 27.5675 - val_loss: 34521.6953 - val_mae: 35.9293\n","Epoch 10/40\n","1314/1314 [==============================] - 58s 44ms/step - loss: 22928.1074 - mae: 28.0861 - val_loss: 29751.2695 - val_mae: 30.5315\n","Epoch 11/40\n","1314/1314 [==============================] - 62s 47ms/step - loss: 22620.4238 - mae: 27.9124 - val_loss: 24134.1758 - val_mae: 24.8512\n","Epoch 12/40\n","1314/1314 [==============================] - 59s 45ms/step - loss: 22124.8848 - mae: 28.2551 - val_loss: 23871.2461 - val_mae: 20.7761\n","Epoch 13/40\n","1314/1314 [==============================] - 62s 47ms/step - loss: 21716.9570 - mae: 27.8644 - val_loss: 23177.8027 - val_mae: 19.7944\n","Epoch 14/40\n","1314/1314 [==============================] - 59s 45ms/step - loss: 22178.5078 - mae: 28.8405 - val_loss: 25939.1484 - val_mae: 32.6385\n","Epoch 15/40\n","1314/1314 [==============================] - 61s 46ms/step - loss: 21897.2969 - mae: 28.4939 - val_loss: 23194.9590 - val_mae: 24.8004\n","Epoch 16/40\n","1314/1314 [==============================] - 59s 45ms/step - loss: 22036.2129 - mae: 28.6650 - val_loss: 20906.7891 - val_mae: 24.9353\n","Epoch 17/40\n","1314/1314 [==============================] - 59s 45ms/step - loss: 22110.4141 - mae: 28.5369 - val_loss: 22111.7656 - val_mae: 39.1597\n","Epoch 18/40\n","1314/1314 [==============================] - 63s 48ms/step - loss: 21740.5273 - mae: 28.9407 - val_loss: 22512.7871 - val_mae: 26.4948\n","Epoch 19/40\n","1314/1314 [==============================] - 61s 46ms/step - loss: 21485.6211 - mae: 28.2149 - val_loss: 22639.7559 - val_mae: 33.0381\n","Epoch 20/40\n","1314/1314 [==============================] - 63s 48ms/step - loss: 21921.6172 - mae: 28.9727 - val_loss: 22357.7754 - val_mae: 29.1228\n","Epoch 21/40\n","1314/1314 [==============================] - 60s 46ms/step - loss: 21795.2539 - mae: 28.9794 - val_loss: 21237.9102 - val_mae: 24.1144\n","Epoch 22/40\n","1314/1314 [==============================] - 63s 48ms/step - loss: 21265.8047 - mae: 28.8828 - val_loss: 21347.1465 - val_mae: 25.6345\n","Epoch 23/40\n","1314/1314 [==============================] - 61s 46ms/step - loss: 21363.5195 - mae: 28.7990 - val_loss: 23673.4805 - val_mae: 23.3938\n","Epoch 24/40\n","1314/1314 [==============================] - 64s 49ms/step - loss: 21418.2754 - mae: 28.9271 - val_loss: 20648.3438 - val_mae: 30.8239\n","Epoch 25/40\n","1314/1314 [==============================] - 61s 46ms/step - loss: 21632.5762 - mae: 29.1407 - val_loss: 20129.5371 - val_mae: 24.4136\n","Epoch 26/40\n","1314/1314 [==============================] - 62s 47ms/step - loss: 21150.1836 - mae: 28.8945 - val_loss: 19302.6973 - val_mae: 23.8108\n","Epoch 27/40\n","1314/1314 [==============================] - 60s 46ms/step - loss: 21120.0176 - mae: 28.8984 - val_loss: 19505.0371 - val_mae: 27.7035\n","Epoch 28/40\n","1314/1314 [==============================] - 62s 47ms/step - loss: 20880.8496 - mae: 28.7549 - val_loss: 20816.6152 - val_mae: 32.5455\n","Epoch 29/40\n","1314/1314 [==============================] - 63s 48ms/step - loss: 20786.8770 - mae: 28.3445 - val_loss: 20172.2129 - val_mae: 31.6066\n","Epoch 30/40\n","1314/1314 [==============================] - 64s 49ms/step - loss: 20774.4609 - mae: 29.1374 - val_loss: 20479.4551 - val_mae: 24.5432\n","Epoch 31/40\n","1314/1314 [==============================] - 61s 47ms/step - loss: 20951.4570 - mae: 29.1704 - val_loss: 20040.1172 - val_mae: 25.8023\n","Epoch 32/40\n","1314/1314 [==============================] - 63s 48ms/step - loss: 21611.7969 - mae: 29.3954 - val_loss: 20126.3750 - val_mae: 19.6454\n","Epoch 33/40\n","1314/1314 [==============================] - 62s 47ms/step - loss: 20474.0293 - mae: 28.7258 - val_loss: 19985.1055 - val_mae: 30.1021\n","Epoch 34/40\n","1314/1314 [==============================] - 62s 47ms/step - loss: 21317.4883 - mae: 29.1640 - val_loss: 19215.3340 - val_mae: 35.6430\n","Epoch 35/40\n","1314/1314 [==============================] - 63s 48ms/step - loss: 20852.9531 - mae: 29.1029 - val_loss: 18841.7363 - val_mae: 25.3817\n","Epoch 36/40\n","1314/1314 [==============================] - 62s 47ms/step - loss: 20671.0996 - mae: 28.5340 - val_loss: 19147.2617 - val_mae: 23.8848\n","Epoch 37/40\n","1314/1314 [==============================] - 65s 49ms/step - loss: 20587.8086 - mae: 28.9029 - val_loss: 19148.9180 - val_mae: 22.4220\n","Epoch 38/40\n","1314/1314 [==============================] - 63s 48ms/step - loss: 20813.8086 - mae: 29.1514 - val_loss: 19466.7090 - val_mae: 19.1387\n","Epoch 39/40\n","1314/1314 [==============================] - 65s 50ms/step - loss: 20745.1035 - mae: 28.8990 - val_loss: 19303.8926 - val_mae: 30.7301\n","Epoch 40/40\n","1314/1314 [==============================] - 61s 46ms/step - loss: 20658.0469 - mae: 28.6545 - val_loss: 18857.6445 - val_mae: 25.1029\n","42.39516988924436\n","0.6647531834421669\n","0.9298374014081129\n","start group3,This is the experiment num: 4\n","\n","---------------------------------------------- domain num 0 is running----------------------------------\n","start training\n","Epoch 1/40\n","1314/1314 [==============================] - 60s 45ms/step - loss: 27428.0684 - mae: 26.7199 - val_loss: 19587.1484 - val_mae: 34.8377\n","Epoch 2/40\n","1314/1314 [==============================] - 62s 47ms/step - loss: 25472.2891 - mae: 26.0070 - val_loss: 23613.8535 - val_mae: 28.6779\n","Epoch 3/40\n","1314/1314 [==============================] - 61s 47ms/step - loss: 24706.9414 - mae: 24.1877 - val_loss: 28434.2129 - val_mae: 47.1671\n","Epoch 4/40\n","1314/1314 [==============================] - 63s 48ms/step - loss: 24923.0410 - mae: 25.1882 - val_loss: 26881.6660 - val_mae: 28.8603\n","Epoch 5/40\n","1314/1314 [==============================] - 62s 47ms/step - loss: 24139.3457 - mae: 25.3759 - val_loss: 32430.4023 - val_mae: 32.1041\n","Epoch 6/40\n","1314/1314 [==============================] - 65s 49ms/step - loss: 24116.6484 - mae: 26.7002 - val_loss: 30310.7480 - val_mae: 28.1414\n","Epoch 7/40\n","1314/1314 [==============================] - 62s 47ms/step - loss: 23205.7988 - mae: 26.3274 - val_loss: 25661.2480 - val_mae: 29.3679\n","Epoch 8/40\n","1314/1314 [==============================] - 63s 48ms/step - loss: 23299.1973 - mae: 27.8566 - val_loss: 23693.6504 - val_mae: 23.6476\n","Epoch 9/40\n","1314/1314 [==============================] - 62s 47ms/step - loss: 22646.7676 - mae: 27.9403 - val_loss: 23706.5957 - val_mae: 27.9847\n","Epoch 10/40\n","1314/1314 [==============================] - 65s 49ms/step - loss: 22167.2734 - mae: 27.9287 - val_loss: 20783.1699 - val_mae: 19.2430\n","Epoch 11/40\n","1314/1314 [==============================] - 63s 48ms/step - loss: 22370.3418 - mae: 28.7410 - val_loss: 19425.6465 - val_mae: 31.1056\n","Epoch 12/40\n","1314/1314 [==============================] - 65s 49ms/step - loss: 21982.3242 - mae: 28.4370 - val_loss: 21128.3750 - val_mae: 26.3224\n","Epoch 13/40\n","1314/1314 [==============================] - 63s 48ms/step - loss: 21939.0332 - mae: 28.7676 - val_loss: 20474.0625 - val_mae: 26.9594\n","Epoch 14/40\n","1314/1314 [==============================] - 64s 49ms/step - loss: 21935.5391 - mae: 28.9012 - val_loss: 20039.0703 - val_mae: 20.6174\n","Epoch 15/40\n","1314/1314 [==============================] - 63s 48ms/step - loss: 22047.7617 - mae: 28.7336 - val_loss: 19395.8965 - val_mae: 23.6139\n","Epoch 16/40\n","1314/1314 [==============================] - 65s 49ms/step - loss: 21638.7207 - mae: 29.2831 - val_loss: 19109.8906 - val_mae: 35.4969\n","Epoch 17/40\n","1314/1314 [==============================] - 67s 51ms/step - loss: 21158.8047 - mae: 28.9494 - val_loss: 18373.8652 - val_mae: 32.0850\n","Epoch 18/40\n","1314/1314 [==============================] - 68s 51ms/step - loss: 21519.2520 - mae: 28.8390 - val_loss: 18402.5078 - val_mae: 19.1012\n","Epoch 19/40\n","1314/1314 [==============================] - 67s 51ms/step - loss: 21355.3828 - mae: 29.2281 - val_loss: 18700.8438 - val_mae: 28.5506\n","Epoch 20/40\n","1314/1314 [==============================] - 67s 51ms/step - loss: 21487.4590 - mae: 28.8492 - val_loss: 18397.7422 - val_mae: 21.0966\n","Epoch 21/40\n","1314/1314 [==============================] - 63s 48ms/step - loss: 21382.8242 - mae: 29.0252 - val_loss: 18056.1934 - val_mae: 28.5430\n","Epoch 22/40\n","1314/1314 [==============================] - 66s 50ms/step - loss: 21597.0762 - mae: 28.8272 - val_loss: 18085.3984 - val_mae: 31.3425\n","Epoch 23/40\n","1314/1314 [==============================] - 66s 50ms/step - loss: 21417.4668 - mae: 29.2896 - val_loss: 18148.8926 - val_mae: 28.2441\n","Epoch 24/40\n","1314/1314 [==============================] - 68s 52ms/step - loss: 21405.1230 - mae: 29.1367 - val_loss: 18069.5801 - val_mae: 26.8486\n","Epoch 25/40\n","1314/1314 [==============================] - 67s 51ms/step - loss: 20840.9316 - mae: 28.6427 - val_loss: 18437.5117 - val_mae: 25.7918\n","Epoch 26/40\n","1314/1314 [==============================] - 66s 50ms/step - loss: 21443.3809 - mae: 28.9448 - val_loss: 18062.2852 - val_mae: 30.6017\n","Epoch 27/40\n","1314/1314 [==============================] - 67s 51ms/step - loss: 20960.9414 - mae: 28.9322 - val_loss: 18216.0137 - val_mae: 25.0159\n","Epoch 28/40\n","1314/1314 [==============================] - 67s 51ms/step - loss: 20876.3828 - mae: 29.2143 - val_loss: 18234.7891 - val_mae: 26.5441\n","Epoch 29/40\n","1314/1314 [==============================] - 69s 53ms/step - loss: 21179.6191 - mae: 29.0933 - val_loss: 18101.2598 - val_mae: 22.4577\n","Epoch 30/40\n","1314/1314 [==============================] - 67s 51ms/step - loss: 20739.1445 - mae: 28.8196 - val_loss: 18079.5273 - val_mae: 27.4595\n","Epoch 31/40\n","1314/1314 [==============================] - 68s 52ms/step - loss: 21120.2383 - mae: 28.9263 - val_loss: 17886.5840 - val_mae: 27.4318\n","Epoch 32/40\n","1314/1314 [==============================] - 67s 51ms/step - loss: 20795.0664 - mae: 29.0135 - val_loss: 18118.5625 - val_mae: 23.0687\n","Epoch 33/40\n","1314/1314 [==============================] - 68s 52ms/step - loss: 20662.4258 - mae: 28.5395 - val_loss: 18056.3652 - val_mae: 30.8032\n","Epoch 34/40\n","1314/1314 [==============================] - 70s 53ms/step - loss: 20783.0859 - mae: 29.0807 - val_loss: 18230.4258 - val_mae: 26.7164\n","Epoch 35/40\n","1314/1314 [==============================] - 66s 50ms/step - loss: 20710.7129 - mae: 28.4930 - val_loss: 17855.3730 - val_mae: 24.8800\n","Epoch 36/40\n","1314/1314 [==============================] - 67s 51ms/step - loss: 20523.3574 - mae: 28.9804 - val_loss: 17968.7344 - val_mae: 21.5889\n","Epoch 37/40\n","1314/1314 [==============================] - 67s 51ms/step - loss: 20881.1289 - mae: 28.9180 - val_loss: 17972.7305 - val_mae: 26.1167\n","Epoch 38/40\n","1314/1314 [==============================] - 68s 51ms/step - loss: 20480.8320 - mae: 29.4116 - val_loss: 18087.3145 - val_mae: 24.2025\n","Epoch 39/40\n","1314/1314 [==============================] - 69s 52ms/step - loss: 20252.0430 - mae: 28.4815 - val_loss: 18296.4277 - val_mae: 23.3859\n","Epoch 40/40\n","1314/1314 [==============================] - 71s 54ms/step - loss: 20220.2246 - mae: 29.1999 - val_loss: 18123.6387 - val_mae: 26.6052\n","46.30007862346309\n","0.5993254347946816\n","0.9541219551681153\n","start group4,This is the experiment num: 0\n","\n","---------------------------------------------- domain num 0 is running----------------------------------\n","start training\n","Epoch 1/40\n","1690/1690 [==============================] - 89s 52ms/step - loss: 24721.0449 - mae: 25.9897 - val_loss: 38590.0547 - val_mae: 38.1092\n","Epoch 2/40\n","1690/1690 [==============================] - 81s 48ms/step - loss: 24135.8145 - mae: 26.2996 - val_loss: 34941.5586 - val_mae: 27.1280\n","Epoch 3/40\n","1690/1690 [==============================] - 79s 47ms/step - loss: 23470.5293 - mae: 24.6186 - val_loss: 35720.7969 - val_mae: 32.3228\n","Epoch 4/40\n","1690/1690 [==============================] - 80s 48ms/step - loss: 23513.3906 - mae: 25.0235 - val_loss: 29414.0527 - val_mae: 36.2138\n","Epoch 5/40\n","1690/1690 [==============================] - 82s 49ms/step - loss: 23389.3418 - mae: 25.6370 - val_loss: 29287.7773 - val_mae: 29.1237\n","Epoch 6/40\n","1690/1690 [==============================] - 80s 48ms/step - loss: 23501.2266 - mae: 25.9229 - val_loss: 32656.2910 - val_mae: 25.6538\n","Epoch 7/40\n","1690/1690 [==============================] - 83s 49ms/step - loss: 23201.3145 - mae: 25.8637 - val_loss: 28084.0508 - val_mae: 29.2741\n","Epoch 8/40\n","1690/1690 [==============================] - 83s 49ms/step - loss: 22888.3184 - mae: 25.1029 - val_loss: 24251.9922 - val_mae: 26.4642\n","Epoch 9/40\n","1690/1690 [==============================] - 82s 49ms/step - loss: 22979.8555 - mae: 25.7886 - val_loss: 29661.8633 - val_mae: 25.9056\n","Epoch 10/40\n","1690/1690 [==============================] - 83s 49ms/step - loss: 22602.2695 - mae: 26.1354 - val_loss: 37100.0977 - val_mae: 31.0191\n","Epoch 11/40\n","1690/1690 [==============================] - 84s 49ms/step - loss: 22302.0020 - mae: 26.8258 - val_loss: 31139.9453 - val_mae: 24.9712\n","Epoch 12/40\n","1690/1690 [==============================] - 82s 48ms/step - loss: 22135.0664 - mae: 27.0740 - val_loss: 25425.8945 - val_mae: 26.4614\n","Epoch 13/40\n","1690/1690 [==============================] - 80s 47ms/step - loss: 21917.8867 - mae: 27.4974 - val_loss: 34761.7422 - val_mae: 25.2085\n","Epoch 14/40\n","1690/1690 [==============================] - 83s 49ms/step - loss: 21963.2949 - mae: 27.7935 - val_loss: 36916.3672 - val_mae: 31.2580\n","Epoch 15/40\n","1690/1690 [==============================] - 81s 48ms/step - loss: 21986.1816 - mae: 27.6613 - val_loss: 38876.6797 - val_mae: 24.1710\n","Epoch 16/40\n","1690/1690 [==============================] - 79s 47ms/step - loss: 21563.3984 - mae: 27.5719 - val_loss: 38688.9922 - val_mae: 30.3075\n","Epoch 17/40\n","1690/1690 [==============================] - 82s 49ms/step - loss: 21623.7090 - mae: 28.4362 - val_loss: 39321.9570 - val_mae: 29.2402\n","Epoch 18/40\n","1690/1690 [==============================] - 82s 49ms/step - loss: 21750.5293 - mae: 28.2949 - val_loss: 34699.9180 - val_mae: 25.9795\n","Epoch 19/40\n","1690/1690 [==============================] - 81s 48ms/step - loss: 21294.2949 - mae: 27.6116 - val_loss: 34433.3008 - val_mae: 28.0519\n","Epoch 20/40\n","1690/1690 [==============================] - 80s 47ms/step - loss: 21198.4141 - mae: 27.7097 - val_loss: 40774.0117 - val_mae: 30.9314\n","Epoch 21/40\n","1690/1690 [==============================] - 83s 49ms/step - loss: 21276.8320 - mae: 27.7639 - val_loss: 39767.6797 - val_mae: 31.4991\n","Epoch 22/40\n","1690/1690 [==============================] - 82s 49ms/step - loss: 21289.8535 - mae: 27.6795 - val_loss: 32720.9434 - val_mae: 38.5026\n","Epoch 23/40\n","1690/1690 [==============================] - 80s 47ms/step - loss: 21407.1523 - mae: 28.7455 - val_loss: 40332.0508 - val_mae: 27.9508\n","Epoch 24/40\n","1690/1690 [==============================] - 82s 49ms/step - loss: 21053.5039 - mae: 27.6389 - val_loss: 41043.0352 - val_mae: 28.6937\n","Epoch 25/40\n","1690/1690 [==============================] - 84s 50ms/step - loss: 20980.9277 - mae: 28.3551 - val_loss: 40115.9453 - val_mae: 27.5036\n","Epoch 26/40\n","1690/1690 [==============================] - 81s 48ms/step - loss: 20676.9727 - mae: 27.7993 - val_loss: 38729.0508 - val_mae: 30.8872\n","Epoch 27/40\n","1690/1690 [==============================] - 83s 49ms/step - loss: 21035.9023 - mae: 28.6055 - val_loss: 40164.0859 - val_mae: 31.5386\n","Epoch 28/40\n","1690/1690 [==============================] - 83s 49ms/step - loss: 21214.8066 - mae: 27.7914 - val_loss: 41427.4688 - val_mae: 29.2144\n","Epoch 29/40\n","1690/1690 [==============================] - 83s 49ms/step - loss: 20901.8301 - mae: 27.9369 - val_loss: 42413.5625 - val_mae: 40.8521\n","Epoch 30/40\n","1690/1690 [==============================] - 78s 46ms/step - loss: 20754.3086 - mae: 27.9922 - val_loss: 41393.8906 - val_mae: 34.6582\n","Epoch 31/40\n","1690/1690 [==============================] - 81s 48ms/step - loss: 20469.1914 - mae: 27.4800 - val_loss: 39647.3164 - val_mae: 30.3027\n","Epoch 32/40\n","1690/1690 [==============================] - 81s 48ms/step - loss: 20714.9844 - mae: 27.7544 - val_loss: 39871.7891 - val_mae: 33.1714\n","Epoch 33/40\n","1690/1690 [==============================] - 79s 47ms/step - loss: 20808.7285 - mae: 28.4390 - val_loss: 42331.1250 - val_mae: 47.4795\n","Epoch 34/40\n","1690/1690 [==============================] - 81s 48ms/step - loss: 20495.9434 - mae: 28.3257 - val_loss: 43527.1641 - val_mae: 33.4592\n","Epoch 35/40\n","1690/1690 [==============================] - 83s 49ms/step - loss: 20601.8340 - mae: 27.8991 - val_loss: 42039.8633 - val_mae: 30.3480\n","Epoch 36/40\n","1690/1690 [==============================] - 82s 49ms/step - loss: 20364.3672 - mae: 27.3256 - val_loss: 40701.9219 - val_mae: 31.7827\n","Epoch 37/40\n","1690/1690 [==============================] - 80s 47ms/step - loss: 20643.8613 - mae: 27.7330 - val_loss: 37647.4453 - val_mae: 34.2619\n","Epoch 38/40\n","1690/1690 [==============================] - 81s 48ms/step - loss: 20421.9590 - mae: 27.4971 - val_loss: 41946.1836 - val_mae: 34.5775\n","Epoch 39/40\n","1690/1690 [==============================] - 84s 50ms/step - loss: 20340.7754 - mae: 27.8609 - val_loss: 42245.8164 - val_mae: 32.7802\n","Epoch 40/40\n","1690/1690 [==============================] - 82s 49ms/step - loss: 20329.5684 - mae: 27.8714 - val_loss: 42521.2617 - val_mae: 28.8117\n","28.950112505655948\n","0.6376860873553034\n","0.914528144273035\n","start group4,This is the experiment num: 1\n","\n","---------------------------------------------- domain num 0 is running----------------------------------\n","start training\n","Epoch 1/40\n","1690/1690 [==============================] - 82s 48ms/step - loss: 24778.3789 - mae: 26.8744 - val_loss: 39279.0547 - val_mae: 24.9905\n","Epoch 2/40\n","1690/1690 [==============================] - 80s 47ms/step - loss: 23748.1816 - mae: 24.8452 - val_loss: 30998.2734 - val_mae: 27.0632\n","Epoch 3/40\n","1690/1690 [==============================] - 83s 49ms/step - loss: 23226.6191 - mae: 24.5490 - val_loss: 32719.5020 - val_mae: 24.8476\n","Epoch 4/40\n","1690/1690 [==============================] - 80s 48ms/step - loss: 23502.7969 - mae: 25.3324 - val_loss: 28763.8457 - val_mae: 24.9465\n","Epoch 5/40\n","1690/1690 [==============================] - 81s 48ms/step - loss: 23307.9785 - mae: 25.4519 - val_loss: 29414.5957 - val_mae: 26.3933\n","Epoch 6/40\n","1690/1690 [==============================] - 82s 48ms/step - loss: 23017.9102 - mae: 25.8105 - val_loss: 28934.4902 - val_mae: 28.9436\n","Epoch 7/40\n","1690/1690 [==============================] - 83s 49ms/step - loss: 23033.2402 - mae: 26.5268 - val_loss: 31886.5352 - val_mae: 30.7357\n","Epoch 8/40\n","1690/1690 [==============================] - 81s 48ms/step - loss: 22828.3496 - mae: 26.5195 - val_loss: 30099.4531 - val_mae: 35.3723\n","Epoch 9/40\n","1690/1690 [==============================] - 82s 49ms/step - loss: 22223.4023 - mae: 25.8977 - val_loss: 39689.8633 - val_mae: 31.8292\n","Epoch 10/40\n","1690/1690 [==============================] - 82s 49ms/step - loss: 22136.3164 - mae: 26.6831 - val_loss: 30978.4648 - val_mae: 23.0583\n","Epoch 11/40\n","1690/1690 [==============================] - 81s 48ms/step - loss: 22127.5703 - mae: 26.9517 - val_loss: 29695.8203 - val_mae: 28.7710\n","Epoch 12/40\n","1690/1690 [==============================] - 82s 48ms/step - loss: 21710.0391 - mae: 27.0718 - val_loss: 33786.3750 - val_mae: 23.7163\n","Epoch 13/40\n","1690/1690 [==============================] - 81s 48ms/step - loss: 21411.2617 - mae: 27.2177 - val_loss: 36738.3711 - val_mae: 29.5363\n","Epoch 14/40\n","1690/1690 [==============================] - 80s 47ms/step - loss: 21709.5352 - mae: 27.3753 - val_loss: 38212.2773 - val_mae: 25.6792\n","Epoch 15/40\n","1690/1690 [==============================] - 80s 47ms/step - loss: 21713.9414 - mae: 28.1734 - val_loss: 35443.8281 - val_mae: 33.2119\n","Epoch 16/40\n","1690/1690 [==============================] - 81s 48ms/step - loss: 21449.6641 - mae: 27.6048 - val_loss: 35407.4570 - val_mae: 23.4980\n","Epoch 17/40\n","1690/1690 [==============================] - 80s 47ms/step - loss: 21436.7520 - mae: 27.6532 - val_loss: 39168.0625 - val_mae: 28.6617\n","Epoch 18/40\n","1690/1690 [==============================] - 82s 48ms/step - loss: 21412.0449 - mae: 27.8663 - val_loss: 35474.7617 - val_mae: 25.3423\n","Epoch 19/40\n","1690/1690 [==============================] - 80s 47ms/step - loss: 21018.8594 - mae: 27.7529 - val_loss: 37819.0781 - val_mae: 28.8269\n","Epoch 20/40\n","1690/1690 [==============================] - 80s 47ms/step - loss: 20979.4746 - mae: 27.7303 - val_loss: 39389.8828 - val_mae: 29.4244\n","Epoch 21/40\n","1690/1690 [==============================] - 79s 47ms/step - loss: 21040.7422 - mae: 28.0287 - val_loss: 35450.2148 - val_mae: 28.7966\n","Epoch 22/40\n","1690/1690 [==============================] - 83s 49ms/step - loss: 21267.3047 - mae: 27.8567 - val_loss: 31268.1211 - val_mae: 29.2454\n","Epoch 23/40\n","1690/1690 [==============================] - 83s 49ms/step - loss: 21076.2852 - mae: 27.8099 - val_loss: 38948.7070 - val_mae: 32.2410\n","Epoch 24/40\n","1690/1690 [==============================] - 81s 48ms/step - loss: 20944.9141 - mae: 27.9087 - val_loss: 37137.5156 - val_mae: 32.2241\n","Epoch 25/40\n","1690/1690 [==============================] - 81s 48ms/step - loss: 21601.8613 - mae: 28.6374 - val_loss: 38237.8516 - val_mae: 27.6095\n","Epoch 26/40\n","1690/1690 [==============================] - 80s 47ms/step - loss: 21122.0645 - mae: 28.1674 - val_loss: 42332.2617 - val_mae: 32.0797\n","Epoch 27/40\n","1690/1690 [==============================] - 82s 49ms/step - loss: 21030.6758 - mae: 27.6474 - val_loss: 38919.0273 - val_mae: 26.6618\n","Epoch 28/40\n","1690/1690 [==============================] - 81s 48ms/step - loss: 21042.4551 - mae: 28.5008 - val_loss: 35953.1250 - val_mae: 24.6102\n","Epoch 29/40\n","1690/1690 [==============================] - 81s 48ms/step - loss: 21808.9922 - mae: 28.0751 - val_loss: 38496.0703 - val_mae: 29.0115\n","Epoch 30/40\n","1690/1690 [==============================] - 80s 47ms/step - loss: 20788.7070 - mae: 28.2299 - val_loss: 41512.9180 - val_mae: 30.1230\n","Epoch 31/40\n","1690/1690 [==============================] - 81s 48ms/step - loss: 20855.1855 - mae: 27.5287 - val_loss: 39551.0000 - val_mae: 30.8675\n","Epoch 32/40\n","1690/1690 [==============================] - 80s 48ms/step - loss: 21030.1445 - mae: 28.1227 - val_loss: 38158.1992 - val_mae: 30.2203\n","Epoch 33/40\n","1690/1690 [==============================] - 82s 48ms/step - loss: 21073.9102 - mae: 28.1320 - val_loss: 38257.8203 - val_mae: 25.7133\n","Epoch 34/40\n","1690/1690 [==============================] - 79s 47ms/step - loss: 20671.5742 - mae: 27.9145 - val_loss: 41164.8164 - val_mae: 31.8438\n","Epoch 35/40\n","1690/1690 [==============================] - 73s 43ms/step - loss: 20664.3516 - mae: 28.1247 - val_loss: 37985.6953 - val_mae: 26.3320\n","Epoch 36/40\n","1690/1690 [==============================] - 80s 47ms/step - loss: 20918.0918 - mae: 28.0720 - val_loss: 36675.8125 - val_mae: 30.6258\n","Epoch 37/40\n","1690/1690 [==============================] - 83s 49ms/step - loss: 20780.3730 - mae: 28.0043 - val_loss: 34704.7383 - val_mae: 35.9902\n","Epoch 38/40\n","1690/1690 [==============================] - 82s 48ms/step - loss: 20415.0137 - mae: 28.1735 - val_loss: 38737.7852 - val_mae: 36.3276\n","Epoch 39/40\n","1690/1690 [==============================] - 80s 47ms/step - loss: 20388.4648 - mae: 27.5849 - val_loss: 40329.5703 - val_mae: 29.3414\n","Epoch 40/40\n","1690/1690 [==============================] - 83s 49ms/step - loss: 20399.1387 - mae: 28.1860 - val_loss: 42746.1094 - val_mae: 34.5339\n","34.465243125723774\n","0.42870934514264153\n","0.9292125520173137\n","start group4,This is the experiment num: 2\n","\n","---------------------------------------------- domain num 0 is running----------------------------------\n","start training\n","Epoch 1/40\n","1690/1690 [==============================] - 84s 49ms/step - loss: 24918.9043 - mae: 26.6046 - val_loss: 35591.9688 - val_mae: 34.9942\n","Epoch 2/40\n","1690/1690 [==============================] - 81s 48ms/step - loss: 23871.5664 - mae: 25.4762 - val_loss: 30326.2031 - val_mae: 36.7388\n","Epoch 3/40\n","1690/1690 [==============================] - 82s 48ms/step - loss: 23528.1543 - mae: 25.1828 - val_loss: 30967.4922 - val_mae: 30.1979\n","Epoch 4/40\n","1690/1690 [==============================] - 82s 48ms/step - loss: 23154.3945 - mae: 24.9240 - val_loss: 27991.1133 - val_mae: 27.4626\n","Epoch 5/40\n","1690/1690 [==============================] - 79s 47ms/step - loss: 22940.3262 - mae: 25.4754 - val_loss: 32199.3262 - val_mae: 27.8363\n","Epoch 6/40\n","1690/1690 [==============================] - 81s 48ms/step - loss: 23135.2168 - mae: 26.3150 - val_loss: 30458.4648 - val_mae: 26.5655\n","Epoch 7/40\n","1690/1690 [==============================] - 82s 48ms/step - loss: 22764.0684 - mae: 26.2540 - val_loss: 32527.7930 - val_mae: 28.1817\n","Epoch 8/40\n","1690/1690 [==============================] - 81s 48ms/step - loss: 22614.5684 - mae: 26.1716 - val_loss: 30820.9629 - val_mae: 31.3289\n","Epoch 9/40\n","1690/1690 [==============================] - 80s 47ms/step - loss: 22419.1895 - mae: 26.6796 - val_loss: 35480.9531 - val_mae: 26.7625\n","Epoch 10/40\n","1690/1690 [==============================] - 79s 47ms/step - loss: 22112.4961 - mae: 27.1659 - val_loss: 31615.0332 - val_mae: 26.9117\n","Epoch 11/40\n","1690/1690 [==============================] - 82s 48ms/step - loss: 22211.4395 - mae: 26.9650 - val_loss: 35925.9102 - val_mae: 27.7498\n","Epoch 12/40\n","1690/1690 [==============================] - 80s 48ms/step - loss: 21674.8105 - mae: 27.2311 - val_loss: 37026.4453 - val_mae: 24.5468\n","Epoch 13/40\n","1690/1690 [==============================] - 81s 48ms/step - loss: 21469.3164 - mae: 27.3409 - val_loss: 33212.3477 - val_mae: 31.3688\n","Epoch 14/40\n","1690/1690 [==============================] - 82s 48ms/step - loss: 21813.3301 - mae: 27.8612 - val_loss: 37030.6836 - val_mae: 25.3720\n","Epoch 15/40\n","1690/1690 [==============================] - 79s 47ms/step - loss: 21706.5488 - mae: 27.9739 - val_loss: 34091.7695 - val_mae: 25.0115\n","Epoch 16/40\n","1690/1690 [==============================] - 79s 47ms/step - loss: 21566.8906 - mae: 28.6186 - val_loss: 37818.7539 - val_mae: 34.3083\n","Epoch 17/40\n","1690/1690 [==============================] - 82s 49ms/step - loss: 21496.4492 - mae: 27.9523 - val_loss: 35796.8008 - val_mae: 30.1157\n","Epoch 18/40\n","1690/1690 [==============================] - 82s 49ms/step - loss: 21544.3809 - mae: 28.1550 - val_loss: 39040.0391 - val_mae: 34.4712\n","Epoch 19/40\n","1690/1690 [==============================] - 82s 48ms/step - loss: 21199.2441 - mae: 27.9092 - val_loss: 39464.0938 - val_mae: 28.6229\n","Epoch 20/40\n","1690/1690 [==============================] - 81s 48ms/step - loss: 21253.0625 - mae: 27.9060 - val_loss: 42671.0781 - val_mae: 25.8200\n","Epoch 21/40\n","1690/1690 [==============================] - 83s 49ms/step - loss: 21162.7109 - mae: 28.1420 - val_loss: 36301.3711 - val_mae: 26.7277\n","Epoch 22/40\n","1690/1690 [==============================] - 82s 49ms/step - loss: 21079.6738 - mae: 28.2691 - val_loss: 38613.1641 - val_mae: 25.3503\n","Epoch 23/40\n","1690/1690 [==============================] - 82s 49ms/step - loss: 21067.3320 - mae: 28.2077 - val_loss: 40721.7344 - val_mae: 35.9718\n","Epoch 24/40\n","1690/1690 [==============================] - 84s 50ms/step - loss: 21222.6191 - mae: 28.3845 - val_loss: 36573.4531 - val_mae: 27.7062\n","Epoch 25/40\n","1690/1690 [==============================] - 85s 51ms/step - loss: 20817.2168 - mae: 27.5844 - val_loss: 36552.1523 - val_mae: 27.0268\n","Epoch 26/40\n","1690/1690 [==============================] - 82s 48ms/step - loss: 20851.5293 - mae: 28.1392 - val_loss: 39208.1484 - val_mae: 28.4157\n","Epoch 27/40\n","1690/1690 [==============================] - 83s 49ms/step - loss: 20705.4277 - mae: 28.3696 - val_loss: 40086.3086 - val_mae: 28.8590\n","Epoch 28/40\n","1690/1690 [==============================] - 84s 49ms/step - loss: 20632.3066 - mae: 27.4280 - val_loss: 41338.9844 - val_mae: 26.3843\n","Epoch 29/40\n","1690/1690 [==============================] - 84s 50ms/step - loss: 20763.8340 - mae: 27.7721 - val_loss: 38700.4844 - val_mae: 28.3962\n","Epoch 30/40\n","1690/1690 [==============================] - 83s 49ms/step - loss: 20654.7363 - mae: 27.7469 - val_loss: 37714.8203 - val_mae: 33.5033\n","Epoch 31/40\n","1690/1690 [==============================] - 85s 50ms/step - loss: 21211.7949 - mae: 28.3186 - val_loss: 39359.2266 - val_mae: 25.0590\n","Epoch 32/40\n","1690/1690 [==============================] - 85s 50ms/step - loss: 20757.0449 - mae: 28.2800 - val_loss: 40190.3555 - val_mae: 24.6787\n","Epoch 33/40\n","1690/1690 [==============================] - 82s 48ms/step - loss: 20886.2188 - mae: 27.8233 - val_loss: 39456.4883 - val_mae: 31.1755\n","Epoch 34/40\n","1690/1690 [==============================] - 84s 49ms/step - loss: 20461.6387 - mae: 28.2937 - val_loss: 36436.8633 - val_mae: 33.1323\n","Epoch 35/40\n","1690/1690 [==============================] - 84s 50ms/step - loss: 20417.9160 - mae: 27.5696 - val_loss: 39754.5859 - val_mae: 35.7841\n","Epoch 36/40\n","1690/1690 [==============================] - 86s 51ms/step - loss: 20939.2188 - mae: 27.4904 - val_loss: 36931.4531 - val_mae: 25.1000\n","Epoch 37/40\n","1690/1690 [==============================] - 85s 50ms/step - loss: 20750.4453 - mae: 28.3533 - val_loss: 41329.5938 - val_mae: 26.0115\n","Epoch 38/40\n","1690/1690 [==============================] - 86s 51ms/step - loss: 20766.8730 - mae: 28.0538 - val_loss: 42663.0078 - val_mae: 33.7408\n","Epoch 39/40\n","1690/1690 [==============================] - 85s 50ms/step - loss: 20336.0488 - mae: 27.7507 - val_loss: 40283.7734 - val_mae: 28.7790\n","Epoch 40/40\n","1690/1690 [==============================] - 86s 51ms/step - loss: 20516.7520 - mae: 27.9736 - val_loss: 42541.7070 - val_mae: 46.2960\n","45.614918574194775\n","0.0846740368159338\n","0.9159347478030352\n","start group4,This is the experiment num: 3\n","\n","---------------------------------------------- domain num 0 is running----------------------------------\n","start training\n","Epoch 1/40\n","1690/1690 [==============================] - 84s 49ms/step - loss: 24805.0137 - mae: 27.3778 - val_loss: 35336.8086 - val_mae: 35.0252\n","Epoch 2/40\n","1690/1690 [==============================] - 85s 50ms/step - loss: 23801.4258 - mae: 25.3257 - val_loss: 34329.5312 - val_mae: 24.4566\n","Epoch 3/40\n","1690/1690 [==============================] - 85s 50ms/step - loss: 23534.8906 - mae: 24.4174 - val_loss: 33402.4961 - val_mae: 27.3067\n","Epoch 4/40\n","1690/1690 [==============================] - 84s 50ms/step - loss: 23598.3477 - mae: 25.3766 - val_loss: 36470.9805 - val_mae: 28.8195\n","Epoch 5/40\n","1690/1690 [==============================] - 86s 51ms/step - loss: 23287.6465 - mae: 25.1161 - val_loss: 29617.7090 - val_mae: 25.2517\n","Epoch 6/40\n","1690/1690 [==============================] - 87s 51ms/step - loss: 23085.6758 - mae: 25.2351 - val_loss: 35004.1445 - val_mae: 30.3866\n","Epoch 7/40\n","1690/1690 [==============================] - 85s 50ms/step - loss: 22936.5430 - mae: 25.9082 - val_loss: 34221.8398 - val_mae: 24.9362\n","Epoch 8/40\n","1690/1690 [==============================] - 85s 50ms/step - loss: 22342.3770 - mae: 26.0470 - val_loss: 29864.3809 - val_mae: 33.2225\n","Epoch 9/40\n","1690/1690 [==============================] - 73s 43ms/step - loss: 22222.9121 - mae: 27.0772 - val_loss: 37385.2188 - val_mae: 29.4020\n","Epoch 10/40\n","1690/1690 [==============================] - 90s 53ms/step - loss: 22121.8223 - mae: 26.9381 - val_loss: 35440.8125 - val_mae: 34.7379\n","Epoch 11/40\n","1690/1690 [==============================] - 89s 53ms/step - loss: 21711.5859 - mae: 27.2756 - val_loss: 41375.1289 - val_mae: 24.9042\n","Epoch 12/40\n","1690/1690 [==============================] - 91s 54ms/step - loss: 21972.8691 - mae: 27.1631 - val_loss: 32286.2832 - val_mae: 28.2994\n","Epoch 13/40\n","1690/1690 [==============================] - 89s 53ms/step - loss: 21581.9570 - mae: 27.5958 - val_loss: 38414.7852 - val_mae: 31.0581\n","Epoch 14/40\n","1690/1690 [==============================] - 92s 55ms/step - loss: 21289.2344 - mae: 27.3182 - val_loss: 30038.9941 - val_mae: 26.9549\n","Epoch 15/40\n","1690/1690 [==============================] - 91s 54ms/step - loss: 21374.8828 - mae: 27.4643 - val_loss: 33959.4609 - val_mae: 33.3841\n","Epoch 16/40\n","1690/1690 [==============================] - 91s 54ms/step - loss: 21389.0137 - mae: 28.1962 - val_loss: 39739.0859 - val_mae: 28.8775\n","Epoch 17/40\n","1690/1690 [==============================] - 92s 55ms/step - loss: 21509.8867 - mae: 27.8967 - val_loss: 38392.8438 - val_mae: 27.1468\n","Epoch 18/40\n","1690/1690 [==============================] - 94s 56ms/step - loss: 21217.6816 - mae: 27.7099 - val_loss: 41831.3711 - val_mae: 25.0072\n","Epoch 19/40\n","1690/1690 [==============================] - 91s 54ms/step - loss: 21337.4121 - mae: 28.3529 - val_loss: 38246.8828 - val_mae: 29.1833\n","Epoch 20/40\n","1690/1690 [==============================] - 91s 54ms/step - loss: 21207.7559 - mae: 27.6496 - val_loss: 34801.3672 - val_mae: 25.2776\n","Epoch 21/40\n","1690/1690 [==============================] - 91s 54ms/step - loss: 21003.4531 - mae: 28.1269 - val_loss: 38428.5273 - val_mae: 30.8834\n","Epoch 22/40\n","1690/1690 [==============================] - 94s 55ms/step - loss: 20789.1328 - mae: 27.7652 - val_loss: 37823.6211 - val_mae: 36.2861\n","Epoch 23/40\n","1690/1690 [==============================] - 92s 55ms/step - loss: 20989.2598 - mae: 27.8089 - val_loss: 41420.1914 - val_mae: 29.5658\n","Epoch 24/40\n","1690/1690 [==============================] - 94s 56ms/step - loss: 21182.7852 - mae: 28.2626 - val_loss: 37525.2617 - val_mae: 28.3390\n","Epoch 25/40\n","1690/1690 [==============================] - 94s 56ms/step - loss: 20973.6738 - mae: 28.0921 - val_loss: 35574.5000 - val_mae: 31.1505\n","Epoch 26/40\n","1690/1690 [==============================] - 93s 55ms/step - loss: 20928.9980 - mae: 27.9326 - val_loss: 36277.0703 - val_mae: 30.8596\n","Epoch 27/40\n","1690/1690 [==============================] - 93s 55ms/step - loss: 20849.7754 - mae: 27.5968 - val_loss: 39791.1016 - val_mae: 29.5379\n","Epoch 28/40\n","1690/1690 [==============================] - 92s 55ms/step - loss: 20657.9297 - mae: 28.0479 - val_loss: 39101.1055 - val_mae: 31.6869\n","Epoch 29/40\n","1690/1690 [==============================] - 93s 55ms/step - loss: 20878.2441 - mae: 28.0564 - val_loss: 42504.6289 - val_mae: 33.6585\n","Epoch 30/40\n","1690/1690 [==============================] - 93s 55ms/step - loss: 20846.0254 - mae: 28.1265 - val_loss: 40448.3047 - val_mae: 25.9261\n","Epoch 31/40\n","1690/1690 [==============================] - 93s 55ms/step - loss: 20828.7051 - mae: 28.2199 - val_loss: 38292.3672 - val_mae: 31.7101\n","Epoch 32/40\n","1690/1690 [==============================] - 95s 56ms/step - loss: 20595.1934 - mae: 28.2903 - val_loss: 39264.3242 - val_mae: 29.0516\n","Epoch 33/40\n","1690/1690 [==============================] - 97s 58ms/step - loss: 20816.7129 - mae: 27.3512 - val_loss: 39152.7109 - val_mae: 31.0933\n","Epoch 34/40\n","1690/1690 [==============================] - 97s 58ms/step - loss: 20822.7812 - mae: 28.3617 - val_loss: 39098.2070 - val_mae: 35.2077\n","Epoch 35/40\n","1690/1690 [==============================] - 100s 59ms/step - loss: 20772.5625 - mae: 27.8354 - val_loss: 41010.3086 - val_mae: 36.0371\n","Epoch 36/40\n","1690/1690 [==============================] - 97s 58ms/step - loss: 20536.5684 - mae: 28.0228 - val_loss: 39288.0273 - val_mae: 35.3752\n","Epoch 37/40\n","1690/1690 [==============================] - 99s 59ms/step - loss: 20643.9922 - mae: 27.5331 - val_loss: 41604.2617 - val_mae: 30.5372\n","Epoch 38/40\n","1690/1690 [==============================] - 101s 60ms/step - loss: 20629.1602 - mae: 27.9328 - val_loss: 41596.8750 - val_mae: 31.4664\n","Epoch 39/40\n","1690/1690 [==============================] - 98s 58ms/step - loss: 20651.0918 - mae: 27.6380 - val_loss: 38895.2383 - val_mae: 30.1745\n","Epoch 40/40\n","1690/1690 [==============================] - 98s 58ms/step - loss: 20442.5469 - mae: 27.8454 - val_loss: 41599.7578 - val_mae: 33.4444\n","33.36901845739343\n","0.4561934857897503\n","0.9202465779372372\n","start group4,This is the experiment num: 4\n","\n","---------------------------------------------- domain num 0 is running----------------------------------\n","start training\n","Epoch 1/40\n","1690/1690 [==============================] - 93s 54ms/step - loss: 24693.6465 - mae: 27.2369 - val_loss: 39310.6328 - val_mae: 33.1019\n","Epoch 2/40\n","1690/1690 [==============================] - 92s 54ms/step - loss: 23757.0859 - mae: 24.4929 - val_loss: 35076.8047 - val_mae: 28.3156\n","Epoch 3/40\n","1690/1690 [==============================] - 93s 55ms/step - loss: 23336.9668 - mae: 24.8206 - val_loss: 27451.9316 - val_mae: 23.8645\n","Epoch 4/40\n","1690/1690 [==============================] - 93s 55ms/step - loss: 23199.8770 - mae: 24.9002 - val_loss: 29640.6465 - val_mae: 31.7402\n","Epoch 5/40\n","1690/1690 [==============================] - 94s 55ms/step - loss: 23264.2090 - mae: 25.5988 - val_loss: 30341.8438 - val_mae: 30.3426\n","Epoch 6/40\n","1690/1690 [==============================] - 95s 56ms/step - loss: 23213.6855 - mae: 25.7627 - val_loss: 30223.7109 - val_mae: 39.6259\n","Epoch 7/40\n","1690/1690 [==============================] - 96s 57ms/step - loss: 22853.9395 - mae: 26.1194 - val_loss: 26419.2070 - val_mae: 30.2296\n","Epoch 8/40\n","1690/1690 [==============================] - 97s 57ms/step - loss: 22825.6973 - mae: 26.6802 - val_loss: 32673.8535 - val_mae: 24.3705\n","Epoch 9/40\n","1690/1690 [==============================] - 97s 57ms/step - loss: 22267.2070 - mae: 26.3143 - val_loss: 31978.8047 - val_mae: 23.9962\n","Epoch 10/40\n","1690/1690 [==============================] - 97s 58ms/step - loss: 21956.1172 - mae: 26.4620 - val_loss: 33272.8242 - val_mae: 27.7272\n","Epoch 11/40\n","1690/1690 [==============================] - 96s 57ms/step - loss: 22161.9941 - mae: 27.1435 - val_loss: 28746.8223 - val_mae: 25.2255\n","Epoch 12/40\n","1690/1690 [==============================] - 96s 57ms/step - loss: 21603.0547 - mae: 27.2369 - val_loss: 33936.2734 - val_mae: 28.4729\n","Epoch 13/40\n","1690/1690 [==============================] - 97s 57ms/step - loss: 21621.7793 - mae: 28.1498 - val_loss: 33472.0078 - val_mae: 30.7343\n","Epoch 14/40\n","1690/1690 [==============================] - 97s 57ms/step - loss: 21692.2871 - mae: 27.8585 - val_loss: 35888.0781 - val_mae: 32.6993\n","Epoch 15/40\n","1690/1690 [==============================] - 97s 58ms/step - loss: 21583.1680 - mae: 27.7946 - val_loss: 30365.3203 - val_mae: 22.8145\n","Epoch 16/40\n","1690/1690 [==============================] - 96s 57ms/step - loss: 21625.6895 - mae: 27.7606 - val_loss: 34651.5547 - val_mae: 22.9022\n","Epoch 17/40\n","1690/1690 [==============================] - 97s 57ms/step - loss: 21394.0664 - mae: 28.0017 - val_loss: 32424.0840 - val_mae: 27.6922\n","Epoch 18/40\n","1690/1690 [==============================] - 95s 56ms/step - loss: 21106.7559 - mae: 27.8577 - val_loss: 34781.0312 - val_mae: 26.4505\n","Epoch 19/40\n","1690/1690 [==============================] - 96s 57ms/step - loss: 21376.1230 - mae: 27.8109 - val_loss: 35566.2188 - val_mae: 28.9366\n","Epoch 20/40\n","1690/1690 [==============================] - 97s 57ms/step - loss: 21063.5918 - mae: 27.8823 - val_loss: 32723.2227 - val_mae: 22.5629\n","Epoch 21/40\n","1690/1690 [==============================] - 94s 56ms/step - loss: 20951.0312 - mae: 27.7050 - val_loss: 37777.5000 - val_mae: 23.8343\n","Epoch 22/40\n","1690/1690 [==============================] - 97s 58ms/step - loss: 21019.6094 - mae: 28.3379 - val_loss: 38469.7461 - val_mae: 30.9719\n","Epoch 23/40\n","1690/1690 [==============================] - 97s 57ms/step - loss: 20963.4844 - mae: 28.2080 - val_loss: 39242.9023 - val_mae: 30.7988\n","Epoch 24/40\n","1690/1690 [==============================] - 96s 57ms/step - loss: 21048.0039 - mae: 27.9850 - val_loss: 37527.5664 - val_mae: 28.4883\n","Epoch 25/40\n","1690/1690 [==============================] - 94s 56ms/step - loss: 20957.7637 - mae: 27.6598 - val_loss: 34175.4141 - val_mae: 25.6373\n","Epoch 26/40\n","1690/1690 [==============================] - 94s 56ms/step - loss: 21060.9238 - mae: 28.0259 - val_loss: 38230.5039 - val_mae: 27.2107\n","Epoch 27/40\n","1690/1690 [==============================] - 94s 56ms/step - loss: 20923.1680 - mae: 28.0696 - val_loss: 44158.6133 - val_mae: 34.3921\n","Epoch 28/40\n","1690/1690 [==============================] - 94s 56ms/step - loss: 20514.7324 - mae: 27.5198 - val_loss: 35996.0469 - val_mae: 28.4285\n","Epoch 29/40\n","1690/1690 [==============================] - 96s 57ms/step - loss: 20450.6270 - mae: 27.8449 - val_loss: 40130.9492 - val_mae: 28.8384\n","Epoch 30/40\n","1690/1690 [==============================] - 98s 58ms/step - loss: 20723.1934 - mae: 28.1991 - val_loss: 39361.3867 - val_mae: 34.6039\n","Epoch 31/40\n","1690/1690 [==============================] - 98s 58ms/step - loss: 20793.2363 - mae: 27.9881 - val_loss: 40349.0195 - val_mae: 31.1015\n","Epoch 32/40\n","1690/1690 [==============================] - 98s 58ms/step - loss: 20568.2891 - mae: 27.5784 - val_loss: 43529.4531 - val_mae: 40.5556\n","Epoch 33/40\n","1690/1690 [==============================] - 98s 58ms/step - loss: 20375.9180 - mae: 27.9080 - val_loss: 42186.4922 - val_mae: 36.5724\n","Epoch 34/40\n","1690/1690 [==============================] - 97s 57ms/step - loss: 20515.6543 - mae: 28.0172 - val_loss: 39913.0195 - val_mae: 37.5809\n","Epoch 35/40\n","1690/1690 [==============================] - 97s 58ms/step - loss: 20548.3262 - mae: 27.8279 - val_loss: 40777.0430 - val_mae: 31.3078\n","Epoch 36/40\n","1690/1690 [==============================] - 98s 58ms/step - loss: 20466.0020 - mae: 27.9617 - val_loss: 41734.3594 - val_mae: 28.4324\n","Epoch 37/40\n","1690/1690 [==============================] - 97s 58ms/step - loss: 20741.7520 - mae: 28.1694 - val_loss: 41332.8672 - val_mae: 26.7952\n","Epoch 38/40\n","1690/1690 [==============================] - 99s 59ms/step - loss: 20735.4531 - mae: 27.4598 - val_loss: 41140.5117 - val_mae: 36.1287\n","Epoch 39/40\n","1690/1690 [==============================] - 98s 58ms/step - loss: 20423.5391 - mae: 28.5977 - val_loss: 44210.7500 - val_mae: 31.1671\n","Epoch 40/40\n","1690/1690 [==============================] - 100s 59ms/step - loss: 20346.8457 - mae: 28.1620 - val_loss: 41456.1055 - val_mae: 31.0795\n","31.585780503667305\n","0.5638951682455833\n","0.9322200733643536\n"]}]},{"cell_type":"code","source":["trainfile1=\"/content/drive/MyDrive/training_data/fridge_test_.csv\"\n","trainfile2=\"/content/drive/MyDrive/training_data/fridge_house_2_training_.csv\"\n","trainfile3=\"/content/drive/MyDrive/ukdale_training/fridge_house_1_training_.csv\"\n","trainfile4=\"/content/drive/MyDrive/ukdale_training/fridge_house_2_training_.csv\"\n","trainfile5=\"/content/drive/MyDrive/refit_training/fridge/fridge_house_12_training_.csv\"\n","trainfile6=\"/content/drive/MyDrive/refit_training/fridge/fridge_house_15_training_.csv\"\n","fileList=[trainfile1,trainfile2,trainfile3,trainfile4,trainfile5,trainfile6]\n","stepsizeList=[2,2,16,16,16,16]\n","data_insts, data_labels, num_insts,on = [], [], [],[]\n","threshold=50\n","for i in range(len(fileList)):\n","    X,Y=dataProvider(fileList[i], 19, stepsizeList[i], threshold)\n","    Y=Y.reshape(-1,1)\n","    data_insts.append(X)\n","    data_labels.append(Y)\n","    num_insts.append(X.shape[0])\n","min_size=min(num_insts)\n","x_tem, y_tem=[],[]\n","for j in range(len(fileList)):\n","  ridx = np.random.choice(num_insts[j], min_size)\n","  x_tem.append(data_insts[j][ridx, :])\n","  y_tem.append(data_labels[j][ridx, :])\n","  num_insts[j]=x_tem[j].shape[0]\n","data_insts=x_tem\n","data_labels=y_tem \n","print(num_insts)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I1hTfE03N_Gl","executionInfo":{"status":"ok","timestamp":1660631499973,"user_tz":-600,"elapsed":13475,"user":{"displayName":"XIAOMIN CHANG","userId":"17429039977919006081"}},"outputId":"9d050820-97a8-4a6e-f3b0-799af7f830ca"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[15017, 15017, 15017, 15017, 15017, 15017]\n"]}]},{"cell_type":"code","source":["trainfile1=\"/content/drive/MyDrive/refit_training/fridge/fridge_house_2_training_.csv\"\n","trainfile2=\"/content/drive/MyDrive/refit_training/fridge/fridge_house_5_training_.csv\"\n","trainfile3=\"/content/drive/MyDrive/refit_training/fridge/fridge_house_9_training_.csv\"\n","trainfile4=\"/content/drive/MyDrive/refit_training/fridge/fridge_house_12_training_.csv\"\n","trainfile5=\"/content/drive/MyDrive/refit_training/fridge/fridge_house_15_training_.csv\"\n","fileList=[trainfile1,trainfile2,trainfile3,trainfile4,trainfile5]\n","stepsizeList=[16,16,16,16,16]\n","data_insts, data_labels, num_insts,on = [], [], [],[]\n","threshold=50\n","for i in range(len(fileList)):\n","    X,Y=dataProvider(fileList[i], 19, stepsizeList[i], threshold)\n","    Y=Y.reshape(-1,1)\n","    data_insts.append(X)\n","    data_labels.append(Y)\n","    num_insts.append(X.shape[0])\n","min_size=min(num_insts)\n","x_tem, y_tem=[],[]\n","for j in range(len(fileList)):\n","  ridx = np.random.choice(num_insts[j], min_size)\n","  x_tem.append(data_insts[j][ridx, :])\n","  y_tem.append(data_labels[j][ridx, :])\n","  num_insts[j]=x_tem[j].shape[0]\n","data_insts=x_tem\n","data_labels=y_tem \n","print(num_insts)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"phuVKMj-Z4ke","executionInfo":{"status":"ok","timestamp":1660885608324,"user_tz":-600,"elapsed":10634,"user":{"displayName":"XIAOMIN CHANG","userId":"17429039977919006081"}},"outputId":"1a4d83bd-9bf1-4adb-88db-a3957770727b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[71669, 71669, 71669, 71669, 71669]\n"]}]},{"cell_type":"code","source":["for i in [1]:\n","        print('\\n---------------------------------------------- domain num %i is running----------------------------------'%(i))\n","        # Build source instances.\n","        source_insts = []\n","        source_labels = []\n","        for j in range(len(fileList)):\n","            if j != i:\n","                source_insts.append(data_insts[j])\n","                source_labels.append(data_labels[j])\n","        # Build target instances.\n","        target_idx = i\n","        target_insts = data_insts[i]\n","        target_labels = data_labels[i]\n","        target_insts0, X_t, target_labels0, y_t =train_test_split(target_insts, target_labels, test_size=0.2,random_state=100)\n","        \n","        X=np.concatenate(source_insts, axis=0)\n","        Y=np.concatenate(source_labels, axis=0)\n","        \n","        x_train_all, x_test, y_train_all, y_test =train_test_split(X, Y, test_size=0.2,random_state=100)\n","        model=CNN_training_best(X,Y)\n","        prediction=model.predict(X_t)\n","        stopT=get_mae(y_t, prediction)\n","        print(stopT)\n","        print(get_sae(y_t, prediction))\n","        print(get_nde(y_t, prediction))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DMr8TFm_aKvl","executionInfo":{"status":"ok","timestamp":1660891009060,"user_tz":-600,"elapsed":5400167,"user":{"displayName":"XIAOMIN CHANG","userId":"17429039977919006081"}},"outputId":"9ae6876f-c91e-4d05-9129-3fa7fa6d61e6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","---------------------------------------------- domain num 1 is running----------------------------------\n","start training\n","Epoch 1/50\n","3584/3584 [==============================] - 127s 35ms/step - loss: 2765.6609 - mae: 38.7874 - val_loss: 1500.3828 - val_mae: 35.2442\n","Epoch 2/50\n","3584/3584 [==============================] - 123s 34ms/step - loss: 2373.1526 - mae: 38.0297 - val_loss: 2090.2600 - val_mae: 41.8835\n","Epoch 3/50\n","3584/3584 [==============================] - 119s 33ms/step - loss: 2368.2993 - mae: 37.8935 - val_loss: 2010.1548 - val_mae: 41.0903\n","Epoch 4/50\n","3584/3584 [==============================] - 121s 34ms/step - loss: 2359.9233 - mae: 37.7106 - val_loss: 1812.5397 - val_mae: 39.1214\n","Epoch 5/50\n","3584/3584 [==============================] - 119s 33ms/step - loss: 2354.6228 - mae: 37.5632 - val_loss: 2109.7861 - val_mae: 41.9465\n","Epoch 6/50\n","3584/3584 [==============================] - 118s 33ms/step - loss: 2353.4556 - mae: 37.5014 - val_loss: 1378.4595 - val_mae: 31.6540\n","Epoch 7/50\n","3584/3584 [==============================] - 117s 33ms/step - loss: 2353.0718 - mae: 37.4672 - val_loss: 1880.9672 - val_mae: 39.8906\n","Epoch 8/50\n","3584/3584 [==============================] - 116s 32ms/step - loss: 2348.2090 - mae: 37.3945 - val_loss: 1924.9402 - val_mae: 40.7726\n","Epoch 9/50\n","3584/3584 [==============================] - 115s 32ms/step - loss: 2347.5571 - mae: 37.3579 - val_loss: 1921.8260 - val_mae: 40.3104\n","Epoch 10/50\n","3584/3584 [==============================] - 117s 33ms/step - loss: 2343.5681 - mae: 37.3181 - val_loss: 1771.0623 - val_mae: 38.6008\n","Epoch 11/50\n","3584/3584 [==============================] - 113s 32ms/step - loss: 2345.4177 - mae: 37.3257 - val_loss: 1966.6344 - val_mae: 41.1893\n","Epoch 12/50\n","3584/3584 [==============================] - 114s 32ms/step - loss: 2340.0774 - mae: 37.2453 - val_loss: 2276.9543 - val_mae: 43.5851\n","Epoch 13/50\n","3584/3584 [==============================] - 113s 31ms/step - loss: 2339.1992 - mae: 37.2381 - val_loss: 1744.9910 - val_mae: 37.6542\n","Epoch 14/50\n","3584/3584 [==============================] - 110s 31ms/step - loss: 2339.0393 - mae: 37.1987 - val_loss: 1929.1443 - val_mae: 40.8813\n","Epoch 15/50\n","3584/3584 [==============================] - 110s 31ms/step - loss: 2337.5093 - mae: 37.1710 - val_loss: 2013.0918 - val_mae: 41.5732\n","Epoch 16/50\n","3584/3584 [==============================] - 109s 31ms/step - loss: 2334.1121 - mae: 37.1310 - val_loss: 1832.2500 - val_mae: 38.8316\n","Epoch 17/50\n","3584/3584 [==============================] - 109s 31ms/step - loss: 2333.9932 - mae: 37.1162 - val_loss: 1800.0448 - val_mae: 38.6058\n","Epoch 18/50\n","3584/3584 [==============================] - 109s 30ms/step - loss: 2333.6536 - mae: 37.1295 - val_loss: 1960.2527 - val_mae: 40.9515\n","Epoch 19/50\n","3584/3584 [==============================] - 108s 30ms/step - loss: 2327.6597 - mae: 37.0374 - val_loss: 1775.6146 - val_mae: 38.0557\n","Epoch 20/50\n","3584/3584 [==============================] - 108s 30ms/step - loss: 2326.4077 - mae: 37.0572 - val_loss: 1818.8315 - val_mae: 38.8940\n","Epoch 21/50\n","3584/3584 [==============================] - 108s 30ms/step - loss: 2325.7344 - mae: 37.0139 - val_loss: 1925.4865 - val_mae: 40.7609\n","Epoch 22/50\n","3584/3584 [==============================] - 108s 30ms/step - loss: 2324.3230 - mae: 36.9922 - val_loss: 1964.3933 - val_mae: 40.5804\n","Epoch 23/50\n","3584/3584 [==============================] - 106s 30ms/step - loss: 2324.7244 - mae: 36.9527 - val_loss: 2024.6576 - val_mae: 41.7623\n","Epoch 24/50\n","3584/3584 [==============================] - 108s 30ms/step - loss: 2318.3901 - mae: 36.8987 - val_loss: 1796.9331 - val_mae: 38.8234\n","Epoch 25/50\n","3584/3584 [==============================] - 108s 30ms/step - loss: 2317.0674 - mae: 36.8543 - val_loss: 1933.8171 - val_mae: 40.3457\n","Epoch 26/50\n","3584/3584 [==============================] - 105s 29ms/step - loss: 2312.1226 - mae: 36.7965 - val_loss: 1956.4995 - val_mae: 40.6392\n","Epoch 27/50\n","3584/3584 [==============================] - 107s 30ms/step - loss: 2309.6646 - mae: 36.7582 - val_loss: 2040.6650 - val_mae: 41.6969\n","Epoch 28/50\n","3584/3584 [==============================] - 104s 29ms/step - loss: 2307.4150 - mae: 36.7061 - val_loss: 1838.1349 - val_mae: 39.1780\n","Epoch 29/50\n","3584/3584 [==============================] - 104s 29ms/step - loss: 2306.1035 - mae: 36.6884 - val_loss: 1990.9714 - val_mae: 41.0656\n","Epoch 30/50\n","3584/3584 [==============================] - 104s 29ms/step - loss: 2302.6179 - mae: 36.6213 - val_loss: 2003.4602 - val_mae: 40.7097\n","Epoch 31/50\n","3584/3584 [==============================] - 103s 29ms/step - loss: 2299.0491 - mae: 36.5548 - val_loss: 1963.1023 - val_mae: 40.6914\n","Epoch 32/50\n","3584/3584 [==============================] - 104s 29ms/step - loss: 2296.4216 - mae: 36.5366 - val_loss: 1987.5013 - val_mae: 40.6719\n","Epoch 33/50\n","3584/3584 [==============================] - 103s 29ms/step - loss: 2296.2463 - mae: 36.5138 - val_loss: 2074.0303 - val_mae: 41.7654\n","Epoch 34/50\n","3584/3584 [==============================] - 102s 28ms/step - loss: 2293.5093 - mae: 36.4469 - val_loss: 1985.6437 - val_mae: 40.5551\n","Epoch 35/50\n","3584/3584 [==============================] - 102s 28ms/step - loss: 2292.5034 - mae: 36.4946 - val_loss: 1896.5118 - val_mae: 39.7557\n","Epoch 36/50\n","3584/3584 [==============================] - 103s 29ms/step - loss: 2290.0898 - mae: 36.4353 - val_loss: 2014.0996 - val_mae: 41.2138\n","Epoch 37/50\n","3584/3584 [==============================] - 103s 29ms/step - loss: 2287.4873 - mae: 36.4088 - val_loss: 1964.5294 - val_mae: 40.2676\n","Epoch 38/50\n","3584/3584 [==============================] - 104s 29ms/step - loss: 2286.4805 - mae: 36.4035 - val_loss: 1969.4927 - val_mae: 40.8119\n","Epoch 39/50\n","3584/3584 [==============================] - 103s 29ms/step - loss: 2282.1628 - mae: 36.3328 - val_loss: 1973.9825 - val_mae: 40.5640\n","Epoch 40/50\n","3584/3584 [==============================] - 103s 29ms/step - loss: 2285.3035 - mae: 36.4097 - val_loss: 1944.9257 - val_mae: 40.1415\n","Epoch 41/50\n","3584/3584 [==============================] - 102s 28ms/step - loss: 2281.2119 - mae: 36.3263 - val_loss: 2044.9075 - val_mae: 40.8169\n","Epoch 42/50\n","3584/3584 [==============================] - 100s 28ms/step - loss: 2280.9827 - mae: 36.3430 - val_loss: 2080.2471 - val_mae: 42.0351\n","Epoch 43/50\n","3584/3584 [==============================] - 102s 28ms/step - loss: 2277.3091 - mae: 36.3457 - val_loss: 2030.6146 - val_mae: 41.2873\n","Epoch 44/50\n","3584/3584 [==============================] - 101s 28ms/step - loss: 2280.0115 - mae: 36.3357 - val_loss: 1980.8772 - val_mae: 40.9528\n","Epoch 45/50\n","3584/3584 [==============================] - 101s 28ms/step - loss: 2277.1094 - mae: 36.3146 - val_loss: 1952.4241 - val_mae: 40.0945\n","Epoch 46/50\n","3584/3584 [==============================] - 101s 28ms/step - loss: 2277.2419 - mae: 36.3082 - val_loss: 1921.1565 - val_mae: 40.1565\n","Epoch 47/50\n","3584/3584 [==============================] - 101s 28ms/step - loss: 2272.6504 - mae: 36.2479 - val_loss: 1966.3396 - val_mae: 40.6320\n","Epoch 48/50\n","3584/3584 [==============================] - 100s 28ms/step - loss: 2272.4021 - mae: 36.2451 - val_loss: 1837.2323 - val_mae: 39.3850\n","Epoch 49/50\n","3584/3584 [==============================] - 101s 28ms/step - loss: 2275.0227 - mae: 36.2851 - val_loss: 1933.4742 - val_mae: 39.3979\n","Epoch 50/50\n","3584/3584 [==============================] - 101s 28ms/step - loss: 2269.1929 - mae: 36.2551 - val_loss: 1970.5112 - val_mae: 40.9916\n","57.63654766100062\n","0.07333084920728646\n","0.780932185251402\n"]}]},{"cell_type":"code","source":["for i in [0,2,5]:\n","        print('\\n---------------------------------------------- domain num %i is running----------------------------------'%(i))\n","        # Build source instances.\n","        source_insts = []\n","        source_labels = []\n","        for j in range(len(fileList)):\n","            if j != i:\n","                source_insts.append(data_insts[j])\n","                source_labels.append(data_labels[j])\n","        # Build target instances.\n","        target_idx = i\n","        target_insts = data_insts[i]\n","        target_labels = data_labels[i]\n","        target_insts0, X_t, target_labels0, y_t =train_test_split(target_insts, target_labels, test_size=0.2,random_state=100)\n","        \n","        X=np.concatenate(source_insts, axis=0)\n","        Y=np.concatenate(source_labels, axis=0)\n","        \n","        x_train_all, x_test, y_train_all, y_test =train_test_split(X, Y, test_size=0.2,random_state=100)\n","        model=CNN_training_best(X,Y)\n","        prediction=model.predict(X_t)\n","        stopT=get_mae(y_t, prediction)\n","        print(stopT)\n","        print(get_sae(y_t, prediction))\n","        print(get_nde(y_t, prediction))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tFw8eSCrz11_","executionInfo":{"status":"ok","timestamp":1660639251359,"user_tz":-600,"elapsed":7751397,"user":{"displayName":"XIAOMIN CHANG","userId":"17429039977919006081"}},"outputId":"cc58e28e-0fda-4545-85e5-f470605bd26d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","---------------------------------------------- domain num 0 is running----------------------------------\n","start training\n","Epoch 1/50\n","939/939 [==============================] - 62s 64ms/step - loss: 4087.4934 - mae: 42.5080 - val_loss: 1762.5642 - val_mae: 33.8645\n","Epoch 2/50\n","939/939 [==============================] - 52s 55ms/step - loss: 3389.8281 - mae: 41.1931 - val_loss: 1835.3457 - val_mae: 34.5247\n","Epoch 3/50\n","939/939 [==============================] - 52s 55ms/step - loss: 3353.7578 - mae: 40.9616 - val_loss: 1717.6984 - val_mae: 31.4909\n","Epoch 4/50\n","939/939 [==============================] - 51s 54ms/step - loss: 3332.5139 - mae: 40.6672 - val_loss: 1975.4424 - val_mae: 36.4030\n","Epoch 5/50\n","939/939 [==============================] - 53s 56ms/step - loss: 3322.2432 - mae: 40.5385 - val_loss: 1910.5995 - val_mae: 35.5875\n","Epoch 6/50\n","939/939 [==============================] - 54s 58ms/step - loss: 3303.5430 - mae: 40.2624 - val_loss: 1808.4558 - val_mae: 33.8218\n","Epoch 7/50\n","939/939 [==============================] - 50s 53ms/step - loss: 3295.9587 - mae: 40.4409 - val_loss: 1913.1362 - val_mae: 33.4851\n","Epoch 8/50\n","939/939 [==============================] - 51s 55ms/step - loss: 3290.3809 - mae: 40.2780 - val_loss: 2010.9827 - val_mae: 36.5631\n","Epoch 9/50\n","939/939 [==============================] - 51s 54ms/step - loss: 3281.3948 - mae: 40.1291 - val_loss: 1837.0826 - val_mae: 35.2432\n","Epoch 10/50\n","939/939 [==============================] - 50s 54ms/step - loss: 3269.2295 - mae: 40.0965 - val_loss: 1837.2739 - val_mae: 34.0763\n","Epoch 11/50\n","939/939 [==============================] - 46s 49ms/step - loss: 3271.0613 - mae: 40.1173 - val_loss: 1910.2954 - val_mae: 34.4966\n","Epoch 12/50\n","939/939 [==============================] - 48s 51ms/step - loss: 3270.1277 - mae: 40.0852 - val_loss: 1767.6884 - val_mae: 34.5915\n","Epoch 13/50\n","939/939 [==============================] - 50s 53ms/step - loss: 3256.9060 - mae: 39.9817 - val_loss: 1864.5181 - val_mae: 35.4219\n","Epoch 14/50\n","939/939 [==============================] - 49s 52ms/step - loss: 3241.6804 - mae: 39.7938 - val_loss: 1714.6738 - val_mae: 32.9697\n","Epoch 15/50\n","939/939 [==============================] - 48s 51ms/step - loss: 3251.1475 - mae: 39.8870 - val_loss: 2129.6960 - val_mae: 37.8344\n","Epoch 16/50\n","939/939 [==============================] - 52s 55ms/step - loss: 3254.2468 - mae: 39.9160 - val_loss: 1813.9094 - val_mae: 34.5465\n","Epoch 17/50\n","939/939 [==============================] - 48s 51ms/step - loss: 3238.5715 - mae: 39.6829 - val_loss: 2079.6665 - val_mae: 37.9646\n","Epoch 18/50\n","939/939 [==============================] - 47s 50ms/step - loss: 3238.0354 - mae: 39.7377 - val_loss: 1749.8546 - val_mae: 34.0577\n","Epoch 19/50\n","939/939 [==============================] - 50s 54ms/step - loss: 3252.3535 - mae: 39.8749 - val_loss: 1957.4486 - val_mae: 36.3200\n","Epoch 20/50\n","939/939 [==============================] - 48s 52ms/step - loss: 3231.4180 - mae: 39.6128 - val_loss: 1840.0664 - val_mae: 36.3244\n","Epoch 21/50\n","939/939 [==============================] - 49s 52ms/step - loss: 3239.7607 - mae: 39.8324 - val_loss: 1908.5724 - val_mae: 35.2683\n","Epoch 22/50\n","939/939 [==============================] - 51s 54ms/step - loss: 3222.5603 - mae: 39.5928 - val_loss: 1810.4296 - val_mae: 36.1558\n","Epoch 23/50\n","939/939 [==============================] - 48s 52ms/step - loss: 3229.2710 - mae: 39.7882 - val_loss: 2004.4208 - val_mae: 36.5932\n","Epoch 24/50\n","939/939 [==============================] - 50s 53ms/step - loss: 3215.0227 - mae: 39.5681 - val_loss: 1940.9392 - val_mae: 37.3535\n","Epoch 25/50\n","939/939 [==============================] - 48s 51ms/step - loss: 3206.5657 - mae: 39.5477 - val_loss: 1916.5536 - val_mae: 35.4825\n","Epoch 26/50\n","939/939 [==============================] - 48s 51ms/step - loss: 3200.3574 - mae: 39.3923 - val_loss: 2014.6801 - val_mae: 36.9697\n","Epoch 27/50\n","939/939 [==============================] - 49s 53ms/step - loss: 3197.7939 - mae: 39.3822 - val_loss: 1955.0171 - val_mae: 35.8777\n","Epoch 28/50\n","939/939 [==============================] - 46s 49ms/step - loss: 3194.3018 - mae: 39.2840 - val_loss: 1940.4749 - val_mae: 35.1790\n","Epoch 29/50\n","939/939 [==============================] - 49s 53ms/step - loss: 3188.2676 - mae: 39.5089 - val_loss: 1915.0312 - val_mae: 35.7621\n","Epoch 30/50\n","939/939 [==============================] - 50s 54ms/step - loss: 3194.9219 - mae: 39.5081 - val_loss: 1909.7756 - val_mae: 35.4963\n","Epoch 31/50\n","939/939 [==============================] - 48s 51ms/step - loss: 3186.4963 - mae: 39.3201 - val_loss: 1863.2747 - val_mae: 36.5212\n","Epoch 32/50\n","939/939 [==============================] - 49s 52ms/step - loss: 3175.3396 - mae: 39.2144 - val_loss: 2018.5614 - val_mae: 37.6830\n","Epoch 33/50\n","939/939 [==============================] - 50s 54ms/step - loss: 3176.4180 - mae: 39.3361 - val_loss: 1985.5740 - val_mae: 37.5991\n","Epoch 34/50\n","939/939 [==============================] - 50s 53ms/step - loss: 3173.5623 - mae: 39.2657 - val_loss: 1804.6628 - val_mae: 34.4784\n","Epoch 35/50\n","939/939 [==============================] - 57s 60ms/step - loss: 3177.4922 - mae: 39.3072 - val_loss: 1954.6785 - val_mae: 36.5447\n","Epoch 36/50\n","939/939 [==============================] - 54s 57ms/step - loss: 3163.5217 - mae: 39.1836 - val_loss: 1847.1199 - val_mae: 35.9758\n","Epoch 37/50\n","939/939 [==============================] - 54s 58ms/step - loss: 3156.5586 - mae: 39.1760 - val_loss: 2063.4524 - val_mae: 37.6047\n","Epoch 38/50\n","939/939 [==============================] - 55s 59ms/step - loss: 3141.9629 - mae: 39.0044 - val_loss: 1778.6609 - val_mae: 34.4590\n","Epoch 39/50\n","939/939 [==============================] - 52s 56ms/step - loss: 3156.1897 - mae: 39.2023 - val_loss: 1814.4612 - val_mae: 35.2393\n","Epoch 40/50\n","939/939 [==============================] - 54s 58ms/step - loss: 3147.8423 - mae: 39.0738 - val_loss: 2061.2590 - val_mae: 37.9198\n","Epoch 41/50\n","939/939 [==============================] - 54s 57ms/step - loss: 3145.6338 - mae: 39.0095 - val_loss: 1965.5027 - val_mae: 36.6147\n","Epoch 42/50\n","939/939 [==============================] - 51s 54ms/step - loss: 3144.5518 - mae: 38.9916 - val_loss: 2172.8481 - val_mae: 38.9462\n","Epoch 43/50\n","939/939 [==============================] - 52s 56ms/step - loss: 3138.8726 - mae: 38.9125 - val_loss: 1766.5751 - val_mae: 34.3061\n","Epoch 44/50\n","939/939 [==============================] - 51s 54ms/step - loss: 3137.7524 - mae: 38.9762 - val_loss: 1984.5209 - val_mae: 37.1839\n","Epoch 45/50\n","939/939 [==============================] - 51s 55ms/step - loss: 3132.0920 - mae: 38.9103 - val_loss: 1873.4069 - val_mae: 34.8838\n","Epoch 46/50\n","939/939 [==============================] - 51s 55ms/step - loss: 3130.5493 - mae: 38.9031 - val_loss: 2147.5676 - val_mae: 38.9693\n","Epoch 47/50\n","939/939 [==============================] - 51s 54ms/step - loss: 3131.7734 - mae: 38.9869 - val_loss: 2004.0854 - val_mae: 37.7283\n","Epoch 48/50\n","939/939 [==============================] - 52s 56ms/step - loss: 3123.7861 - mae: 38.8249 - val_loss: 1811.6533 - val_mae: 35.2014\n","Epoch 49/50\n","939/939 [==============================] - 50s 53ms/step - loss: 3118.5356 - mae: 38.9328 - val_loss: 1832.8881 - val_mae: 36.0217\n","Epoch 50/50\n","939/939 [==============================] - 50s 54ms/step - loss: 3126.7563 - mae: 38.8807 - val_loss: 1964.4320 - val_mae: 36.1834\n","57.003156866264824\n","0.050376017355683596\n","0.7267207921228848\n","\n","---------------------------------------------- domain num 2 is running----------------------------------\n","start training\n","Epoch 1/50\n","939/939 [==============================] - 54s 56ms/step - loss: 5023.4775 - mae: 46.5814 - val_loss: 2407.6895 - val_mae: 40.6672\n","Epoch 2/50\n","939/939 [==============================] - 52s 56ms/step - loss: 4035.1899 - mae: 44.6540 - val_loss: 2214.8191 - val_mae: 38.4079\n","Epoch 3/50\n","939/939 [==============================] - 53s 57ms/step - loss: 4011.5911 - mae: 44.4981 - val_loss: 2352.6870 - val_mae: 39.6174\n","Epoch 4/50\n","939/939 [==============================] - 55s 58ms/step - loss: 3992.6934 - mae: 44.3107 - val_loss: 2619.6802 - val_mae: 42.5904\n","Epoch 5/50\n","939/939 [==============================] - 54s 58ms/step - loss: 3961.2083 - mae: 44.0593 - val_loss: 2492.6062 - val_mae: 41.2115\n","Epoch 6/50\n","939/939 [==============================] - 54s 57ms/step - loss: 3955.5916 - mae: 43.8494 - val_loss: 2195.0303 - val_mae: 38.4963\n","Epoch 7/50\n","939/939 [==============================] - 52s 55ms/step - loss: 3934.5432 - mae: 43.7988 - val_loss: 2242.0461 - val_mae: 36.6201\n","Epoch 8/50\n","939/939 [==============================] - 50s 53ms/step - loss: 3919.3972 - mae: 43.5579 - val_loss: 2372.3171 - val_mae: 39.6765\n","Epoch 9/50\n","939/939 [==============================] - 52s 55ms/step - loss: 3909.9399 - mae: 43.5287 - val_loss: 2030.7496 - val_mae: 35.3380\n","Epoch 10/50\n","939/939 [==============================] - 51s 54ms/step - loss: 3890.0283 - mae: 43.2680 - val_loss: 2289.4858 - val_mae: 37.9035\n","Epoch 11/50\n","939/939 [==============================] - 48s 52ms/step - loss: 3889.8020 - mae: 43.3703 - val_loss: 2708.3228 - val_mae: 43.0915\n","Epoch 12/50\n","939/939 [==============================] - 50s 53ms/step - loss: 3881.3428 - mae: 43.3811 - val_loss: 2213.4048 - val_mae: 37.9201\n","Epoch 13/50\n","939/939 [==============================] - 49s 52ms/step - loss: 3871.1965 - mae: 43.3905 - val_loss: 2184.9595 - val_mae: 38.1553\n","Epoch 14/50\n","939/939 [==============================] - 48s 51ms/step - loss: 3857.0583 - mae: 43.2430 - val_loss: 2569.2063 - val_mae: 42.3770\n","Epoch 15/50\n","939/939 [==============================] - 50s 53ms/step - loss: 3847.8542 - mae: 43.1968 - val_loss: 2333.3962 - val_mae: 39.7579\n","Epoch 16/50\n","939/939 [==============================] - 50s 53ms/step - loss: 3856.5850 - mae: 43.0774 - val_loss: 2457.8123 - val_mae: 41.6236\n","Epoch 17/50\n","939/939 [==============================] - 49s 52ms/step - loss: 3856.5710 - mae: 43.2033 - val_loss: 2626.5378 - val_mae: 41.9668\n","Epoch 18/50\n","939/939 [==============================] - 49s 52ms/step - loss: 3830.1807 - mae: 43.1695 - val_loss: 2480.9397 - val_mae: 40.8920\n","Epoch 19/50\n","939/939 [==============================] - 48s 51ms/step - loss: 3836.1177 - mae: 43.0503 - val_loss: 3337.7756 - val_mae: 49.0240\n","Epoch 20/50\n","939/939 [==============================] - 53s 56ms/step - loss: 3844.3093 - mae: 43.4007 - val_loss: 2519.7595 - val_mae: 41.3986\n","Epoch 21/50\n","939/939 [==============================] - 49s 53ms/step - loss: 3814.7190 - mae: 43.0050 - val_loss: 2083.7993 - val_mae: 36.6116\n","Epoch 22/50\n","939/939 [==============================] - 50s 53ms/step - loss: 3829.5779 - mae: 42.9787 - val_loss: 2081.6208 - val_mae: 37.3623\n","Epoch 23/50\n","939/939 [==============================] - 53s 56ms/step - loss: 3815.6013 - mae: 43.0092 - val_loss: 2661.2280 - val_mae: 42.9604\n","Epoch 24/50\n","939/939 [==============================] - 53s 56ms/step - loss: 3807.8472 - mae: 42.9785 - val_loss: 2565.4871 - val_mae: 42.1459\n","Epoch 25/50\n","939/939 [==============================] - 51s 55ms/step - loss: 3813.1831 - mae: 42.9983 - val_loss: 2343.7827 - val_mae: 40.4344\n","Epoch 26/50\n","939/939 [==============================] - 50s 53ms/step - loss: 3812.3940 - mae: 42.8906 - val_loss: 2038.9950 - val_mae: 37.4373\n","Epoch 27/50\n","939/939 [==============================] - 51s 54ms/step - loss: 3804.8542 - mae: 42.8237 - val_loss: 2080.0815 - val_mae: 37.4111\n","Epoch 28/50\n","939/939 [==============================] - 54s 57ms/step - loss: 3795.8252 - mae: 42.8745 - val_loss: 2305.9456 - val_mae: 40.2984\n","Epoch 29/50\n","939/939 [==============================] - 52s 55ms/step - loss: 3798.6838 - mae: 42.8830 - val_loss: 2247.4265 - val_mae: 39.9265\n","Epoch 30/50\n","939/939 [==============================] - 52s 56ms/step - loss: 3790.0688 - mae: 42.8155 - val_loss: 2318.4705 - val_mae: 40.5398\n","Epoch 31/50\n","939/939 [==============================] - 50s 53ms/step - loss: 3791.3989 - mae: 42.8530 - val_loss: 2254.5615 - val_mae: 40.1661\n","Epoch 32/50\n","939/939 [==============================] - 51s 54ms/step - loss: 3783.6069 - mae: 42.8500 - val_loss: 2313.4106 - val_mae: 40.2582\n","Epoch 33/50\n","939/939 [==============================] - 55s 58ms/step - loss: 3786.5100 - mae: 42.8441 - val_loss: 2667.8535 - val_mae: 43.3803\n","Epoch 34/50\n","939/939 [==============================] - 55s 58ms/step - loss: 3770.7683 - mae: 42.7394 - val_loss: 2578.0679 - val_mae: 42.2396\n","Epoch 35/50\n","939/939 [==============================] - 51s 54ms/step - loss: 3788.8535 - mae: 43.0302 - val_loss: 2207.0593 - val_mae: 38.0082\n","Epoch 36/50\n","939/939 [==============================] - 52s 56ms/step - loss: 3774.6599 - mae: 42.7197 - val_loss: 2115.1765 - val_mae: 38.4880\n","Epoch 37/50\n","939/939 [==============================] - 55s 58ms/step - loss: 3775.3774 - mae: 42.8143 - val_loss: 2314.3975 - val_mae: 40.6992\n","Epoch 38/50\n","939/939 [==============================] - 57s 60ms/step - loss: 3781.7375 - mae: 42.8496 - val_loss: 2613.0029 - val_mae: 43.3294\n","Epoch 39/50\n","939/939 [==============================] - 59s 63ms/step - loss: 3765.4065 - mae: 42.8752 - val_loss: 2408.6404 - val_mae: 41.7747\n","Epoch 40/50\n","939/939 [==============================] - 53s 56ms/step - loss: 3773.9949 - mae: 42.6911 - val_loss: 2553.9810 - val_mae: 43.1091\n","Epoch 41/50\n","939/939 [==============================] - 49s 52ms/step - loss: 3768.6799 - mae: 42.7711 - val_loss: 2324.7454 - val_mae: 40.1592\n","Epoch 42/50\n","939/939 [==============================] - 52s 55ms/step - loss: 3769.7302 - mae: 42.7413 - val_loss: 2454.5527 - val_mae: 41.8473\n","Epoch 43/50\n","939/939 [==============================] - 53s 56ms/step - loss: 3767.0249 - mae: 42.7679 - val_loss: 2084.9966 - val_mae: 37.6372\n","Epoch 44/50\n","939/939 [==============================] - 50s 53ms/step - loss: 3758.8506 - mae: 42.6652 - val_loss: 2263.0774 - val_mae: 39.5140\n","Epoch 45/50\n","939/939 [==============================] - 52s 55ms/step - loss: 3748.9685 - mae: 42.7488 - val_loss: 2358.9287 - val_mae: 40.5611\n","Epoch 46/50\n","939/939 [==============================] - 52s 55ms/step - loss: 3746.6807 - mae: 42.7027 - val_loss: 2603.3098 - val_mae: 43.8455\n","Epoch 47/50\n","939/939 [==============================] - 54s 58ms/step - loss: 3756.9006 - mae: 42.7588 - val_loss: 2162.7341 - val_mae: 39.2152\n","Epoch 48/50\n","939/939 [==============================] - 53s 56ms/step - loss: 3755.5686 - mae: 42.7222 - val_loss: 2222.2646 - val_mae: 39.5548\n","Epoch 49/50\n","939/939 [==============================] - 53s 56ms/step - loss: 3745.6792 - mae: 42.5827 - val_loss: 2538.6035 - val_mae: 42.1066\n","Epoch 50/50\n","939/939 [==============================] - 55s 59ms/step - loss: 3746.6460 - mae: 42.6111 - val_loss: 2397.2720 - val_mae: 42.1035\n","47.517090276459086\n","0.8021594911716706\n","0.8953877863843901\n","\n","---------------------------------------------- domain num 5 is running----------------------------------\n","start training\n","Epoch 1/50\n","939/939 [==============================] - 53s 55ms/step - loss: 5039.1167 - mae: 45.1538 - val_loss: 2980.9663 - val_mae: 39.3041\n","Epoch 2/50\n","939/939 [==============================] - 53s 57ms/step - loss: 4057.6917 - mae: 43.7601 - val_loss: 3253.0730 - val_mae: 41.7901\n","Epoch 3/50\n","939/939 [==============================] - 51s 55ms/step - loss: 3996.5249 - mae: 43.1792 - val_loss: 3178.4255 - val_mae: 43.2113\n","Epoch 4/50\n","939/939 [==============================] - 50s 53ms/step - loss: 3982.1123 - mae: 42.9725 - val_loss: 3046.7368 - val_mae: 43.1622\n","Epoch 5/50\n","939/939 [==============================] - 49s 52ms/step - loss: 3966.2522 - mae: 42.6410 - val_loss: 3041.8164 - val_mae: 42.0721\n","Epoch 6/50\n","939/939 [==============================] - 51s 55ms/step - loss: 3958.8130 - mae: 42.5796 - val_loss: 2896.6299 - val_mae: 38.3073\n","Epoch 7/50\n","939/939 [==============================] - 51s 55ms/step - loss: 3947.4851 - mae: 42.5408 - val_loss: 3356.2612 - val_mae: 39.1857\n","Epoch 8/50\n","939/939 [==============================] - 53s 57ms/step - loss: 3932.6340 - mae: 42.3042 - val_loss: 3333.3169 - val_mae: 42.7832\n","Epoch 9/50\n","939/939 [==============================] - 52s 55ms/step - loss: 3949.8987 - mae: 42.4773 - val_loss: 3238.0425 - val_mae: 45.5399\n","Epoch 10/50\n","939/939 [==============================] - 52s 55ms/step - loss: 3924.8367 - mae: 42.1492 - val_loss: 3082.1177 - val_mae: 42.5249\n","Epoch 11/50\n","939/939 [==============================] - 52s 56ms/step - loss: 3928.0991 - mae: 42.3297 - val_loss: 2830.0874 - val_mae: 40.8625\n","Epoch 12/50\n","939/939 [==============================] - 51s 54ms/step - loss: 3911.9524 - mae: 42.2110 - val_loss: 3146.4678 - val_mae: 38.9670\n","Epoch 13/50\n","939/939 [==============================] - 51s 54ms/step - loss: 3920.7104 - mae: 42.2994 - val_loss: 2724.0193 - val_mae: 39.8872\n","Epoch 14/50\n","939/939 [==============================] - 49s 52ms/step - loss: 3920.8770 - mae: 42.1971 - val_loss: 2888.9902 - val_mae: 42.0277\n","Epoch 15/50\n","939/939 [==============================] - 49s 53ms/step - loss: 3908.6064 - mae: 42.2178 - val_loss: 3231.1694 - val_mae: 40.6227\n","Epoch 16/50\n","939/939 [==============================] - 49s 53ms/step - loss: 3920.8994 - mae: 42.3028 - val_loss: 3151.0903 - val_mae: 43.4607\n","Epoch 17/50\n","939/939 [==============================] - 48s 51ms/step - loss: 3893.2961 - mae: 42.1808 - val_loss: 2965.0557 - val_mae: 40.8800\n","Epoch 18/50\n","939/939 [==============================] - 48s 51ms/step - loss: 3892.3762 - mae: 42.2340 - val_loss: 3153.8132 - val_mae: 43.1599\n","Epoch 19/50\n","939/939 [==============================] - 52s 55ms/step - loss: 3902.1943 - mae: 42.2935 - val_loss: 2941.4580 - val_mae: 40.8452\n","Epoch 20/50\n","939/939 [==============================] - 51s 54ms/step - loss: 3909.7351 - mae: 42.3852 - val_loss: 2881.4946 - val_mae: 41.8597\n","Epoch 21/50\n","939/939 [==============================] - 51s 54ms/step - loss: 3877.9851 - mae: 42.0764 - val_loss: 2887.8999 - val_mae: 41.5042\n","Epoch 22/50\n","939/939 [==============================] - 55s 58ms/step - loss: 3874.6323 - mae: 42.1582 - val_loss: 3115.0259 - val_mae: 43.4229\n","Epoch 23/50\n","939/939 [==============================] - 53s 57ms/step - loss: 3858.1777 - mae: 41.9707 - val_loss: 3203.4949 - val_mae: 42.7288\n","Epoch 24/50\n","939/939 [==============================] - 48s 51ms/step - loss: 3851.3906 - mae: 41.9354 - val_loss: 3230.0837 - val_mae: 44.8566\n","Epoch 25/50\n","939/939 [==============================] - 53s 57ms/step - loss: 3840.0654 - mae: 41.9059 - val_loss: 3138.9761 - val_mae: 41.4322\n","Epoch 26/50\n","939/939 [==============================] - 48s 51ms/step - loss: 3839.4475 - mae: 41.8599 - val_loss: 3011.9033 - val_mae: 42.8894\n","Epoch 27/50\n","939/939 [==============================] - 51s 55ms/step - loss: 3829.7778 - mae: 41.7690 - val_loss: 3152.6677 - val_mae: 43.6971\n","Epoch 28/50\n","939/939 [==============================] - 48s 52ms/step - loss: 3813.6965 - mae: 41.7932 - val_loss: 2893.9910 - val_mae: 40.0122\n","Epoch 29/50\n","939/939 [==============================] - 49s 52ms/step - loss: 3816.3179 - mae: 41.8251 - val_loss: 3019.5427 - val_mae: 41.2955\n","Epoch 30/50\n","939/939 [==============================] - 51s 54ms/step - loss: 3803.0205 - mae: 41.7182 - val_loss: 3093.1577 - val_mae: 40.8675\n","Epoch 31/50\n","939/939 [==============================] - 49s 52ms/step - loss: 3800.2449 - mae: 41.6036 - val_loss: 3010.1191 - val_mae: 42.4831\n","Epoch 32/50\n","939/939 [==============================] - 50s 53ms/step - loss: 3786.4692 - mae: 41.5018 - val_loss: 3088.7073 - val_mae: 40.7774\n","Epoch 33/50\n","939/939 [==============================] - 53s 56ms/step - loss: 3803.6899 - mae: 41.6846 - val_loss: 2969.6274 - val_mae: 40.3953\n","Epoch 34/50\n","939/939 [==============================] - 49s 52ms/step - loss: 3791.9526 - mae: 41.5277 - val_loss: 2996.8787 - val_mae: 41.7169\n","Epoch 35/50\n","939/939 [==============================] - 49s 53ms/step - loss: 3802.3613 - mae: 41.5922 - val_loss: 2867.1912 - val_mae: 42.6674\n","Epoch 36/50\n","939/939 [==============================] - 52s 56ms/step - loss: 3775.7646 - mae: 41.4044 - val_loss: 2787.8181 - val_mae: 40.4350\n","Epoch 37/50\n","939/939 [==============================] - 53s 56ms/step - loss: 3785.9927 - mae: 41.5069 - val_loss: 2943.1709 - val_mae: 42.9538\n","Epoch 38/50\n","939/939 [==============================] - 53s 57ms/step - loss: 3774.0571 - mae: 41.4670 - val_loss: 2744.2207 - val_mae: 41.4706\n","Epoch 39/50\n","939/939 [==============================] - 53s 57ms/step - loss: 3769.0715 - mae: 41.3989 - val_loss: 3041.2666 - val_mae: 42.2862\n","Epoch 40/50\n","939/939 [==============================] - 51s 55ms/step - loss: 3765.7764 - mae: 41.3631 - val_loss: 3038.1865 - val_mae: 43.7281\n","Epoch 41/50\n","939/939 [==============================] - 54s 57ms/step - loss: 3765.6016 - mae: 41.4579 - val_loss: 3037.2200 - val_mae: 42.3649\n","Epoch 42/50\n","939/939 [==============================] - 50s 54ms/step - loss: 3755.9023 - mae: 41.3075 - val_loss: 2905.4543 - val_mae: 42.2345\n","Epoch 43/50\n","939/939 [==============================] - 52s 56ms/step - loss: 3770.3577 - mae: 41.5429 - val_loss: 2724.3110 - val_mae: 42.7805\n","Epoch 44/50\n","939/939 [==============================] - 54s 57ms/step - loss: 3762.5305 - mae: 41.5085 - val_loss: 2833.5718 - val_mae: 41.1470\n","Epoch 45/50\n","939/939 [==============================] - 50s 53ms/step - loss: 3755.0188 - mae: 41.4172 - val_loss: 3002.5518 - val_mae: 42.2959\n","Epoch 46/50\n","939/939 [==============================] - 50s 53ms/step - loss: 3750.6050 - mae: 41.4644 - val_loss: 3029.9260 - val_mae: 42.5658\n","Epoch 47/50\n","939/939 [==============================] - 50s 53ms/step - loss: 3747.7517 - mae: 41.3390 - val_loss: 2882.2305 - val_mae: 42.6025\n","Epoch 48/50\n","939/939 [==============================] - 48s 51ms/step - loss: 3734.0833 - mae: 41.1800 - val_loss: 3345.0029 - val_mae: 45.8369\n","Epoch 49/50\n","939/939 [==============================] - 54s 57ms/step - loss: 3737.7764 - mae: 41.3633 - val_loss: 2949.7744 - val_mae: 42.7093\n","Epoch 50/50\n","939/939 [==============================] - 56s 59ms/step - loss: 3746.9700 - mae: 41.3965 - val_loss: 3004.9392 - val_mae: 43.4825\n","39.32282229285742\n","1.0834155082228192\n","1.07430625407197\n"]}]},{"cell_type":"code","source":["######################################washingmachine###############################################################\n","# #trainfile4=\"/content/drive/MyDrive/training_data/dishwasher_test_.csv\"\n","# # trainfile1=\"/content/drive/MyDrive/training_data/washingmachine_house_2_training_.csv\"\n","# trainfile1=\"/content/drive/MyDrive/training_data/washingmachine_test_.csv\"\n","\n","# trainfile2=\"/content/drive/MyDrive/ukdale_training/washingmachine_house_1_training_.csv\"\n","# # trainfile3=\"/content/drive/MyDrive/ukdale_training/fridge_house_2_training_.csv\"\n","# trainfile3=\"/content/drive/MyDrive/refit_training/washingmachine/washingmachine_house_9_training_.csv\"\n","# trainfile4=\"/content/drive/MyDrive/refit_training/washingmachine/washingmachine_house_16_training_.csv\"\n","\n","# fileList=[trainfile1,trainfile2,trainfile3,trainfile4]\n","# stepsizeList=[2,16,16,16]\n","trainfile1=\"/content/drive/MyDrive/training_data/washingmachine_test_.csv\"\n","trainfile2=\"/content/drive/MyDrive/training_data/washingmachine_house_2_training_.csv\"\n","trainfile3=\"/content/drive/MyDrive/ukdale_training/washingmachine_house_1_training_.csv\"\n","trainfile4=\"/content/drive/MyDrive/ukdale_training/washingmachine_house_2_training_.csv\"\n","trainfile5=\"/content/drive/MyDrive/refit_training/washingmachine/washingmachine_house_9_training_.csv\"\n","trainfile6=\"/content/drive/MyDrive/refit_training/washingmachine/washingmachine_house_16_training_.csv\"\n","fileList=[trainfile1,trainfile2,trainfile3,trainfile4,trainfile5,trainfile6]\n","stepsizeList=[2,2,16,16,16,16]\n","data_insts, data_labels, num_insts,on = [], [], [],[]\n","threshold=20\n","for i in range(len(fileList)):\n","    X,Y=dataProvider(fileList[i], 19, stepsizeList[i], threshold)\n","    Y=Y.reshape(-1,1)\n","    data_insts.append(X)\n","    data_labels.append(Y)\n","    num_insts.append(X.shape[0])\n","min_size=min(num_insts)\n","x_tem, y_tem=[],[]\n","for j in range(len(fileList)):\n","  ridx = np.random.choice(num_insts[j], min_size)\n","  x_tem.append(data_insts[j][ridx, :])\n","  y_tem.append(data_labels[j][ridx, :])\n","  num_insts[j]=x_tem[j].shape[0]\n","data_insts=x_tem\n","data_labels=y_tem \n","print(num_insts)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VJe8abL_Sujd","executionInfo":{"status":"ok","timestamp":1660469806714,"user_tz":-600,"elapsed":16623,"user":{"displayName":"XIAOMIN CHANG","userId":"17429039977919006081"}},"outputId":"91672cda-22b6-4249-c2aa-d389e537a57f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[15017, 15017, 15017, 15017, 15017, 15017]\n"]}]},{"cell_type":"code","source":["for i in [0,2,5]:\n","        print('\\n---------------------------------------------- domain num %i is running----------------------------------'%(i))\n","        # Build source instances.\n","        source_insts = []\n","        source_labels = []\n","        for j in range(len(fileList)):\n","            if j != i:\n","                source_insts.append(data_insts[j])\n","                source_labels.append(data_labels[j])\n","        # Build target instances.\n","        target_idx = i\n","        target_insts = data_insts[i]\n","        target_labels = data_labels[i]\n","        target_insts0, X_t, target_labels0, y_t =train_test_split(target_insts, target_labels, test_size=0.2,random_state=100)\n","        \n","        X=np.concatenate(source_insts, axis=0)\n","        Y=np.concatenate(source_labels, axis=0)\n","        \n","        x_train_all, x_test, y_train_all, y_test =train_test_split(X, Y, test_size=0.2,random_state=100)\n","        model=CNN_training_best(X,Y)\n","        prediction=model.predict(X_t)\n","        stopT=get_mae(y_t, prediction)\n","        print(stopT)\n","        print(get_sae(y_t, prediction))\n","        print(get_nde(y_t, prediction))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hDPbz0HuSu09","executionInfo":{"status":"ok","timestamp":1660477680083,"user_tz":-600,"elapsed":7872368,"user":{"displayName":"XIAOMIN CHANG","userId":"17429039977919006081"}},"outputId":"88290300-72a6-4e6f-e8f9-55f480f01821"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","---------------------------------------------- domain num 0 is running----------------------------------\n","start training\n","Epoch 1/50\n","939/939 [==============================] - 48s 49ms/step - loss: 20229.8105 - mae: 26.0237 - val_loss: 30870.8027 - val_mae: 28.8795\n","Epoch 2/50\n","939/939 [==============================] - 47s 50ms/step - loss: 19435.1602 - mae: 24.4780 - val_loss: 29279.5977 - val_mae: 39.1957\n","Epoch 3/50\n","939/939 [==============================] - 46s 49ms/step - loss: 19111.0527 - mae: 23.5206 - val_loss: 28688.9707 - val_mae: 38.6389\n","Epoch 4/50\n","939/939 [==============================] - 47s 50ms/step - loss: 19090.6816 - mae: 23.6940 - val_loss: 29183.6582 - val_mae: 30.5932\n","Epoch 5/50\n","939/939 [==============================] - 45s 48ms/step - loss: 19213.7637 - mae: 24.1038 - val_loss: 28560.5879 - val_mae: 34.7031\n","Epoch 6/50\n","939/939 [==============================] - 47s 50ms/step - loss: 19160.4023 - mae: 24.7287 - val_loss: 29185.8535 - val_mae: 31.4334\n","Epoch 7/50\n","939/939 [==============================] - 46s 49ms/step - loss: 19034.2090 - mae: 24.5116 - val_loss: 28548.8203 - val_mae: 32.1857\n","Epoch 8/50\n","939/939 [==============================] - 45s 48ms/step - loss: 19041.0625 - mae: 24.9731 - val_loss: 28712.1621 - val_mae: 30.4345\n","Epoch 9/50\n","939/939 [==============================] - 47s 50ms/step - loss: 19034.4238 - mae: 24.5426 - val_loss: 28756.7148 - val_mae: 35.4287\n","Epoch 10/50\n","939/939 [==============================] - 46s 49ms/step - loss: 18844.4199 - mae: 24.5609 - val_loss: 28204.4023 - val_mae: 37.2067\n","Epoch 11/50\n","939/939 [==============================] - 47s 50ms/step - loss: 18978.3672 - mae: 25.2245 - val_loss: 28392.8809 - val_mae: 44.9184\n","Epoch 12/50\n","939/939 [==============================] - 45s 48ms/step - loss: 18826.3418 - mae: 24.8693 - val_loss: 28079.7168 - val_mae: 35.8639\n","Epoch 13/50\n","939/939 [==============================] - 48s 51ms/step - loss: 18877.4434 - mae: 24.9883 - val_loss: 28384.8789 - val_mae: 44.0327\n","Epoch 14/50\n","939/939 [==============================] - 45s 47ms/step - loss: 18696.0918 - mae: 25.4379 - val_loss: 29148.1406 - val_mae: 29.1875\n","Epoch 15/50\n","939/939 [==============================] - 45s 48ms/step - loss: 18864.1094 - mae: 24.9616 - val_loss: 28409.8848 - val_mae: 38.9705\n","Epoch 16/50\n","939/939 [==============================] - 43s 46ms/step - loss: 18659.7266 - mae: 25.4780 - val_loss: 28582.0781 - val_mae: 48.0505\n","Epoch 17/50\n","939/939 [==============================] - 45s 48ms/step - loss: 18763.4141 - mae: 25.5850 - val_loss: 28247.3418 - val_mae: 38.4589\n","Epoch 18/50\n","939/939 [==============================] - 43s 46ms/step - loss: 18722.4551 - mae: 25.6115 - val_loss: 28453.8086 - val_mae: 37.9820\n","Epoch 19/50\n","939/939 [==============================] - 45s 48ms/step - loss: 18772.8203 - mae: 25.3942 - val_loss: 28544.1152 - val_mae: 36.2410\n","Epoch 20/50\n","939/939 [==============================] - 43s 46ms/step - loss: 18636.7148 - mae: 25.4314 - val_loss: 28168.2246 - val_mae: 37.9137\n","Epoch 21/50\n","939/939 [==============================] - 45s 48ms/step - loss: 18606.4004 - mae: 25.9408 - val_loss: 28498.7012 - val_mae: 33.9072\n","Epoch 22/50\n","939/939 [==============================] - 43s 46ms/step - loss: 18576.2598 - mae: 25.6801 - val_loss: 28612.6816 - val_mae: 35.9489\n","Epoch 23/50\n","939/939 [==============================] - 43s 46ms/step - loss: 18395.9980 - mae: 25.6573 - val_loss: 28328.5918 - val_mae: 39.8843\n","Epoch 24/50\n","939/939 [==============================] - 45s 48ms/step - loss: 18536.5957 - mae: 25.6892 - val_loss: 28492.8105 - val_mae: 39.5488\n","Epoch 25/50\n","939/939 [==============================] - 43s 46ms/step - loss: 18459.4883 - mae: 25.8208 - val_loss: 28435.9648 - val_mae: 42.1783\n","Epoch 26/50\n","939/939 [==============================] - 44s 47ms/step - loss: 18569.3477 - mae: 25.9023 - val_loss: 28412.7930 - val_mae: 39.4249\n","Epoch 27/50\n","939/939 [==============================] - 42s 45ms/step - loss: 18453.3965 - mae: 25.4729 - val_loss: 28134.1699 - val_mae: 37.9660\n","Epoch 28/50\n","939/939 [==============================] - 44s 47ms/step - loss: 18491.5332 - mae: 26.0863 - val_loss: 28204.5137 - val_mae: 35.4465\n","Epoch 29/50\n","939/939 [==============================] - 43s 46ms/step - loss: 18403.0508 - mae: 25.4802 - val_loss: 28617.2285 - val_mae: 36.9636\n","Epoch 30/50\n","939/939 [==============================] - 44s 47ms/step - loss: 18479.9492 - mae: 25.7073 - val_loss: 28170.4609 - val_mae: 38.5894\n","Epoch 31/50\n","939/939 [==============================] - 42s 45ms/step - loss: 18432.7891 - mae: 25.9664 - val_loss: 27965.9844 - val_mae: 36.4533\n","Epoch 32/50\n","939/939 [==============================] - 44s 47ms/step - loss: 18466.0996 - mae: 25.2140 - val_loss: 28102.2031 - val_mae: 36.9345\n","Epoch 33/50\n","939/939 [==============================] - 44s 47ms/step - loss: 18464.0371 - mae: 26.0749 - val_loss: 28309.3047 - val_mae: 41.1702\n","Epoch 34/50\n","939/939 [==============================] - 43s 46ms/step - loss: 18288.1133 - mae: 25.7242 - val_loss: 28238.1895 - val_mae: 41.7121\n","Epoch 35/50\n","939/939 [==============================] - 45s 47ms/step - loss: 18290.3730 - mae: 25.9103 - val_loss: 28550.8398 - val_mae: 30.5306\n","Epoch 36/50\n","939/939 [==============================] - 43s 46ms/step - loss: 18444.9434 - mae: 25.5462 - val_loss: 27986.5020 - val_mae: 34.8911\n","Epoch 37/50\n","939/939 [==============================] - 45s 48ms/step - loss: 18419.3867 - mae: 26.2626 - val_loss: 28586.9531 - val_mae: 43.6420\n","Epoch 38/50\n","939/939 [==============================] - 43s 45ms/step - loss: 18217.2773 - mae: 25.5776 - val_loss: 28034.9629 - val_mae: 36.1120\n","Epoch 39/50\n","939/939 [==============================] - 44s 47ms/step - loss: 18239.5508 - mae: 25.6852 - val_loss: 28047.9180 - val_mae: 41.3102\n","Epoch 40/50\n","939/939 [==============================] - 43s 45ms/step - loss: 18253.6289 - mae: 25.9406 - val_loss: 28166.1504 - val_mae: 40.4767\n","Epoch 41/50\n","939/939 [==============================] - 44s 47ms/step - loss: 18248.7871 - mae: 26.0169 - val_loss: 28046.1406 - val_mae: 34.3279\n","Epoch 42/50\n","939/939 [==============================] - 42s 45ms/step - loss: 18231.0566 - mae: 25.5069 - val_loss: 28011.3809 - val_mae: 37.2336\n","Epoch 43/50\n","939/939 [==============================] - 43s 46ms/step - loss: 18292.7246 - mae: 25.9117 - val_loss: 28255.4590 - val_mae: 43.7727\n","Epoch 44/50\n","939/939 [==============================] - 44s 47ms/step - loss: 18147.5156 - mae: 25.7480 - val_loss: 27929.0391 - val_mae: 37.1647\n","Epoch 45/50\n","939/939 [==============================] - 42s 45ms/step - loss: 18052.7480 - mae: 25.8283 - val_loss: 28121.7363 - val_mae: 32.8993\n","Epoch 46/50\n","939/939 [==============================] - 44s 47ms/step - loss: 18182.9766 - mae: 26.1862 - val_loss: 28311.3809 - val_mae: 41.9357\n","Epoch 47/50\n","939/939 [==============================] - 42s 45ms/step - loss: 18194.4727 - mae: 26.0493 - val_loss: 28065.7500 - val_mae: 39.3110\n","Epoch 48/50\n","939/939 [==============================] - 44s 47ms/step - loss: 18120.5703 - mae: 26.8115 - val_loss: 28399.9785 - val_mae: 35.4145\n","Epoch 49/50\n","939/939 [==============================] - 42s 45ms/step - loss: 18190.9961 - mae: 26.0444 - val_loss: 28423.8750 - val_mae: 32.6917\n","Epoch 50/50\n","939/939 [==============================] - 44s 47ms/step - loss: 18244.0508 - mae: 26.5931 - val_loss: 27894.9492 - val_mae: 35.3464\n","34.646816440349916\n","0.858242421785111\n","0.9562664958694006\n","\n","---------------------------------------------- domain num 2 is running----------------------------------\n","start training\n","Epoch 1/50\n","939/939 [==============================] - 57s 60ms/step - loss: 29875.0293 - mae: 29.8678 - val_loss: 29864.3906 - val_mae: 30.1771\n","Epoch 2/50\n","939/939 [==============================] - 53s 57ms/step - loss: 26820.4727 - mae: 25.9814 - val_loss: 30180.6660 - val_mae: 42.1919\n","Epoch 3/50\n","939/939 [==============================] - 53s 57ms/step - loss: 25512.9785 - mae: 26.2452 - val_loss: 30740.6562 - val_mae: 40.0807\n","Epoch 4/50\n","939/939 [==============================] - 51s 55ms/step - loss: 23465.6523 - mae: 25.9163 - val_loss: 34981.7695 - val_mae: 55.5363\n","Epoch 5/50\n","939/939 [==============================] - 52s 56ms/step - loss: 23059.6816 - mae: 26.0900 - val_loss: 31586.2305 - val_mae: 25.5285\n","Epoch 6/50\n","939/939 [==============================] - 52s 55ms/step - loss: 22444.7070 - mae: 28.1584 - val_loss: 30163.6328 - val_mae: 35.8340\n","Epoch 7/50\n","939/939 [==============================] - 52s 56ms/step - loss: 21516.8613 - mae: 27.5528 - val_loss: 33690.2305 - val_mae: 52.2154\n","Epoch 8/50\n","939/939 [==============================] - 50s 54ms/step - loss: 21707.8672 - mae: 28.4834 - val_loss: 31160.0938 - val_mae: 40.1949\n","Epoch 9/50\n","939/939 [==============================] - 52s 56ms/step - loss: 19737.6719 - mae: 27.4949 - val_loss: 31528.9688 - val_mae: 50.5664\n","Epoch 10/50\n","939/939 [==============================] - 51s 54ms/step - loss: 20439.1660 - mae: 28.0089 - val_loss: 37743.2930 - val_mae: 48.8371\n","Epoch 11/50\n","939/939 [==============================] - 52s 55ms/step - loss: 19803.5352 - mae: 28.2147 - val_loss: 31787.3066 - val_mae: 34.6268\n","Epoch 12/50\n","939/939 [==============================] - 50s 53ms/step - loss: 19659.5977 - mae: 28.2620 - val_loss: 30963.3535 - val_mae: 30.6542\n","Epoch 13/50\n","939/939 [==============================] - 52s 55ms/step - loss: 19004.6777 - mae: 28.3661 - val_loss: 31914.9570 - val_mae: 32.8210\n","Epoch 14/50\n","939/939 [==============================] - 52s 55ms/step - loss: 18511.8730 - mae: 28.1322 - val_loss: 31763.9453 - val_mae: 33.2323\n","Epoch 15/50\n","939/939 [==============================] - 51s 54ms/step - loss: 17943.5117 - mae: 28.4733 - val_loss: 32402.2910 - val_mae: 39.2219\n","Epoch 16/50\n","939/939 [==============================] - 53s 56ms/step - loss: 18884.1270 - mae: 28.2160 - val_loss: 38695.8711 - val_mae: 56.6474\n","Epoch 17/50\n","939/939 [==============================] - 53s 56ms/step - loss: 19643.4297 - mae: 29.0930 - val_loss: 33704.2461 - val_mae: 52.4614\n","Epoch 18/50\n","939/939 [==============================] - 55s 59ms/step - loss: 18065.2676 - mae: 29.0409 - val_loss: 31100.6582 - val_mae: 33.4644\n","Epoch 19/50\n","939/939 [==============================] - 53s 57ms/step - loss: 18583.2754 - mae: 28.1941 - val_loss: 31331.0000 - val_mae: 31.2184\n","Epoch 20/50\n","939/939 [==============================] - 56s 60ms/step - loss: 17575.3184 - mae: 27.7056 - val_loss: 32264.5156 - val_mae: 35.2194\n","Epoch 21/50\n","939/939 [==============================] - 55s 59ms/step - loss: 17443.4922 - mae: 27.9387 - val_loss: 30820.1973 - val_mae: 46.3573\n","Epoch 22/50\n","939/939 [==============================] - 56s 60ms/step - loss: 17979.7617 - mae: 28.2081 - val_loss: 33669.6992 - val_mae: 32.6116\n","Epoch 23/50\n","939/939 [==============================] - 57s 60ms/step - loss: 17815.2383 - mae: 27.9115 - val_loss: 30731.6621 - val_mae: 33.8138\n","Epoch 24/50\n","939/939 [==============================] - 55s 59ms/step - loss: 17088.5059 - mae: 28.1713 - val_loss: 32095.5156 - val_mae: 27.3302\n","Epoch 25/50\n","939/939 [==============================] - 57s 61ms/step - loss: 17333.8730 - mae: 27.7221 - val_loss: 34403.9648 - val_mae: 34.1042\n","Epoch 26/50\n","939/939 [==============================] - 55s 59ms/step - loss: 17779.7422 - mae: 28.0661 - val_loss: 31796.8242 - val_mae: 25.0240\n","Epoch 27/50\n","939/939 [==============================] - 57s 61ms/step - loss: 16508.2109 - mae: 27.7125 - val_loss: 31504.9473 - val_mae: 26.7099\n","Epoch 28/50\n","939/939 [==============================] - 58s 62ms/step - loss: 16853.5527 - mae: 27.9921 - val_loss: 31464.7188 - val_mae: 42.4465\n","Epoch 29/50\n","939/939 [==============================] - 57s 60ms/step - loss: 17384.4102 - mae: 27.9614 - val_loss: 31358.0664 - val_mae: 38.3625\n","Epoch 30/50\n","939/939 [==============================] - 58s 62ms/step - loss: 16187.9189 - mae: 27.6838 - val_loss: 30479.6797 - val_mae: 29.8850\n","Epoch 31/50\n","939/939 [==============================] - 56s 60ms/step - loss: 16476.2988 - mae: 28.3358 - val_loss: 32090.6328 - val_mae: 32.7952\n","Epoch 32/50\n","939/939 [==============================] - 58s 61ms/step - loss: 16499.5410 - mae: 28.0367 - val_loss: 31188.4902 - val_mae: 28.0382\n","Epoch 33/50\n","939/939 [==============================] - 57s 61ms/step - loss: 16338.0195 - mae: 27.6534 - val_loss: 30788.3086 - val_mae: 35.6462\n","Epoch 34/50\n","939/939 [==============================] - 56s 59ms/step - loss: 15760.4062 - mae: 27.4506 - val_loss: 33075.8008 - val_mae: 32.1236\n","Epoch 35/50\n","939/939 [==============================] - 57s 60ms/step - loss: 15488.1367 - mae: 27.6089 - val_loss: 34423.1250 - val_mae: 55.6256\n","Epoch 36/50\n","939/939 [==============================] - 56s 60ms/step - loss: 15590.8623 - mae: 27.8235 - val_loss: 31391.1191 - val_mae: 53.8393\n","Epoch 37/50\n","939/939 [==============================] - 57s 61ms/step - loss: 15174.3154 - mae: 27.7294 - val_loss: 35315.2266 - val_mae: 62.9658\n","Epoch 38/50\n","939/939 [==============================] - 58s 62ms/step - loss: 15653.2285 - mae: 27.9226 - val_loss: 30330.6602 - val_mae: 36.9921\n","Epoch 39/50\n","939/939 [==============================] - 56s 59ms/step - loss: 15881.9639 - mae: 28.2936 - val_loss: 32114.6562 - val_mae: 35.1291\n","Epoch 40/50\n","939/939 [==============================] - 57s 61ms/step - loss: 14952.0420 - mae: 27.6441 - val_loss: 31016.2539 - val_mae: 46.2419\n","Epoch 41/50\n","939/939 [==============================] - 55s 59ms/step - loss: 15179.9062 - mae: 27.6960 - val_loss: 31963.8477 - val_mae: 24.8178\n","Epoch 42/50\n","939/939 [==============================] - 56s 60ms/step - loss: 15368.0771 - mae: 27.4371 - val_loss: 31290.1426 - val_mae: 31.5517\n","Epoch 43/50\n","939/939 [==============================] - 56s 60ms/step - loss: 15103.3135 - mae: 28.0511 - val_loss: 30128.4980 - val_mae: 36.9372\n","Epoch 44/50\n","939/939 [==============================] - 55s 58ms/step - loss: 14628.5400 - mae: 27.4022 - val_loss: 30984.7305 - val_mae: 32.6177\n","Epoch 45/50\n","939/939 [==============================] - 57s 61ms/step - loss: 14557.6611 - mae: 27.6367 - val_loss: 29579.3008 - val_mae: 34.1492\n","Epoch 46/50\n","939/939 [==============================] - 54s 58ms/step - loss: 14310.0928 - mae: 27.6910 - val_loss: 30504.0293 - val_mae: 30.5158\n","Epoch 47/50\n","939/939 [==============================] - 55s 59ms/step - loss: 15474.1914 - mae: 28.0616 - val_loss: 31239.2246 - val_mae: 31.3331\n","Epoch 48/50\n","939/939 [==============================] - 54s 58ms/step - loss: 15004.2676 - mae: 27.9703 - val_loss: 33458.3438 - val_mae: 44.0699\n","Epoch 49/50\n","939/939 [==============================] - 52s 56ms/step - loss: 14834.0703 - mae: 27.6700 - val_loss: 30743.1367 - val_mae: 37.2500\n","Epoch 50/50\n","939/939 [==============================] - 52s 55ms/step - loss: 14309.7783 - mae: 27.4017 - val_loss: 31446.1953 - val_mae: 48.4169\n","56.96012986309519\n","1.8196524295348435\n","0.9614018606209241\n","\n","---------------------------------------------- domain num 5 is running----------------------------------\n","start training\n","Epoch 1/50\n","939/939 [==============================] - 55s 57ms/step - loss: 33322.5938 - mae: 32.2660 - val_loss: 26944.2734 - val_mae: 42.6891\n","Epoch 2/50\n","939/939 [==============================] - 54s 58ms/step - loss: 28310.4512 - mae: 28.7483 - val_loss: 40398.4141 - val_mae: 64.1584\n","Epoch 3/50\n","939/939 [==============================] - 56s 60ms/step - loss: 25737.4121 - mae: 28.7559 - val_loss: 52449.9727 - val_mae: 58.8667\n","Epoch 4/50\n","939/939 [==============================] - 54s 58ms/step - loss: 22961.4375 - mae: 29.4324 - val_loss: 56287.7031 - val_mae: 58.6391\n","Epoch 5/50\n","939/939 [==============================] - 57s 61ms/step - loss: 21902.1797 - mae: 31.2377 - val_loss: 79509.1406 - val_mae: 62.6250\n","Epoch 6/50\n","939/939 [==============================] - 56s 60ms/step - loss: 20126.1465 - mae: 30.8798 - val_loss: 118305.4375 - val_mae: 73.5492\n","Epoch 7/50\n","939/939 [==============================] - 59s 62ms/step - loss: 18838.4492 - mae: 30.4589 - val_loss: 273044.9062 - val_mae: 101.7801\n","Epoch 8/50\n","939/939 [==============================] - 57s 61ms/step - loss: 17885.6777 - mae: 31.1566 - val_loss: 361243.3125 - val_mae: 114.1283\n","Epoch 9/50\n","939/939 [==============================] - 57s 60ms/step - loss: 18176.7637 - mae: 31.3463 - val_loss: 305740.7188 - val_mae: 102.8076\n","Epoch 10/50\n","939/939 [==============================] - 58s 61ms/step - loss: 16767.4570 - mae: 30.9139 - val_loss: 189458.8594 - val_mae: 76.4023\n","Epoch 11/50\n","939/939 [==============================] - 56s 60ms/step - loss: 16912.8652 - mae: 30.8276 - val_loss: 221573.4531 - val_mae: 87.5111\n","Epoch 12/50\n","939/939 [==============================] - 57s 61ms/step - loss: 15611.7393 - mae: 30.0830 - val_loss: 77613.5938 - val_mae: 57.2728\n","Epoch 13/50\n","939/939 [==============================] - 56s 60ms/step - loss: 16039.7559 - mae: 31.0399 - val_loss: 166074.5469 - val_mae: 70.8949\n","Epoch 14/50\n","939/939 [==============================] - 57s 61ms/step - loss: 15104.3242 - mae: 30.0592 - val_loss: 151565.0469 - val_mae: 70.7451\n","Epoch 15/50\n","939/939 [==============================] - 57s 61ms/step - loss: 15117.9512 - mae: 30.4672 - val_loss: 200345.1406 - val_mae: 71.4165\n","Epoch 16/50\n","939/939 [==============================] - 56s 60ms/step - loss: 15342.9443 - mae: 31.3866 - val_loss: 218220.8438 - val_mae: 87.5049\n","Epoch 17/50\n","939/939 [==============================] - 58s 62ms/step - loss: 15792.2715 - mae: 31.0738 - val_loss: 500816.9688 - val_mae: 144.7025\n","Epoch 18/50\n","939/939 [==============================] - 55s 59ms/step - loss: 16125.4141 - mae: 31.3637 - val_loss: 232511.1250 - val_mae: 71.7113\n","Epoch 19/50\n","939/939 [==============================] - 57s 61ms/step - loss: 14582.9199 - mae: 30.4395 - val_loss: 186997.1250 - val_mae: 75.7696\n","Epoch 20/50\n","939/939 [==============================] - 58s 61ms/step - loss: 15253.3154 - mae: 31.2005 - val_loss: 160220.0000 - val_mae: 58.0503\n","Epoch 21/50\n","939/939 [==============================] - 56s 59ms/step - loss: 14913.3809 - mae: 30.2757 - val_loss: 174698.9375 - val_mae: 71.3310\n","Epoch 22/50\n","939/939 [==============================] - 58s 62ms/step - loss: 14641.5352 - mae: 30.0511 - val_loss: 309275.8438 - val_mae: 91.9289\n","Epoch 23/50\n","939/939 [==============================] - 56s 59ms/step - loss: 14299.0488 - mae: 30.7692 - val_loss: 314786.0625 - val_mae: 77.2270\n","Epoch 24/50\n","939/939 [==============================] - 58s 61ms/step - loss: 14045.8789 - mae: 29.8664 - val_loss: 203797.9375 - val_mae: 79.8346\n","Epoch 25/50\n","939/939 [==============================] - 57s 61ms/step - loss: 14291.5732 - mae: 30.5933 - val_loss: 189055.6406 - val_mae: 92.8317\n","Epoch 26/50\n","939/939 [==============================] - 58s 62ms/step - loss: 13779.7559 - mae: 30.5180 - val_loss: 239144.5156 - val_mae: 102.0598\n","Epoch 27/50\n","939/939 [==============================] - 58s 61ms/step - loss: 14309.4160 - mae: 30.4627 - val_loss: 181590.5156 - val_mae: 112.3140\n","Epoch 28/50\n","939/939 [==============================] - 56s 60ms/step - loss: 14445.2607 - mae: 30.5851 - val_loss: 103978.6250 - val_mae: 72.3661\n","Epoch 29/50\n","939/939 [==============================] - 58s 62ms/step - loss: 14347.4990 - mae: 30.1290 - val_loss: 215885.7031 - val_mae: 85.0260\n","Epoch 30/50\n","939/939 [==============================] - 56s 60ms/step - loss: 13610.8477 - mae: 30.2404 - val_loss: 181217.9219 - val_mae: 88.4740\n","Epoch 31/50\n","939/939 [==============================] - 57s 61ms/step - loss: 13695.4141 - mae: 29.3054 - val_loss: 159320.8125 - val_mae: 75.4252\n","Epoch 32/50\n","939/939 [==============================] - 57s 60ms/step - loss: 13577.9326 - mae: 30.2839 - val_loss: 288168.6875 - val_mae: 82.2869\n","Epoch 33/50\n","939/939 [==============================] - 56s 60ms/step - loss: 13392.6465 - mae: 30.0170 - val_loss: 169982.3125 - val_mae: 85.6664\n","Epoch 34/50\n","939/939 [==============================] - 57s 61ms/step - loss: 13025.3936 - mae: 29.5317 - val_loss: 208995.6719 - val_mae: 86.1527\n","Epoch 35/50\n","939/939 [==============================] - 56s 60ms/step - loss: 12806.2549 - mae: 29.6078 - val_loss: 295681.2500 - val_mae: 82.6842\n","Epoch 36/50\n","939/939 [==============================] - 58s 61ms/step - loss: 13221.6504 - mae: 29.7599 - val_loss: 282020.0312 - val_mae: 105.0765\n","Epoch 37/50\n","939/939 [==============================] - 57s 60ms/step - loss: 12819.7100 - mae: 29.4244 - val_loss: 318266.8438 - val_mae: 75.6446\n","Epoch 38/50\n","939/939 [==============================] - 58s 62ms/step - loss: 13103.0586 - mae: 29.8355 - val_loss: 181952.9688 - val_mae: 92.1227\n","Epoch 39/50\n","939/939 [==============================] - 59s 62ms/step - loss: 13633.3086 - mae: 30.0983 - val_loss: 359782.6875 - val_mae: 100.6246\n","Epoch 40/50\n","939/939 [==============================] - 57s 60ms/step - loss: 13459.5830 - mae: 29.9363 - val_loss: 366249.5938 - val_mae: 121.9919\n","Epoch 41/50\n","939/939 [==============================] - 56s 60ms/step - loss: 13046.7178 - mae: 29.3454 - val_loss: 333353.3125 - val_mae: 76.4079\n","Epoch 42/50\n","939/939 [==============================] - 55s 59ms/step - loss: 12793.4268 - mae: 29.9383 - val_loss: 223704.7969 - val_mae: 97.8469\n","Epoch 43/50\n","939/939 [==============================] - 57s 61ms/step - loss: 13895.9834 - mae: 30.1393 - val_loss: 257973.7656 - val_mae: 80.8573\n","Epoch 44/50\n","939/939 [==============================] - 56s 59ms/step - loss: 13135.2949 - mae: 29.6039 - val_loss: 441532.9062 - val_mae: 127.0788\n","Epoch 45/50\n","939/939 [==============================] - 57s 61ms/step - loss: 12955.1348 - mae: 30.0681 - val_loss: 342635.3750 - val_mae: 92.3319\n","Epoch 46/50\n","939/939 [==============================] - 56s 59ms/step - loss: 12955.1826 - mae: 29.4347 - val_loss: 322902.1875 - val_mae: 103.4646\n","Epoch 47/50\n","939/939 [==============================] - 54s 57ms/step - loss: 12698.3750 - mae: 29.4360 - val_loss: 194294.3906 - val_mae: 72.8386\n","Epoch 48/50\n","939/939 [==============================] - 56s 59ms/step - loss: 12764.4102 - mae: 29.3170 - val_loss: 339704.6875 - val_mae: 97.0274\n","Epoch 49/50\n","939/939 [==============================] - 55s 58ms/step - loss: 12802.5527 - mae: 29.8606 - val_loss: 337748.3750 - val_mae: 98.3609\n","Epoch 50/50\n","939/939 [==============================] - 56s 59ms/step - loss: 12786.4736 - mae: 29.8516 - val_loss: 178850.6875 - val_mae: 107.7901\n","81.20505321367126\n","2.8058686884838147\n","1.1043199921097304\n"]}]},{"cell_type":"code","source":["######################################dishwasher###############################################################\n","# #trainfile4=\"/content/drive/MyDrive/training_data/dishwasher_test_.csv\"\n","# trainfile1=\"/content/drive/MyDrive/training_data/dishwasher_house_3_training_.csv\"\n","\n","# trainfile2=\"/content/drive/MyDrive/ukdale_training/dishwasher_house_2_training_.csv\"\n","# # trainfile3=\"/content/drive/MyDrive/ukdale_training/fridge_house_2_training_.csv\"\n","# trainfile3=\"/content/drive/MyDrive/refit_training/dishwasher/dishwasher_house_13_training_.csv\"\n","# trainfile4=\"/content/drive/MyDrive/refit_training/dishwasher/dishwasher_house_18_training_.csv\"\n","\n","# fileList=[trainfile1,trainfile2,trainfile3,trainfile4]\n","# stepsizeList=[2,16,16,16]\n","trainfile1=\"/content/drive/MyDrive/training_data/dishwasher_test_.csv\"\n","trainfile2=\"/content/drive/MyDrive/training_data/dishwasher_house_2_training_.csv\"\n","trainfile3=\"/content/drive/MyDrive/ukdale_training/dishwasher_house_1_training_.csv\"\n","trainfile4=\"/content/drive/MyDrive/ukdale_training/dishwasher_house_2_training_.csv\"\n","trainfile5=\"/content/drive/MyDrive/refit_training/dishwasher/dishwasher_house_13_training_.csv\"\n","trainfile6=\"/content/drive/MyDrive/refit_training/dishwasher/dishwasher_house_18_training_.csv\"\n","fileList=[trainfile1,trainfile2,trainfile3,trainfile4,trainfile5,trainfile6]\n","stepsizeList=[2,2,16,16,16,16]\n","data_insts, data_labels, num_insts,on = [], [], [],[]\n","threshold=10\n","for i in range(len(fileList)):\n","    X,Y=dataProvider(fileList[i], 19, stepsizeList[i], threshold)\n","    Y=Y.reshape(-1,1)\n","    data_insts.append(X)\n","    data_labels.append(Y)\n","    num_insts.append(X.shape[0])\n","min_size=min(num_insts)\n","x_tem, y_tem=[],[]\n","for j in range(len(fileList)):\n","  ridx = np.random.choice(num_insts[j], min_size)\n","  x_tem.append(data_insts[j][ridx, :])\n","  y_tem.append(data_labels[j][ridx, :])\n","  num_insts[j]=x_tem[j].shape[0]\n","data_insts=x_tem\n","data_labels=y_tem \n","print(num_insts)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z0WYKP_pSvCW","executionInfo":{"status":"ok","timestamp":1660477695859,"user_tz":-600,"elapsed":15780,"user":{"displayName":"XIAOMIN CHANG","userId":"17429039977919006081"}},"outputId":"c508822d-3e48-47e7-cc95-2aa1b9e10d12"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[15017, 15017, 15017, 15017, 15017, 15017]\n"]}]},{"cell_type":"code","source":["for i in [0,2,4]:\n","        print('\\n---------------------------------------------- domain num %i is running----------------------------------'%(i))\n","        # Build source instances.\n","        source_insts = []\n","        source_labels = []\n","        for j in range(len(fileList)):\n","            if j != i:\n","                source_insts.append(data_insts[j])\n","                source_labels.append(data_labels[j])\n","        # Build target instances.\n","        target_idx = i\n","        target_insts = data_insts[i]\n","        target_labels = data_labels[i]\n","        target_insts0, X_t, target_labels0, y_t =train_test_split(target_insts, target_labels, test_size=0.2,random_state=100)\n","        \n","        X=np.concatenate(source_insts, axis=0)\n","        Y=np.concatenate(source_labels, axis=0)\n","        \n","        x_train_all, x_test, y_train_all, y_test =train_test_split(X, Y, test_size=0.2,random_state=100)\n","        model=CNN_training_best(X,Y)\n","        prediction=model.predict(X_t)\n","        stopT=get_mae(y_t, prediction)\n","        print(stopT)\n","        print(get_sae(y_t, prediction))\n","        print(get_nde(y_t, prediction))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YF8ZEzKuSvRP","executionInfo":{"status":"ok","timestamp":1660485962143,"user_tz":-600,"elapsed":8265306,"user":{"displayName":"XIAOMIN CHANG","userId":"17429039977919006081"}},"outputId":"15bfad0e-40ab-4da6-ff15-9064f44060ab"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","---------------------------------------------- domain num 0 is running----------------------------------\n","start training\n","Epoch 1/50\n","939/939 [==============================] - 58s 60ms/step - loss: 40377.1211 - mae: 42.6279 - val_loss: 46188.0977 - val_mae: 51.3632\n","Epoch 2/50\n","939/939 [==============================] - 54s 57ms/step - loss: 36168.8477 - mae: 43.9452 - val_loss: 41587.2812 - val_mae: 29.3971\n","Epoch 3/50\n","939/939 [==============================] - 55s 59ms/step - loss: 34711.7344 - mae: 43.1153 - val_loss: 38463.7812 - val_mae: 36.6541\n","Epoch 4/50\n","939/939 [==============================] - 53s 57ms/step - loss: 33910.8086 - mae: 42.5194 - val_loss: 39172.9141 - val_mae: 46.0548\n","Epoch 5/50\n","939/939 [==============================] - 55s 59ms/step - loss: 33853.9492 - mae: 43.2822 - val_loss: 38328.4922 - val_mae: 41.2173\n","Epoch 6/50\n","939/939 [==============================] - 52s 56ms/step - loss: 33381.2930 - mae: 43.5909 - val_loss: 39133.0781 - val_mae: 32.6649\n","Epoch 7/50\n","939/939 [==============================] - 55s 58ms/step - loss: 32988.6602 - mae: 43.6982 - val_loss: 39476.7930 - val_mae: 37.8027\n","Epoch 8/50\n","939/939 [==============================] - 54s 57ms/step - loss: 33113.4062 - mae: 43.8948 - val_loss: 37945.3906 - val_mae: 36.6330\n","Epoch 9/50\n","939/939 [==============================] - 53s 57ms/step - loss: 33147.6133 - mae: 43.8217 - val_loss: 38258.8477 - val_mae: 30.6591\n","Epoch 10/50\n","939/939 [==============================] - 56s 59ms/step - loss: 32554.7617 - mae: 43.9273 - val_loss: 40457.0430 - val_mae: 36.7761\n","Epoch 11/50\n","939/939 [==============================] - 53s 57ms/step - loss: 32102.0449 - mae: 44.0898 - val_loss: 45255.0156 - val_mae: 43.6334\n","Epoch 12/50\n","939/939 [==============================] - 55s 58ms/step - loss: 31648.7773 - mae: 44.7616 - val_loss: 42878.4414 - val_mae: 31.0732\n","Epoch 13/50\n","939/939 [==============================] - 57s 61ms/step - loss: 31318.3652 - mae: 44.1780 - val_loss: 42446.4219 - val_mae: 33.8021\n","Epoch 14/50\n","939/939 [==============================] - 58s 62ms/step - loss: 29853.9609 - mae: 42.9819 - val_loss: 45711.5469 - val_mae: 36.8953\n","Epoch 15/50\n","939/939 [==============================] - 57s 61ms/step - loss: 30382.5156 - mae: 43.2698 - val_loss: 46911.6992 - val_mae: 32.6920\n","Epoch 16/50\n","939/939 [==============================] - 58s 62ms/step - loss: 28922.8867 - mae: 42.1498 - val_loss: 46775.9336 - val_mae: 32.9833\n","Epoch 17/50\n","939/939 [==============================] - 59s 63ms/step - loss: 28405.5215 - mae: 42.0513 - val_loss: 47416.5273 - val_mae: 38.1861\n","Epoch 18/50\n","939/939 [==============================] - 60s 64ms/step - loss: 27673.1875 - mae: 41.3180 - val_loss: 51264.1992 - val_mae: 35.9396\n","Epoch 19/50\n","939/939 [==============================] - 62s 67ms/step - loss: 26004.5039 - mae: 39.7300 - val_loss: 47963.2305 - val_mae: 37.6934\n","Epoch 20/50\n","939/939 [==============================] - 60s 64ms/step - loss: 26403.5488 - mae: 40.6450 - val_loss: 57075.0781 - val_mae: 34.7520\n","Epoch 21/50\n","939/939 [==============================] - 62s 66ms/step - loss: 26932.8613 - mae: 40.9432 - val_loss: 57597.5352 - val_mae: 47.0531\n","Epoch 22/50\n","939/939 [==============================] - 61s 65ms/step - loss: 26113.7754 - mae: 40.9009 - val_loss: 45878.3359 - val_mae: 37.0647\n","Epoch 23/50\n","939/939 [==============================] - 61s 65ms/step - loss: 25016.8281 - mae: 40.1847 - val_loss: 59316.9688 - val_mae: 45.1146\n","Epoch 24/50\n","939/939 [==============================] - 64s 68ms/step - loss: 25864.6582 - mae: 40.5351 - val_loss: 58902.5742 - val_mae: 39.4689\n","Epoch 25/50\n","939/939 [==============================] - 62s 66ms/step - loss: 25552.1211 - mae: 40.7830 - val_loss: 57162.5820 - val_mae: 40.0723\n","Epoch 26/50\n","939/939 [==============================] - 62s 66ms/step - loss: 24560.6523 - mae: 40.0987 - val_loss: 61026.0781 - val_mae: 64.1853\n","Epoch 27/50\n","939/939 [==============================] - 64s 68ms/step - loss: 23995.6719 - mae: 39.5182 - val_loss: 63070.6484 - val_mae: 41.2853\n","Epoch 28/50\n","939/939 [==============================] - 65s 69ms/step - loss: 24442.2930 - mae: 40.4516 - val_loss: 57111.5938 - val_mae: 46.6812\n","Epoch 29/50\n","939/939 [==============================] - 62s 66ms/step - loss: 24947.3457 - mae: 40.9712 - val_loss: 64946.2656 - val_mae: 44.7271\n","Epoch 30/50\n","939/939 [==============================] - 64s 68ms/step - loss: 24189.3047 - mae: 41.1153 - val_loss: 56976.0312 - val_mae: 51.2569\n","Epoch 31/50\n","939/939 [==============================] - 63s 67ms/step - loss: 23861.7734 - mae: 40.2122 - val_loss: 65359.6055 - val_mae: 51.9547\n","Epoch 32/50\n","939/939 [==============================] - 64s 69ms/step - loss: 23605.1680 - mae: 40.8259 - val_loss: 60512.1758 - val_mae: 38.0084\n","Epoch 33/50\n","939/939 [==============================] - 64s 68ms/step - loss: 24551.9297 - mae: 41.5041 - val_loss: 60430.5039 - val_mae: 48.7462\n","Epoch 34/50\n","939/939 [==============================] - 62s 66ms/step - loss: 23079.9863 - mae: 39.4928 - val_loss: 60112.4297 - val_mae: 36.6735\n","Epoch 35/50\n","939/939 [==============================] - 64s 68ms/step - loss: 23100.5078 - mae: 39.6620 - val_loss: 66931.7266 - val_mae: 36.0216\n","Epoch 36/50\n","939/939 [==============================] - 67s 71ms/step - loss: 23239.8555 - mae: 39.7002 - val_loss: 62972.6172 - val_mae: 41.8870\n","Epoch 37/50\n","939/939 [==============================] - 65s 69ms/step - loss: 22473.8320 - mae: 39.0809 - val_loss: 62855.0117 - val_mae: 46.4816\n","Epoch 38/50\n","939/939 [==============================] - 65s 70ms/step - loss: 22261.6465 - mae: 39.6174 - val_loss: 63065.6875 - val_mae: 51.9900\n","Epoch 39/50\n","939/939 [==============================] - 65s 69ms/step - loss: 22181.6172 - mae: 39.7941 - val_loss: 65581.3125 - val_mae: 43.5313\n","Epoch 40/50\n","939/939 [==============================] - 63s 67ms/step - loss: 21785.2773 - mae: 39.2476 - val_loss: 68985.5234 - val_mae: 42.7877\n","Epoch 41/50\n","939/939 [==============================] - 65s 69ms/step - loss: 22569.2402 - mae: 40.5115 - val_loss: 67791.7109 - val_mae: 35.6373\n","Epoch 42/50\n","939/939 [==============================] - 64s 68ms/step - loss: 21517.1348 - mae: 39.0324 - val_loss: 65527.6875 - val_mae: 50.1915\n","Epoch 43/50\n","939/939 [==============================] - 64s 68ms/step - loss: 22376.3164 - mae: 39.9956 - val_loss: 64778.7578 - val_mae: 45.6553\n","Epoch 44/50\n","939/939 [==============================] - 64s 68ms/step - loss: 21563.2539 - mae: 39.1418 - val_loss: 73647.7422 - val_mae: 66.8888\n","Epoch 45/50\n","939/939 [==============================] - 63s 67ms/step - loss: 21290.2246 - mae: 39.8237 - val_loss: 69073.0469 - val_mae: 105.2730\n","Epoch 46/50\n","939/939 [==============================] - 64s 68ms/step - loss: 22222.4336 - mae: 40.1389 - val_loss: 69247.2422 - val_mae: 59.9769\n","Epoch 47/50\n","939/939 [==============================] - 62s 66ms/step - loss: 20881.4375 - mae: 39.0832 - val_loss: 64408.8086 - val_mae: 84.2731\n","Epoch 48/50\n","939/939 [==============================] - 63s 68ms/step - loss: 21441.8086 - mae: 40.3476 - val_loss: 70437.6562 - val_mae: 59.9071\n","Epoch 49/50\n","939/939 [==============================] - 61s 65ms/step - loss: 20947.5645 - mae: 38.9502 - val_loss: 67750.8359 - val_mae: 41.4262\n","Epoch 50/50\n","939/939 [==============================] - 61s 65ms/step - loss: 20845.4590 - mae: 40.0416 - val_loss: 69891.6328 - val_mae: 43.0884\n","45.17062756840488\n","1.7047663718160586\n","1.3491390076616618\n","\n","---------------------------------------------- domain num 2 is running----------------------------------\n","start training\n","Epoch 1/50\n","939/939 [==============================] - 59s 61ms/step - loss: 32890.6641 - mae: 41.8609 - val_loss: 44842.1641 - val_mae: 39.4911\n","Epoch 2/50\n","939/939 [==============================] - 58s 62ms/step - loss: 30137.9805 - mae: 43.8099 - val_loss: 44068.2070 - val_mae: 31.7426\n","Epoch 3/50\n","939/939 [==============================] - 57s 60ms/step - loss: 29233.2012 - mae: 41.6260 - val_loss: 45363.1992 - val_mae: 41.1745\n","Epoch 4/50\n","939/939 [==============================] - 58s 62ms/step - loss: 27589.3359 - mae: 42.2004 - val_loss: 46214.0703 - val_mae: 38.9571\n","Epoch 5/50\n","939/939 [==============================] - 59s 63ms/step - loss: 26796.1055 - mae: 41.1653 - val_loss: 44398.6406 - val_mae: 36.7799\n","Epoch 6/50\n","939/939 [==============================] - 58s 62ms/step - loss: 25595.0801 - mae: 41.2645 - val_loss: 49040.6758 - val_mae: 68.5010\n","Epoch 7/50\n","939/939 [==============================] - 59s 63ms/step - loss: 25625.9219 - mae: 41.5193 - val_loss: 48868.3750 - val_mae: 51.5912\n","Epoch 8/50\n","939/939 [==============================] - 58s 62ms/step - loss: 25257.4570 - mae: 40.6115 - val_loss: 49878.0391 - val_mae: 63.1069\n","Epoch 9/50\n","939/939 [==============================] - 59s 63ms/step - loss: 24338.3750 - mae: 40.4463 - val_loss: 53228.1641 - val_mae: 53.8620\n","Epoch 10/50\n","939/939 [==============================] - 58s 61ms/step - loss: 23595.2520 - mae: 39.0894 - val_loss: 52786.0859 - val_mae: 45.5579\n","Epoch 11/50\n","939/939 [==============================] - 57s 61ms/step - loss: 23479.5293 - mae: 39.0960 - val_loss: 52436.8516 - val_mae: 36.5692\n","Epoch 12/50\n","939/939 [==============================] - 54s 58ms/step - loss: 23299.8574 - mae: 39.1003 - val_loss: 50549.4805 - val_mae: 35.3203\n","Epoch 13/50\n","939/939 [==============================] - 56s 59ms/step - loss: 23067.9824 - mae: 38.5560 - val_loss: 56440.1797 - val_mae: 50.5558\n","Epoch 14/50\n","939/939 [==============================] - 56s 60ms/step - loss: 22812.0898 - mae: 38.6758 - val_loss: 57258.6406 - val_mae: 42.1217\n","Epoch 15/50\n","939/939 [==============================] - 54s 58ms/step - loss: 22223.0703 - mae: 38.0189 - val_loss: 56252.8945 - val_mae: 51.3321\n","Epoch 16/50\n","939/939 [==============================] - 58s 61ms/step - loss: 22121.3086 - mae: 38.0533 - val_loss: 55550.3281 - val_mae: 36.8643\n","Epoch 17/50\n","939/939 [==============================] - 56s 60ms/step - loss: 22144.3906 - mae: 38.3109 - val_loss: 55129.7891 - val_mae: 36.0850\n","Epoch 18/50\n","939/939 [==============================] - 58s 61ms/step - loss: 21321.7051 - mae: 37.7939 - val_loss: 55034.5156 - val_mae: 48.9535\n","Epoch 19/50\n","939/939 [==============================] - 56s 59ms/step - loss: 21381.6875 - mae: 37.9822 - val_loss: 57727.5195 - val_mae: 56.5926\n","Epoch 20/50\n","939/939 [==============================] - 58s 62ms/step - loss: 21285.2344 - mae: 37.1367 - val_loss: 59354.4336 - val_mae: 41.0744\n","Epoch 21/50\n","939/939 [==============================] - 56s 59ms/step - loss: 20507.3379 - mae: 36.8666 - val_loss: 59930.0469 - val_mae: 42.0769\n","Epoch 22/50\n","939/939 [==============================] - 58s 62ms/step - loss: 20109.3301 - mae: 36.1454 - val_loss: 58584.5781 - val_mae: 36.2093\n","Epoch 23/50\n","939/939 [==============================] - 57s 60ms/step - loss: 19667.1992 - mae: 35.7864 - val_loss: 60670.8711 - val_mae: 42.8958\n","Epoch 24/50\n","939/939 [==============================] - 59s 62ms/step - loss: 19818.3047 - mae: 35.9539 - val_loss: 59388.4023 - val_mae: 54.8246\n","Epoch 25/50\n","939/939 [==============================] - 56s 60ms/step - loss: 18634.5293 - mae: 35.9774 - val_loss: 60858.1367 - val_mae: 41.7384\n","Epoch 26/50\n","939/939 [==============================] - 57s 61ms/step - loss: 19383.7930 - mae: 36.7013 - val_loss: 57391.8359 - val_mae: 35.3275\n","Epoch 27/50\n","939/939 [==============================] - 57s 61ms/step - loss: 18389.4824 - mae: 35.3416 - val_loss: 59148.8125 - val_mae: 38.4488\n","Epoch 28/50\n","939/939 [==============================] - 56s 59ms/step - loss: 19003.4160 - mae: 35.9466 - val_loss: 58218.2266 - val_mae: 43.2738\n","Epoch 29/50\n","939/939 [==============================] - 58s 61ms/step - loss: 18323.7637 - mae: 35.4597 - val_loss: 58717.1055 - val_mae: 42.1440\n","Epoch 30/50\n","939/939 [==============================] - 57s 61ms/step - loss: 17875.3906 - mae: 35.4815 - val_loss: 61158.2617 - val_mae: 37.6073\n","Epoch 31/50\n","939/939 [==============================] - 58s 62ms/step - loss: 17774.0410 - mae: 35.0482 - val_loss: 61875.1641 - val_mae: 40.2916\n","Epoch 32/50\n","939/939 [==============================] - 57s 61ms/step - loss: 16859.4805 - mae: 34.6417 - val_loss: 65526.7305 - val_mae: 65.2078\n","Epoch 33/50\n","939/939 [==============================] - 60s 64ms/step - loss: 17129.8496 - mae: 34.0315 - val_loss: 61359.8164 - val_mae: 50.9634\n","Epoch 34/50\n","939/939 [==============================] - 57s 60ms/step - loss: 16148.8213 - mae: 33.3176 - val_loss: 58145.1562 - val_mae: 33.0827\n","Epoch 35/50\n","939/939 [==============================] - 59s 63ms/step - loss: 16211.9697 - mae: 34.5186 - val_loss: 60040.9805 - val_mae: 46.3544\n","Epoch 36/50\n","939/939 [==============================] - 57s 60ms/step - loss: 15991.6104 - mae: 33.7295 - val_loss: 58021.0508 - val_mae: 35.7771\n","Epoch 37/50\n","939/939 [==============================] - 58s 62ms/step - loss: 15969.2959 - mae: 33.7648 - val_loss: 62160.4336 - val_mae: 45.3842\n","Epoch 38/50\n","939/939 [==============================] - 56s 59ms/step - loss: 15770.1523 - mae: 33.3852 - val_loss: 60278.9453 - val_mae: 37.7207\n","Epoch 39/50\n","939/939 [==============================] - 57s 61ms/step - loss: 15557.2207 - mae: 33.9549 - val_loss: 62016.7656 - val_mae: 73.4481\n","Epoch 40/50\n","939/939 [==============================] - 55s 59ms/step - loss: 15456.9492 - mae: 33.6696 - val_loss: 63821.6680 - val_mae: 44.0125\n","Epoch 41/50\n","939/939 [==============================] - 57s 60ms/step - loss: 16274.7275 - mae: 35.1181 - val_loss: 60480.2930 - val_mae: 39.5474\n","Epoch 42/50\n","939/939 [==============================] - 57s 61ms/step - loss: 16294.1494 - mae: 34.2924 - val_loss: 62365.7500 - val_mae: 39.6313\n","Epoch 43/50\n","939/939 [==============================] - 55s 58ms/step - loss: 16033.5547 - mae: 34.3544 - val_loss: 60192.9023 - val_mae: 46.7206\n","Epoch 44/50\n","939/939 [==============================] - 57s 61ms/step - loss: 16754.8066 - mae: 35.1853 - val_loss: 64120.4492 - val_mae: 39.0890\n","Epoch 45/50\n","939/939 [==============================] - 55s 59ms/step - loss: 15356.8760 - mae: 33.6631 - val_loss: 62658.6289 - val_mae: 51.0534\n","Epoch 46/50\n","939/939 [==============================] - 58s 62ms/step - loss: 15374.3359 - mae: 33.3166 - val_loss: 59108.3359 - val_mae: 54.6054\n","Epoch 47/50\n","939/939 [==============================] - 55s 59ms/step - loss: 15788.3867 - mae: 34.1361 - val_loss: 63366.8281 - val_mae: 41.0481\n","Epoch 48/50\n","939/939 [==============================] - 56s 59ms/step - loss: 14894.5928 - mae: 33.5992 - val_loss: 62637.6211 - val_mae: 60.7517\n","Epoch 49/50\n","939/939 [==============================] - 54s 57ms/step - loss: 14931.0420 - mae: 33.4851 - val_loss: 60819.5742 - val_mae: 36.3433\n","Epoch 50/50\n","939/939 [==============================] - 55s 59ms/step - loss: 15067.9121 - mae: 33.1136 - val_loss: 62293.5391 - val_mae: 44.0336\n","52.46387947962859\n","0.575253829618499\n","0.9132635674849946\n","\n","---------------------------------------------- domain num 4 is running----------------------------------\n","start training\n","Epoch 1/50\n","939/939 [==============================] - 56s 58ms/step - loss: 34893.3164 - mae: 41.2110 - val_loss: 43669.0234 - val_mae: 46.2099\n","Epoch 2/50\n","939/939 [==============================] - 56s 59ms/step - loss: 30450.5723 - mae: 40.7267 - val_loss: 40349.3984 - val_mae: 32.9477\n","Epoch 3/50\n","939/939 [==============================] - 54s 57ms/step - loss: 29122.4434 - mae: 38.5480 - val_loss: 38747.7461 - val_mae: 41.5594\n","Epoch 4/50\n","939/939 [==============================] - 54s 57ms/step - loss: 28690.1523 - mae: 39.8252 - val_loss: 39763.7383 - val_mae: 39.6394\n","Epoch 5/50\n","939/939 [==============================] - 52s 55ms/step - loss: 27838.4297 - mae: 41.4762 - val_loss: 40099.5000 - val_mae: 43.4136\n","Epoch 6/50\n","939/939 [==============================] - 54s 57ms/step - loss: 27118.7168 - mae: 41.0230 - val_loss: 42048.1719 - val_mae: 43.4052\n","Epoch 7/50\n","939/939 [==============================] - 45s 48ms/step - loss: 26161.0410 - mae: 40.9815 - val_loss: 46356.5391 - val_mae: 76.6627\n","Epoch 8/50\n","939/939 [==============================] - 44s 47ms/step - loss: 25894.3379 - mae: 40.5171 - val_loss: 45228.0859 - val_mae: 51.7868\n","Epoch 9/50\n","939/939 [==============================] - 46s 49ms/step - loss: 24653.1074 - mae: 40.1367 - val_loss: 46766.7305 - val_mae: 54.0209\n","Epoch 10/50\n","939/939 [==============================] - 44s 47ms/step - loss: 24102.0195 - mae: 39.1733 - val_loss: 51546.7891 - val_mae: 64.8727\n","Epoch 11/50\n","939/939 [==============================] - 44s 47ms/step - loss: 22957.4297 - mae: 38.0445 - val_loss: 49443.6406 - val_mae: 54.9702\n","Epoch 12/50\n","939/939 [==============================] - 46s 49ms/step - loss: 22659.8906 - mae: 38.2601 - val_loss: 42602.4844 - val_mae: 57.3778\n","Epoch 13/50\n","939/939 [==============================] - 44s 46ms/step - loss: 22535.3672 - mae: 37.8127 - val_loss: 53137.6172 - val_mae: 37.2547\n","Epoch 14/50\n","939/939 [==============================] - 46s 49ms/step - loss: 22150.6973 - mae: 38.0988 - val_loss: 51101.1250 - val_mae: 40.3345\n","Epoch 15/50\n","939/939 [==============================] - 44s 47ms/step - loss: 21610.0469 - mae: 37.6011 - val_loss: 58490.8242 - val_mae: 48.5470\n","Epoch 16/50\n","939/939 [==============================] - 45s 48ms/step - loss: 21988.3359 - mae: 37.5229 - val_loss: 36084.7188 - val_mae: 38.5479\n","Epoch 17/50\n","939/939 [==============================] - 47s 50ms/step - loss: 22266.2793 - mae: 38.8625 - val_loss: 51434.2734 - val_mae: 45.0840\n","Epoch 18/50\n","939/939 [==============================] - 45s 47ms/step - loss: 21109.1895 - mae: 37.8097 - val_loss: 54803.6797 - val_mae: 45.3841\n","Epoch 19/50\n","939/939 [==============================] - 46s 49ms/step - loss: 20442.1973 - mae: 36.3270 - val_loss: 54884.4844 - val_mae: 40.0696\n","Epoch 20/50\n","939/939 [==============================] - 44s 47ms/step - loss: 19594.5020 - mae: 36.4177 - val_loss: 57306.6406 - val_mae: 68.0385\n","Epoch 21/50\n","939/939 [==============================] - 45s 48ms/step - loss: 19766.0977 - mae: 37.3054 - val_loss: 58766.6406 - val_mae: 55.9940\n","Epoch 22/50\n","939/939 [==============================] - 47s 50ms/step - loss: 21014.1895 - mae: 37.8477 - val_loss: 57083.4883 - val_mae: 47.5187\n","Epoch 23/50\n","939/939 [==============================] - 46s 48ms/step - loss: 19432.6055 - mae: 36.4293 - val_loss: 59739.9883 - val_mae: 43.3618\n","Epoch 24/50\n","939/939 [==============================] - 47s 50ms/step - loss: 19809.3242 - mae: 36.9798 - val_loss: 58827.9062 - val_mae: 40.4369\n","Epoch 25/50\n","939/939 [==============================] - 45s 48ms/step - loss: 19083.7949 - mae: 35.8070 - val_loss: 58396.7500 - val_mae: 45.2807\n","Epoch 26/50\n","939/939 [==============================] - 46s 49ms/step - loss: 18680.7402 - mae: 35.7160 - val_loss: 58423.0625 - val_mae: 45.9021\n","Epoch 27/50\n","939/939 [==============================] - 45s 48ms/step - loss: 18785.4434 - mae: 36.4974 - val_loss: 56437.3203 - val_mae: 39.0212\n","Epoch 28/50\n","939/939 [==============================] - 45s 47ms/step - loss: 19440.9160 - mae: 37.0414 - val_loss: 61510.0117 - val_mae: 55.6210\n","Epoch 29/50\n","939/939 [==============================] - 46s 49ms/step - loss: 18457.5059 - mae: 35.4174 - val_loss: 58107.6328 - val_mae: 38.9002\n","Epoch 30/50\n","939/939 [==============================] - 45s 48ms/step - loss: 18427.3828 - mae: 35.5873 - val_loss: 54589.8984 - val_mae: 46.5135\n","Epoch 31/50\n","939/939 [==============================] - 46s 49ms/step - loss: 17799.1973 - mae: 35.3435 - val_loss: 57970.1680 - val_mae: 55.3314\n","Epoch 32/50\n","939/939 [==============================] - 45s 48ms/step - loss: 17964.0723 - mae: 35.4235 - val_loss: 57234.6133 - val_mae: 48.1282\n","Epoch 33/50\n","939/939 [==============================] - 45s 48ms/step - loss: 17785.1582 - mae: 35.4886 - val_loss: 56284.9180 - val_mae: 40.8749\n","Epoch 34/50\n","939/939 [==============================] - 46s 49ms/step - loss: 19132.6367 - mae: 36.1593 - val_loss: 61574.1328 - val_mae: 48.6190\n","Epoch 35/50\n","939/939 [==============================] - 45s 48ms/step - loss: 18003.1875 - mae: 35.2388 - val_loss: 57355.5312 - val_mae: 47.2988\n","Epoch 36/50\n","939/939 [==============================] - 48s 51ms/step - loss: 17091.0859 - mae: 35.1593 - val_loss: 59089.9570 - val_mae: 50.0691\n","Epoch 37/50\n","939/939 [==============================] - 45s 48ms/step - loss: 16599.8867 - mae: 34.6811 - val_loss: 58228.8477 - val_mae: 44.3617\n","Epoch 38/50\n","939/939 [==============================] - 46s 49ms/step - loss: 18038.6562 - mae: 35.6066 - val_loss: 62618.8867 - val_mae: 44.2905\n","Epoch 39/50\n","939/939 [==============================] - 47s 51ms/step - loss: 18180.4043 - mae: 35.4430 - val_loss: 60876.0430 - val_mae: 53.7213\n","Epoch 40/50\n","939/939 [==============================] - 45s 48ms/step - loss: 16712.0391 - mae: 34.3235 - val_loss: 60016.0547 - val_mae: 51.4458\n","Epoch 41/50\n","939/939 [==============================] - 48s 51ms/step - loss: 17465.7891 - mae: 34.7917 - val_loss: 58921.3750 - val_mae: 48.6716\n","Epoch 42/50\n","939/939 [==============================] - 46s 49ms/step - loss: 16870.7793 - mae: 34.9145 - val_loss: 57309.0898 - val_mae: 38.8891\n","Epoch 43/50\n","939/939 [==============================] - 46s 49ms/step - loss: 16186.5352 - mae: 34.4040 - val_loss: 58456.2969 - val_mae: 44.2365\n","Epoch 44/50\n","939/939 [==============================] - 48s 51ms/step - loss: 16346.0205 - mae: 34.3231 - val_loss: 60590.6328 - val_mae: 57.3023\n","Epoch 45/50\n","939/939 [==============================] - 45s 48ms/step - loss: 17140.7598 - mae: 34.9104 - val_loss: 57250.1914 - val_mae: 50.1520\n","Epoch 46/50\n","939/939 [==============================] - 47s 50ms/step - loss: 16504.4531 - mae: 34.4986 - val_loss: 60509.2070 - val_mae: 43.9715\n","Epoch 47/50\n","939/939 [==============================] - 45s 48ms/step - loss: 16140.4414 - mae: 34.3142 - val_loss: 57271.2344 - val_mae: 41.2260\n","Epoch 48/50\n","939/939 [==============================] - 45s 48ms/step - loss: 15738.1514 - mae: 34.2043 - val_loss: 65817.9219 - val_mae: 79.5036\n","Epoch 49/50\n","939/939 [==============================] - 47s 50ms/step - loss: 15918.6611 - mae: 34.3750 - val_loss: 58983.6875 - val_mae: 46.8998\n","Epoch 50/50\n","939/939 [==============================] - 45s 48ms/step - loss: 15520.1143 - mae: 33.9455 - val_loss: 60903.2891 - val_mae: 45.9717\n","63.28591005005979\n","0.15359515979997826\n","1.128622589530826\n"]}]},{"cell_type":"code","source":["# ######################################microwave###############################################################\n","#trainfile4=\"/content/drive/MyDrive/training_data/dishwasher_test_.csv\"\n","# trainfile1=\"/content/drive/MyDrive/training_data/microwave_house_3_training_.csv\"\n","\n","# trainfile2=\"/content/drive/MyDrive/ukdale_training/microwave_house_2_training_.csv\"\n","# # trainfile3=\"/content/drive/MyDrive/ukdale_training/fridge_house_2_training_.csv\"\n","# trainfile3=\"/content/drive/MyDrive/refit_training/microwave/microwave_house_10_training_.csv\"\n","# trainfile4=\"/content/drive/MyDrive/refit_training/microwave/microwave_house_17_training_.csv\"\n","\n","# fileList=[trainfile1,trainfile2,trainfile3,trainfile4]\n","# stepsizeList=[2,16,16,16]\n","\n","trainfile1=\"/content/drive/MyDrive/training_data/microwave_test_.csv\"\n","trainfile2=\"/content/drive/MyDrive/training_data/microwave_house_2_training_.csv\"\n","trainfile3=\"/content/drive/MyDrive/ukdale_training/microwave_house_1_training_.csv\"\n","trainfile4=\"/content/drive/MyDrive/ukdale_training/microwave_house_2_training_.csv\"\n","trainfile5=\"/content/drive/MyDrive/refit_training/microwave/microwave_house_10_training_.csv\"\n","trainfile6=\"/content/drive/MyDrive/refit_training/microwave/microwave_house_17_training_.csv\"\n","fileList=[trainfile1,trainfile2,trainfile3,trainfile4,trainfile5,trainfile6]\n","stepsizeList=[2,2,16,16,16,16]\n","data_insts, data_labels, num_insts,on = [], [], [],[]\n","threshold=200\n","for i in range(len(fileList)):\n","    X,Y=dataProvider(fileList[i], 19, stepsizeList[i], threshold)\n","    X_on=X[Y>0]\n","    Y_on=Y[Y>0]\n","    X_off=X[Y==0]\n","    Y_off=Y[Y==0]\n","    ridx = np.random.choice(X_off.shape[0], int(len(Y_on)*50))\n","    X_off = X_off[ridx, :]\n","    Y_on=Y_on.reshape(-1,1)\n","    Y_off=Y_off.reshape(-1,1)\n","    Y_off = Y_off[ridx, :]\n","    X_pre=np.concatenate([X_on,X_off], axis=0)\n","    Y_pre=np.concatenate([Y_on,Y_off], axis=0)\n","    on.append(Y_on)\n","    data_insts.append(X_pre)\n","    data_labels.append(Y_pre)\n","    num_insts.append(X_pre.shape[0])\n","    # r_order = np.arange(num_insts[i])\n","    # np.random.shuffle(r_order)\n","    # data_insts[i] = data_insts[i][r_order, :]\n","    # data_labels[i] = data_labels[i][r_order,:]\n","print(num_insts)\n","min_size=min(num_insts)\n","x_tem, y_tem=[],[]\n","for j in range(len(fileList)):\n","  ridx = np.random.choice(num_insts[j], min_size)\n","  x_tem.append(data_insts[j][ridx, :])\n","  y_tem.append(data_labels[j][ridx, :])\n","  num_insts[j]=x_tem[j].shape[0]\n","data_insts=x_tem\n","data_labels=y_tem \n","print(num_insts)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CzBqzZNpSv0K","executionInfo":{"status":"ok","timestamp":1660884017201,"user_tz":-600,"elapsed":6707,"user":{"displayName":"XIAOMIN CHANG","userId":"17429039977919006081"}},"outputId":"ba1c4a35-5520-46ea-ec7d-ef07523b7ce1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[13311, 2907, 51816, 4335, 11475, 10302]\n","[2907, 2907, 2907, 2907, 2907, 2907]\n"]}]},{"cell_type":"code","source":["fileList"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":166},"id":"HSCT9uWVXz93","executionInfo":{"status":"error","timestamp":1660880605302,"user_tz":-600,"elapsed":422,"user":{"displayName":"XIAOMIN CHANG","userId":"17429039977919006081"}},"outputId":"e92d1be7-80f6-4320-c9fd-937e9e3dfb6e"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-38663cc9a1d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfileList\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'fileList' is not defined"]}]},{"cell_type":"code","source":["for i in [0,2,4]:\n","        print('\\n---------------------------------------------- domain num %i is running----------------------------------'%(i))\n","        # Build source instances.\n","        source_insts = []\n","        source_labels = []\n","        for j in range(len(fileList)):\n","            if j != i:\n","                source_insts.append(data_insts[j])\n","                source_labels.append(data_labels[j])\n","        # Build target instances.\n","        target_idx = i\n","        target_insts = data_insts[i]\n","        target_labels = data_labels[i]\n","        target_insts0, X_t, target_labels0, y_t =train_test_split(target_insts, target_labels, test_size=0.2,random_state=100)\n","        \n","        X=np.concatenate(source_insts, axis=0)\n","        Y=np.concatenate(source_labels, axis=0)\n","        \n","        x_train_all, x_test, y_train_all, y_test =train_test_split(X, Y, test_size=0.2,random_state=100)\n","        model=CNN_training_best(X,Y)\n","        prediction=model.predict(X_t)\n","        stopT=get_mae(y_t, prediction)\n","        print(stopT)\n","        print(get_sae(y_t, prediction))\n","        print(get_nde(y_t, prediction))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yomf_EjvSv71","executionInfo":{"status":"ok","timestamp":1660825857580,"user_tz":-600,"elapsed":1752857,"user":{"displayName":"XIAOMIN CHANG","userId":"17429039977919006081"}},"outputId":"378322c9-54d1-4b65-f25c-f069028dbec1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","---------------------------------------------- domain num 0 is running----------------------------------\n","start training\n","Epoch 1/50\n","271/271 [==============================] - 15s 43ms/step - loss: 36427.3281 - mae: 28.5333 - val_loss: 28900.7363 - val_mae: 23.8294\n","Epoch 2/50\n","271/271 [==============================] - 10s 38ms/step - loss: 33981.1445 - mae: 41.4449 - val_loss: 26373.3496 - val_mae: 48.0415\n","Epoch 3/50\n","271/271 [==============================] - 10s 39ms/step - loss: 32483.1992 - mae: 46.5032 - val_loss: 25659.5020 - val_mae: 55.1275\n","Epoch 4/50\n","271/271 [==============================] - 10s 38ms/step - loss: 31174.6406 - mae: 45.4867 - val_loss: 25180.7324 - val_mae: 49.8655\n","Epoch 5/50\n","271/271 [==============================] - 10s 38ms/step - loss: 29093.2500 - mae: 40.9751 - val_loss: 25293.7539 - val_mae: 56.6046\n","Epoch 6/50\n","271/271 [==============================] - 10s 38ms/step - loss: 27862.7598 - mae: 40.1446 - val_loss: 25343.9434 - val_mae: 52.3048\n","Epoch 7/50\n","271/271 [==============================] - 10s 38ms/step - loss: 26775.3711 - mae: 41.2501 - val_loss: 25665.7910 - val_mae: 42.2519\n","Epoch 8/50\n","271/271 [==============================] - 10s 39ms/step - loss: 26629.7402 - mae: 39.8953 - val_loss: 26554.0254 - val_mae: 48.0471\n","Epoch 9/50\n","271/271 [==============================] - 11s 40ms/step - loss: 26172.0645 - mae: 40.9733 - val_loss: 26499.6543 - val_mae: 44.1818\n","Epoch 10/50\n","271/271 [==============================] - 10s 38ms/step - loss: 25942.2852 - mae: 41.4039 - val_loss: 27116.8555 - val_mae: 40.4547\n","Epoch 11/50\n","271/271 [==============================] - 12s 45ms/step - loss: 25333.8164 - mae: 42.0838 - val_loss: 27413.6426 - val_mae: 42.1872\n","Epoch 12/50\n","271/271 [==============================] - 10s 38ms/step - loss: 24792.3555 - mae: 41.1862 - val_loss: 28651.2969 - val_mae: 41.3246\n","Epoch 13/50\n","271/271 [==============================] - 10s 38ms/step - loss: 25127.1465 - mae: 42.4087 - val_loss: 28351.1582 - val_mae: 47.1461\n","Epoch 14/50\n","271/271 [==============================] - 10s 39ms/step - loss: 24909.6875 - mae: 42.1524 - val_loss: 29941.8359 - val_mae: 47.2120\n","Epoch 15/50\n","271/271 [==============================] - 10s 38ms/step - loss: 24262.1133 - mae: 41.7153 - val_loss: 31355.4785 - val_mae: 47.4595\n","Epoch 16/50\n","271/271 [==============================] - 10s 38ms/step - loss: 24667.5938 - mae: 42.5431 - val_loss: 30045.1387 - val_mae: 45.6263\n","Epoch 17/50\n","271/271 [==============================] - 10s 38ms/step - loss: 24043.7969 - mae: 41.9418 - val_loss: 31233.7129 - val_mae: 45.6831\n","Epoch 18/50\n","271/271 [==============================] - 10s 39ms/step - loss: 23978.4492 - mae: 41.8037 - val_loss: 31338.2246 - val_mae: 42.8187\n","Epoch 19/50\n","271/271 [==============================] - 11s 40ms/step - loss: 24022.4434 - mae: 42.0493 - val_loss: 32094.1875 - val_mae: 43.2696\n","Epoch 20/50\n","271/271 [==============================] - 11s 39ms/step - loss: 23896.8750 - mae: 41.8662 - val_loss: 34076.9375 - val_mae: 53.8910\n","Epoch 21/50\n","271/271 [==============================] - 11s 39ms/step - loss: 24072.6855 - mae: 41.8166 - val_loss: 33188.3867 - val_mae: 46.5799\n","Epoch 22/50\n","271/271 [==============================] - 11s 39ms/step - loss: 24112.7383 - mae: 41.9017 - val_loss: 32378.5898 - val_mae: 45.3144\n","Epoch 23/50\n","271/271 [==============================] - 12s 45ms/step - loss: 23903.4961 - mae: 42.2593 - val_loss: 32863.5039 - val_mae: 55.0540\n","Epoch 24/50\n","271/271 [==============================] - 11s 39ms/step - loss: 23582.5449 - mae: 41.2938 - val_loss: 32478.9453 - val_mae: 49.7209\n","Epoch 25/50\n","271/271 [==============================] - 11s 39ms/step - loss: 23711.2754 - mae: 42.5178 - val_loss: 34672.2109 - val_mae: 45.2278\n","Epoch 26/50\n","271/271 [==============================] - 11s 39ms/step - loss: 23363.4727 - mae: 41.2531 - val_loss: 34550.3516 - val_mae: 49.1906\n","Epoch 27/50\n","271/271 [==============================] - 11s 39ms/step - loss: 23478.8535 - mae: 42.5274 - val_loss: 35048.1406 - val_mae: 53.5885\n","Epoch 28/50\n","271/271 [==============================] - 11s 39ms/step - loss: 23938.7109 - mae: 42.2669 - val_loss: 35378.0039 - val_mae: 54.4092\n","Epoch 29/50\n","271/271 [==============================] - 11s 41ms/step - loss: 23111.5020 - mae: 41.0921 - val_loss: 36069.5781 - val_mae: 54.0136\n","Epoch 30/50\n","271/271 [==============================] - 10s 39ms/step - loss: 23160.4746 - mae: 42.4533 - val_loss: 35315.1797 - val_mae: 51.3045\n","Epoch 31/50\n","271/271 [==============================] - 11s 39ms/step - loss: 22725.8438 - mae: 41.9232 - val_loss: 37161.1406 - val_mae: 59.3048\n","Epoch 32/50\n","271/271 [==============================] - 11s 39ms/step - loss: 23161.3984 - mae: 40.1293 - val_loss: 34678.1758 - val_mae: 59.2847\n","Epoch 33/50\n","271/271 [==============================] - 11s 39ms/step - loss: 23274.1270 - mae: 41.8282 - val_loss: 35834.5898 - val_mae: 51.8000\n","Epoch 34/50\n","271/271 [==============================] - 11s 39ms/step - loss: 23010.7480 - mae: 41.2613 - val_loss: 37030.9180 - val_mae: 51.4944\n","Epoch 35/50\n","271/271 [==============================] - 12s 44ms/step - loss: 22840.2656 - mae: 41.8488 - val_loss: 37343.7930 - val_mae: 49.4019\n","Epoch 36/50\n","271/271 [==============================] - 11s 41ms/step - loss: 23031.4805 - mae: 41.5198 - val_loss: 35814.1758 - val_mae: 48.1120\n","Epoch 37/50\n","271/271 [==============================] - 11s 39ms/step - loss: 22881.9062 - mae: 42.3733 - val_loss: 37465.3359 - val_mae: 50.9051\n","Epoch 38/50\n","271/271 [==============================] - 11s 39ms/step - loss: 22488.8281 - mae: 41.8288 - val_loss: 39869.8555 - val_mae: 52.7254\n","Epoch 39/50\n","271/271 [==============================] - 11s 39ms/step - loss: 22381.2891 - mae: 40.5084 - val_loss: 37586.5781 - val_mae: 54.4035\n","Epoch 40/50\n","271/271 [==============================] - 11s 39ms/step - loss: 22144.2383 - mae: 41.0898 - val_loss: 38211.0820 - val_mae: 51.3617\n","Epoch 41/50\n","271/271 [==============================] - 10s 39ms/step - loss: 22642.2598 - mae: 41.8813 - val_loss: 38916.7969 - val_mae: 50.9925\n","Epoch 42/50\n","271/271 [==============================] - 11s 39ms/step - loss: 22308.9004 - mae: 41.3387 - val_loss: 36927.6328 - val_mae: 47.4710\n","Epoch 43/50\n","271/271 [==============================] - 11s 39ms/step - loss: 22315.4980 - mae: 41.7006 - val_loss: 37563.8477 - val_mae: 46.8738\n","Epoch 44/50\n","271/271 [==============================] - 11s 39ms/step - loss: 22188.1641 - mae: 41.2131 - val_loss: 39502.3789 - val_mae: 54.5201\n","Epoch 45/50\n","271/271 [==============================] - 10s 39ms/step - loss: 21783.3223 - mae: 41.4115 - val_loss: 39360.8438 - val_mae: 49.4542\n","Epoch 46/50\n","271/271 [==============================] - 11s 39ms/step - loss: 21619.1797 - mae: 41.1025 - val_loss: 39804.7305 - val_mae: 56.4902\n","Epoch 47/50\n","271/271 [==============================] - 11s 39ms/step - loss: 21781.4707 - mae: 40.3347 - val_loss: 38364.6523 - val_mae: 50.0163\n","Epoch 48/50\n","271/271 [==============================] - 12s 46ms/step - loss: 21484.2656 - mae: 41.0619 - val_loss: 39076.5078 - val_mae: 51.9008\n","Epoch 49/50\n","271/271 [==============================] - 11s 39ms/step - loss: 22133.0410 - mae: 40.6865 - val_loss: 38075.7227 - val_mae: 59.5100\n","Epoch 50/50\n","271/271 [==============================] - 11s 39ms/step - loss: 21796.9180 - mae: 40.7942 - val_loss: 39138.6953 - val_mae: 62.8564\n","28/28 [==============================] - 0s 7ms/step\n","55.9666945267897\n","0.3962070992852448\n","0.9771199526724589\n","\n","---------------------------------------------- domain num 2 is running----------------------------------\n","start training\n","Epoch 1/50\n","271/271 [==============================] - 12s 41ms/step - loss: 37411.9531 - mae: 30.0135 - val_loss: 29045.2598 - val_mae: 24.7973\n","Epoch 2/50\n","271/271 [==============================] - 11s 40ms/step - loss: 34878.1836 - mae: 43.2439 - val_loss: 26369.4590 - val_mae: 48.4701\n","Epoch 3/50\n","271/271 [==============================] - 11s 41ms/step - loss: 33645.3711 - mae: 47.2261 - val_loss: 25419.9668 - val_mae: 49.8906\n","Epoch 4/50\n","271/271 [==============================] - 11s 40ms/step - loss: 32176.8262 - mae: 46.5191 - val_loss: 24945.1406 - val_mae: 41.5327\n","Epoch 5/50\n","271/271 [==============================] - 11s 40ms/step - loss: 30285.6406 - mae: 40.5602 - val_loss: 26320.7578 - val_mae: 67.5093\n","Epoch 6/50\n","271/271 [==============================] - 11s 40ms/step - loss: 29091.6816 - mae: 41.6400 - val_loss: 25394.6719 - val_mae: 52.4049\n","Epoch 7/50\n","271/271 [==============================] - 13s 47ms/step - loss: 27925.3359 - mae: 42.2027 - val_loss: 25477.6367 - val_mae: 43.0400\n","Epoch 8/50\n","271/271 [==============================] - 11s 40ms/step - loss: 27722.6699 - mae: 41.9092 - val_loss: 25556.1719 - val_mae: 44.1600\n","Epoch 9/50\n","271/271 [==============================] - 11s 40ms/step - loss: 26922.2188 - mae: 41.4500 - val_loss: 26034.7812 - val_mae: 41.9179\n","Epoch 10/50\n","271/271 [==============================] - 11s 40ms/step - loss: 26831.3477 - mae: 42.8141 - val_loss: 27104.9863 - val_mae: 47.8327\n","Epoch 11/50\n","271/271 [==============================] - 11s 40ms/step - loss: 27183.2246 - mae: 43.5423 - val_loss: 27680.2852 - val_mae: 41.1998\n","Epoch 12/50\n","271/271 [==============================] - 11s 40ms/step - loss: 26149.2715 - mae: 43.8380 - val_loss: 28001.2363 - val_mae: 41.4303\n","Epoch 13/50\n","271/271 [==============================] - 11s 40ms/step - loss: 26600.1719 - mae: 43.9296 - val_loss: 28549.4180 - val_mae: 45.3768\n","Epoch 14/50\n","271/271 [==============================] - 11s 40ms/step - loss: 26469.8867 - mae: 44.8396 - val_loss: 28981.2012 - val_mae: 50.1609\n","Epoch 15/50\n","271/271 [==============================] - 11s 41ms/step - loss: 26184.2988 - mae: 44.4821 - val_loss: 29123.0742 - val_mae: 54.7578\n","Epoch 16/50\n","271/271 [==============================] - 11s 40ms/step - loss: 25449.8730 - mae: 44.7217 - val_loss: 29303.1172 - val_mae: 43.4384\n","Epoch 17/50\n","271/271 [==============================] - 11s 40ms/step - loss: 25470.6445 - mae: 44.1081 - val_loss: 30593.5039 - val_mae: 55.0468\n","Epoch 18/50\n","271/271 [==============================] - 11s 40ms/step - loss: 25104.6406 - mae: 43.2961 - val_loss: 30930.5176 - val_mae: 47.1534\n","Epoch 19/50\n","271/271 [==============================] - 13s 47ms/step - loss: 25139.9375 - mae: 43.1783 - val_loss: 31133.1758 - val_mae: 61.2685\n","Epoch 20/50\n","271/271 [==============================] - 11s 40ms/step - loss: 25253.4844 - mae: 44.2978 - val_loss: 31418.8770 - val_mae: 52.0916\n","Epoch 21/50\n","271/271 [==============================] - 11s 40ms/step - loss: 24503.7656 - mae: 43.3322 - val_loss: 33536.7344 - val_mae: 65.9722\n","Epoch 22/50\n","271/271 [==============================] - 11s 40ms/step - loss: 25223.9863 - mae: 42.2374 - val_loss: 32600.3125 - val_mae: 43.5177\n","Epoch 23/50\n","271/271 [==============================] - 11s 40ms/step - loss: 24941.0371 - mae: 42.6817 - val_loss: 34788.7031 - val_mae: 58.2331\n","Epoch 24/50\n","271/271 [==============================] - 11s 41ms/step - loss: 24558.9375 - mae: 42.9259 - val_loss: 34105.0938 - val_mae: 66.0119\n","Epoch 25/50\n","271/271 [==============================] - 11s 40ms/step - loss: 24014.6348 - mae: 40.4190 - val_loss: 34539.9648 - val_mae: 52.8995\n","Epoch 26/50\n","271/271 [==============================] - 11s 40ms/step - loss: 24555.0723 - mae: 42.4595 - val_loss: 35912.5820 - val_mae: 50.7690\n","Epoch 27/50\n","271/271 [==============================] - 11s 41ms/step - loss: 24012.8359 - mae: 41.7297 - val_loss: 34720.8359 - val_mae: 52.2398\n","Epoch 28/50\n","271/271 [==============================] - 11s 41ms/step - loss: 24379.1152 - mae: 41.9402 - val_loss: 34235.7383 - val_mae: 45.9773\n","Epoch 29/50\n","271/271 [==============================] - 11s 40ms/step - loss: 24328.2383 - mae: 43.0296 - val_loss: 34429.3086 - val_mae: 50.7033\n","Epoch 30/50\n","271/271 [==============================] - 11s 41ms/step - loss: 23723.7422 - mae: 41.6179 - val_loss: 36079.9805 - val_mae: 45.4804\n","Epoch 31/50\n","271/271 [==============================] - 13s 47ms/step - loss: 23825.3926 - mae: 42.3381 - val_loss: 36619.6016 - val_mae: 54.1709\n","Epoch 32/50\n","271/271 [==============================] - 11s 41ms/step - loss: 23961.5859 - mae: 41.5569 - val_loss: 35507.8125 - val_mae: 51.7739\n","Epoch 33/50\n","271/271 [==============================] - 11s 40ms/step - loss: 23533.5918 - mae: 42.6641 - val_loss: 36862.5430 - val_mae: 50.7335\n","Epoch 34/50\n","271/271 [==============================] - 11s 40ms/step - loss: 24137.0547 - mae: 41.6090 - val_loss: 34740.4766 - val_mae: 49.1859\n","Epoch 35/50\n","271/271 [==============================] - 11s 40ms/step - loss: 23513.8203 - mae: 42.4175 - val_loss: 41431.5977 - val_mae: 60.5838\n","Epoch 36/50\n","271/271 [==============================] - 11s 40ms/step - loss: 23673.5879 - mae: 41.7004 - val_loss: 39051.3008 - val_mae: 51.9136\n","Epoch 37/50\n","271/271 [==============================] - 11s 40ms/step - loss: 23132.2832 - mae: 41.3865 - val_loss: 38037.0469 - val_mae: 56.6792\n","Epoch 38/50\n","271/271 [==============================] - 11s 40ms/step - loss: 23422.5566 - mae: 41.1514 - val_loss: 36656.5156 - val_mae: 47.9458\n","Epoch 39/50\n","271/271 [==============================] - 11s 41ms/step - loss: 23426.1445 - mae: 41.9655 - val_loss: 39909.3789 - val_mae: 52.0616\n","Epoch 40/50\n","271/271 [==============================] - 11s 41ms/step - loss: 23168.2949 - mae: 42.1294 - val_loss: 39699.0430 - val_mae: 52.8255\n","Epoch 41/50\n","271/271 [==============================] - 11s 40ms/step - loss: 23049.5918 - mae: 41.0228 - val_loss: 38244.9883 - val_mae: 50.6291\n","Epoch 42/50\n","271/271 [==============================] - 11s 41ms/step - loss: 22473.6973 - mae: 41.4025 - val_loss: 39378.1484 - val_mae: 49.7260\n","Epoch 43/50\n","271/271 [==============================] - 13s 47ms/step - loss: 22620.9023 - mae: 41.4722 - val_loss: 40853.3555 - val_mae: 54.0955\n","Epoch 44/50\n","271/271 [==============================] - 11s 40ms/step - loss: 22299.6348 - mae: 40.0600 - val_loss: 40634.0820 - val_mae: 47.3658\n","Epoch 45/50\n","271/271 [==============================] - 11s 40ms/step - loss: 22225.7129 - mae: 41.2822 - val_loss: 42565.6758 - val_mae: 52.9331\n","Epoch 46/50\n","271/271 [==============================] - 11s 40ms/step - loss: 22655.0195 - mae: 40.9954 - val_loss: 43070.0273 - val_mae: 48.1349\n","Epoch 47/50\n","271/271 [==============================] - 11s 40ms/step - loss: 22714.5059 - mae: 41.8172 - val_loss: 41204.5078 - val_mae: 72.3396\n","Epoch 48/50\n","271/271 [==============================] - 11s 41ms/step - loss: 22125.8867 - mae: 39.9178 - val_loss: 42538.4062 - val_mae: 58.6425\n","Epoch 49/50\n","271/271 [==============================] - 11s 40ms/step - loss: 22873.2598 - mae: 40.8948 - val_loss: 41023.0000 - val_mae: 66.2445\n","Epoch 50/50\n","271/271 [==============================] - 11s 40ms/step - loss: 22383.7949 - mae: 42.6432 - val_loss: 43995.8633 - val_mae: 50.1386\n","28/28 [==============================] - 0s 7ms/step\n","32.641638087222596\n","0.18050110154282958\n","0.8307172084183407\n","\n","---------------------------------------------- domain num 4 is running----------------------------------\n","start training\n","Epoch 1/50\n","271/271 [==============================] - 12s 42ms/step - loss: 42716.5234 - mae: 32.8733 - val_loss: 28914.4453 - val_mae: 26.0894\n","Epoch 2/50\n","271/271 [==============================] - 11s 42ms/step - loss: 38331.3867 - mae: 42.8296 - val_loss: 25877.3496 - val_mae: 56.1740\n","Epoch 3/50\n","271/271 [==============================] - 12s 43ms/step - loss: 35678.2109 - mae: 44.8796 - val_loss: 26314.1406 - val_mae: 65.0973\n","Epoch 4/50\n","271/271 [==============================] - 13s 46ms/step - loss: 33776.0000 - mae: 44.8604 - val_loss: 24726.3574 - val_mae: 39.3532\n","Epoch 5/50\n","271/271 [==============================] - 11s 41ms/step - loss: 31834.0391 - mae: 42.4333 - val_loss: 25708.2598 - val_mae: 56.0276\n","Epoch 6/50\n","271/271 [==============================] - 11s 42ms/step - loss: 30415.5430 - mae: 42.4729 - val_loss: 26391.8301 - val_mae: 60.0265\n","Epoch 7/50\n","271/271 [==============================] - 11s 42ms/step - loss: 29303.0020 - mae: 41.0001 - val_loss: 27216.3184 - val_mae: 44.8165\n","Epoch 8/50\n","271/271 [==============================] - 11s 42ms/step - loss: 28681.0820 - mae: 40.8692 - val_loss: 28709.6738 - val_mae: 46.3323\n","Epoch 9/50\n","271/271 [==============================] - 11s 42ms/step - loss: 27838.9824 - mae: 40.8398 - val_loss: 30024.9023 - val_mae: 50.0552\n","Epoch 10/50\n","271/271 [==============================] - 11s 42ms/step - loss: 26890.4277 - mae: 40.8066 - val_loss: 31270.9453 - val_mae: 55.6709\n","Epoch 11/50\n","271/271 [==============================] - 11s 42ms/step - loss: 27192.2324 - mae: 41.6772 - val_loss: 32041.9238 - val_mae: 66.9367\n","Epoch 12/50\n","271/271 [==============================] - 11s 42ms/step - loss: 27789.6836 - mae: 42.3768 - val_loss: 34047.6758 - val_mae: 82.5448\n","Epoch 13/50\n","271/271 [==============================] - 11s 42ms/step - loss: 27893.4043 - mae: 43.1904 - val_loss: 32043.9355 - val_mae: 60.1834\n","Epoch 14/50\n","271/271 [==============================] - 11s 42ms/step - loss: 26538.6543 - mae: 42.2581 - val_loss: 33970.8398 - val_mae: 64.6129\n","Epoch 15/50\n","271/271 [==============================] - 13s 49ms/step - loss: 26517.9785 - mae: 41.7849 - val_loss: 33318.5273 - val_mae: 50.4926\n","Epoch 16/50\n","271/271 [==============================] - 11s 42ms/step - loss: 26669.2734 - mae: 41.2038 - val_loss: 33286.4570 - val_mae: 52.0523\n","Epoch 17/50\n","271/271 [==============================] - 11s 42ms/step - loss: 26219.3809 - mae: 41.6807 - val_loss: 35932.8945 - val_mae: 50.6546\n","Epoch 18/50\n","271/271 [==============================] - 11s 42ms/step - loss: 25970.0508 - mae: 42.2491 - val_loss: 34853.2539 - val_mae: 68.1313\n","Epoch 19/50\n","271/271 [==============================] - 11s 42ms/step - loss: 26174.2422 - mae: 41.4564 - val_loss: 36721.2188 - val_mae: 64.3012\n","Epoch 20/50\n","271/271 [==============================] - 11s 42ms/step - loss: 25783.5859 - mae: 41.5993 - val_loss: 37638.6445 - val_mae: 66.4465\n","Epoch 21/50\n","271/271 [==============================] - 11s 42ms/step - loss: 25619.0547 - mae: 42.1392 - val_loss: 36373.3984 - val_mae: 50.6230\n","Epoch 22/50\n","271/271 [==============================] - 11s 42ms/step - loss: 25596.5801 - mae: 41.7061 - val_loss: 36446.2344 - val_mae: 52.9615\n","Epoch 23/50\n","271/271 [==============================] - 11s 42ms/step - loss: 25784.5488 - mae: 42.6110 - val_loss: 39903.2305 - val_mae: 94.7608\n","Epoch 24/50\n","271/271 [==============================] - 11s 41ms/step - loss: 26154.1543 - mae: 42.7090 - val_loss: 37052.9961 - val_mae: 61.6503\n","Epoch 25/50\n","271/271 [==============================] - 11s 41ms/step - loss: 25240.0566 - mae: 41.9969 - val_loss: 40314.4922 - val_mae: 74.0834\n","Epoch 26/50\n","271/271 [==============================] - 11s 42ms/step - loss: 24809.8457 - mae: 41.5764 - val_loss: 38000.6758 - val_mae: 57.5136\n","Epoch 27/50\n","271/271 [==============================] - 13s 48ms/step - loss: 24889.6113 - mae: 41.2823 - val_loss: 38924.5508 - val_mae: 52.3553\n","Epoch 28/50\n","271/271 [==============================] - 11s 41ms/step - loss: 25297.6777 - mae: 41.5829 - val_loss: 39948.4375 - val_mae: 56.3831\n","Epoch 29/50\n","271/271 [==============================] - 11s 42ms/step - loss: 24298.3867 - mae: 40.9799 - val_loss: 42024.0430 - val_mae: 57.7818\n","Epoch 30/50\n","271/271 [==============================] - 11s 41ms/step - loss: 24312.7383 - mae: 41.5551 - val_loss: 38966.6836 - val_mae: 61.2280\n","Epoch 31/50\n","271/271 [==============================] - 11s 41ms/step - loss: 24992.0098 - mae: 41.9005 - val_loss: 40932.4219 - val_mae: 62.4985\n","Epoch 32/50\n","271/271 [==============================] - 11s 41ms/step - loss: 24684.5566 - mae: 41.7449 - val_loss: 43394.2461 - val_mae: 83.8161\n","Epoch 33/50\n","271/271 [==============================] - 11s 41ms/step - loss: 24064.6035 - mae: 41.5959 - val_loss: 40803.4102 - val_mae: 56.7969\n","Epoch 34/50\n","271/271 [==============================] - 11s 40ms/step - loss: 23954.2305 - mae: 41.0977 - val_loss: 44143.5352 - val_mae: 59.0459\n","Epoch 35/50\n","271/271 [==============================] - 11s 41ms/step - loss: 24461.8184 - mae: 40.8708 - val_loss: 41137.7734 - val_mae: 69.8946\n","Epoch 36/50\n","271/271 [==============================] - 11s 41ms/step - loss: 25193.1367 - mae: 43.4782 - val_loss: 41976.3555 - val_mae: 95.1431\n","Epoch 37/50\n","271/271 [==============================] - 11s 41ms/step - loss: 24194.4902 - mae: 40.9352 - val_loss: 43423.0977 - val_mae: 86.4527\n","Epoch 38/50\n","271/271 [==============================] - 13s 48ms/step - loss: 24181.7383 - mae: 42.5172 - val_loss: 43231.4688 - val_mae: 77.1116\n","Epoch 39/50\n","271/271 [==============================] - 11s 41ms/step - loss: 24028.7539 - mae: 41.1598 - val_loss: 42172.3438 - val_mae: 55.8642\n","Epoch 40/50\n","271/271 [==============================] - 11s 41ms/step - loss: 24724.3027 - mae: 41.8357 - val_loss: 43673.0117 - val_mae: 56.2659\n","Epoch 41/50\n","271/271 [==============================] - 11s 42ms/step - loss: 23532.5254 - mae: 40.4284 - val_loss: 41652.0586 - val_mae: 52.2948\n","Epoch 42/50\n","271/271 [==============================] - 11s 41ms/step - loss: 24024.8262 - mae: 42.0465 - val_loss: 43016.5234 - val_mae: 68.0887\n","Epoch 43/50\n","271/271 [==============================] - 11s 41ms/step - loss: 23722.2871 - mae: 41.1610 - val_loss: 42160.4258 - val_mae: 55.3913\n","Epoch 44/50\n","271/271 [==============================] - 11s 40ms/step - loss: 24260.3418 - mae: 41.9119 - val_loss: 44594.4414 - val_mae: 64.5648\n","Epoch 45/50\n","271/271 [==============================] - 11s 40ms/step - loss: 24188.0312 - mae: 41.0096 - val_loss: 44242.1094 - val_mae: 64.7139\n","Epoch 46/50\n","271/271 [==============================] - 11s 42ms/step - loss: 24144.8418 - mae: 42.0272 - val_loss: 41930.2148 - val_mae: 78.4550\n","Epoch 47/50\n","271/271 [==============================] - 11s 41ms/step - loss: 24206.2090 - mae: 41.8995 - val_loss: 42810.2148 - val_mae: 55.1558\n","Epoch 48/50\n","271/271 [==============================] - 11s 41ms/step - loss: 23463.5195 - mae: 41.1526 - val_loss: 44939.7852 - val_mae: 64.4910\n","Epoch 49/50\n","271/271 [==============================] - 11s 42ms/step - loss: 23930.6562 - mae: 41.9998 - val_loss: 43520.2656 - val_mae: 59.4910\n","Epoch 50/50\n","271/271 [==============================] - 13s 48ms/step - loss: 24046.1094 - mae: 42.9928 - val_loss: 43205.7188 - val_mae: 90.7338\n","28/28 [==============================] - 0s 8ms/step\n","100.60623897785683\n","3.130723178475936\n","1.2615105541813858\n"]}]},{"cell_type":"code","source":["for i in [5]:\n","        print('\\n---------------------------------------------- domain num %i is running----------------------------------'%(i))\n","        # Build source instances.\n","        source_insts = []\n","        source_labels = []\n","        for j in range(len(fileList)):\n","            if j != i:\n","                source_insts.append(data_insts[j])\n","                source_labels.append(data_labels[j])\n","        # Build target instances.\n","        target_idx = i\n","        target_insts = data_insts[i]\n","        target_labels = data_labels[i]\n","        target_insts0, X_t, target_labels0, y_t =train_test_split(target_insts, target_labels, test_size=0.2,random_state=100)\n","        \n","        X=np.concatenate(source_insts, axis=0)\n","        Y=np.concatenate(source_labels, axis=0)\n","        \n","        x_train_all, x_test, y_train_all, y_test =train_test_split(X, Y, test_size=0.2,random_state=100)\n","        model=CNN_training_best(X,Y)\n","        prediction=model.predict(X_t)\n","        stopT=get_mae(y_t, prediction)\n","        print(stopT)\n","        print(get_sae(y_t, prediction))\n","        print(get_nde(y_t, prediction))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ei8eXwKcDYyJ","executionInfo":{"status":"ok","timestamp":1660828423614,"user_tz":-600,"elapsed":564462,"user":{"displayName":"XIAOMIN CHANG","userId":"17429039977919006081"}},"outputId":"dc4198d4-1504-4157-f726-0c76cdb9c327"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","---------------------------------------------- domain num 5 is running----------------------------------\n","start training\n","Epoch 1/50\n","271/271 [==============================] - 14s 45ms/step - loss: 42156.0547 - mae: 32.3752 - val_loss: 18957.1836 - val_mae: 23.7764\n","Epoch 2/50\n","271/271 [==============================] - 10s 38ms/step - loss: 37926.8828 - mae: 42.4810 - val_loss: 21506.8613 - val_mae: 69.8233\n","Epoch 3/50\n","271/271 [==============================] - 10s 39ms/step - loss: 35305.9922 - mae: 45.1648 - val_loss: 25047.3281 - val_mae: 79.7593\n","Epoch 4/50\n","271/271 [==============================] - 11s 39ms/step - loss: 33525.7891 - mae: 44.6917 - val_loss: 28194.4629 - val_mae: 76.2965\n","Epoch 5/50\n","271/271 [==============================] - 10s 39ms/step - loss: 32428.7812 - mae: 44.5551 - val_loss: 24148.4531 - val_mae: 78.4546\n","Epoch 6/50\n","271/271 [==============================] - 11s 39ms/step - loss: 30504.6641 - mae: 41.4045 - val_loss: 26281.7539 - val_mae: 77.1783\n","Epoch 7/50\n","271/271 [==============================] - 11s 39ms/step - loss: 29448.6973 - mae: 41.2028 - val_loss: 28667.8320 - val_mae: 78.9182\n","Epoch 8/50\n","271/271 [==============================] - 11s 40ms/step - loss: 29269.0820 - mae: 41.6405 - val_loss: 31855.1914 - val_mae: 80.1285\n","Epoch 9/50\n","271/271 [==============================] - 11s 39ms/step - loss: 28610.1035 - mae: 42.0754 - val_loss: 32174.0547 - val_mae: 81.3384\n","Epoch 10/50\n","271/271 [==============================] - 11s 39ms/step - loss: 28095.6797 - mae: 41.4263 - val_loss: 32156.0391 - val_mae: 82.6267\n","Epoch 11/50\n","271/271 [==============================] - 12s 46ms/step - loss: 27265.4492 - mae: 41.1884 - val_loss: 34224.0234 - val_mae: 83.7057\n","Epoch 12/50\n","271/271 [==============================] - 11s 39ms/step - loss: 28068.8516 - mae: 43.2243 - val_loss: 33667.4570 - val_mae: 86.1866\n","Epoch 13/50\n","271/271 [==============================] - 11s 39ms/step - loss: 26837.0078 - mae: 42.3186 - val_loss: 38392.8867 - val_mae: 83.1705\n","Epoch 14/50\n","271/271 [==============================] - 11s 39ms/step - loss: 27429.8066 - mae: 42.8380 - val_loss: 35180.2344 - val_mae: 89.9128\n","Epoch 15/50\n","271/271 [==============================] - 11s 39ms/step - loss: 26623.6152 - mae: 43.5110 - val_loss: 35888.6484 - val_mae: 79.6978\n","Epoch 16/50\n","271/271 [==============================] - 11s 39ms/step - loss: 27559.8340 - mae: 43.4103 - val_loss: 34451.5586 - val_mae: 85.2303\n","Epoch 17/50\n","271/271 [==============================] - 11s 39ms/step - loss: 26630.2188 - mae: 42.5968 - val_loss: 33865.3086 - val_mae: 79.5198\n","Epoch 18/50\n","271/271 [==============================] - 11s 39ms/step - loss: 26490.7676 - mae: 43.5008 - val_loss: 33672.3359 - val_mae: 83.0368\n","Epoch 19/50\n","271/271 [==============================] - 11s 39ms/step - loss: 26220.6582 - mae: 43.0694 - val_loss: 37666.8438 - val_mae: 93.2201\n","Epoch 20/50\n","271/271 [==============================] - 11s 39ms/step - loss: 26559.9902 - mae: 43.0356 - val_loss: 36885.6211 - val_mae: 92.6135\n","Epoch 21/50\n","271/271 [==============================] - 11s 39ms/step - loss: 26346.9922 - mae: 42.8933 - val_loss: 35581.6250 - val_mae: 85.2064\n","Epoch 22/50\n","271/271 [==============================] - 10s 39ms/step - loss: 26499.1133 - mae: 43.7114 - val_loss: 35623.6445 - val_mae: 82.6900\n","Epoch 23/50\n","271/271 [==============================] - 11s 39ms/step - loss: 24960.6270 - mae: 42.1176 - val_loss: 34210.7070 - val_mae: 84.7605\n","Epoch 24/50\n","271/271 [==============================] - 12s 45ms/step - loss: 25846.4668 - mae: 43.8341 - val_loss: 32874.1250 - val_mae: 76.8446\n","Epoch 25/50\n","271/271 [==============================] - 11s 39ms/step - loss: 25624.4883 - mae: 42.5200 - val_loss: 37878.0078 - val_mae: 92.4794\n","Epoch 26/50\n","271/271 [==============================] - 11s 39ms/step - loss: 25198.3477 - mae: 42.8450 - val_loss: 39457.3906 - val_mae: 85.5698\n","Epoch 27/50\n","271/271 [==============================] - 11s 39ms/step - loss: 25006.1074 - mae: 42.4056 - val_loss: 34608.7422 - val_mae: 77.1334\n","Epoch 28/50\n","271/271 [==============================] - 11s 39ms/step - loss: 25194.1465 - mae: 43.1869 - val_loss: 35911.4805 - val_mae: 82.4845\n","Epoch 29/50\n","271/271 [==============================] - 11s 39ms/step - loss: 24806.4688 - mae: 42.7195 - val_loss: 37391.2188 - val_mae: 84.4413\n","Epoch 30/50\n","271/271 [==============================] - 11s 39ms/step - loss: 24765.0410 - mae: 42.3655 - val_loss: 38770.9570 - val_mae: 81.2278\n","Epoch 31/50\n","271/271 [==============================] - 11s 40ms/step - loss: 24820.2148 - mae: 41.3587 - val_loss: 41709.8750 - val_mae: 90.2347\n","Epoch 32/50\n","271/271 [==============================] - 10s 39ms/step - loss: 25045.5312 - mae: 42.7487 - val_loss: 34626.3086 - val_mae: 76.1523\n","Epoch 33/50\n","271/271 [==============================] - 11s 39ms/step - loss: 24951.0898 - mae: 42.2849 - val_loss: 36412.1484 - val_mae: 86.4302\n","Epoch 34/50\n","271/271 [==============================] - 11s 39ms/step - loss: 24519.4824 - mae: 42.2950 - val_loss: 38321.8945 - val_mae: 95.9909\n","Epoch 35/50\n","271/271 [==============================] - 11s 39ms/step - loss: 24902.6074 - mae: 43.2606 - val_loss: 37656.2305 - val_mae: 95.4474\n","Epoch 36/50\n","271/271 [==============================] - 11s 39ms/step - loss: 24717.3711 - mae: 42.9904 - val_loss: 36954.7344 - val_mae: 86.4262\n","Epoch 37/50\n","271/271 [==============================] - 12s 46ms/step - loss: 24628.6934 - mae: 43.5816 - val_loss: 37603.1211 - val_mae: 85.9923\n","Epoch 38/50\n","271/271 [==============================] - 11s 39ms/step - loss: 24473.7441 - mae: 42.1279 - val_loss: 34817.2305 - val_mae: 76.2677\n","Epoch 39/50\n","271/271 [==============================] - 11s 39ms/step - loss: 24590.4375 - mae: 43.6779 - val_loss: 37648.1875 - val_mae: 90.2827\n","Epoch 40/50\n","271/271 [==============================] - 11s 39ms/step - loss: 24451.8262 - mae: 42.6677 - val_loss: 36472.3906 - val_mae: 86.4425\n","Epoch 41/50\n","271/271 [==============================] - 11s 39ms/step - loss: 24609.1250 - mae: 43.1293 - val_loss: 36836.1836 - val_mae: 83.7911\n","Epoch 42/50\n","271/271 [==============================] - 11s 39ms/step - loss: 24230.8945 - mae: 43.1827 - val_loss: 36127.7188 - val_mae: 87.9503\n","Epoch 43/50\n","271/271 [==============================] - 11s 39ms/step - loss: 23696.9355 - mae: 42.2172 - val_loss: 38689.3359 - val_mae: 87.2532\n","Epoch 44/50\n","271/271 [==============================] - 11s 39ms/step - loss: 24542.0469 - mae: 43.5157 - val_loss: 33216.7500 - val_mae: 78.5742\n","Epoch 45/50\n","271/271 [==============================] - 11s 39ms/step - loss: 24276.6992 - mae: 43.0376 - val_loss: 36248.6445 - val_mae: 85.9437\n","Epoch 46/50\n","271/271 [==============================] - 11s 39ms/step - loss: 23996.1270 - mae: 41.5757 - val_loss: 39785.5781 - val_mae: 103.8309\n","Epoch 47/50\n","271/271 [==============================] - 11s 39ms/step - loss: 24010.5898 - mae: 43.2919 - val_loss: 38713.8555 - val_mae: 83.4785\n","Epoch 48/50\n","271/271 [==============================] - 11s 39ms/step - loss: 23983.2695 - mae: 42.1339 - val_loss: 37063.9609 - val_mae: 82.6430\n","Epoch 49/50\n","271/271 [==============================] - 11s 39ms/step - loss: 24208.3867 - mae: 44.0367 - val_loss: 34389.9141 - val_mae: 93.9224\n","Epoch 50/50\n","271/271 [==============================] - 12s 46ms/step - loss: 23667.6602 - mae: 42.7532 - val_loss: 36424.8672 - val_mae: 89.3970\n","28/28 [==============================] - 0s 7ms/step\n","72.80180089909588\n","2.4300094708977937\n","1.4039590876934336\n"]}]},{"cell_type":"code","source":["for i in [1,3]:\n","        print('\\n---------------------------------------------- domain num %i is running----------------------------------'%(i))\n","        # Build source instances.\n","        source_insts = []\n","        source_labels = []\n","        for j in range(len(fileList)):\n","            if j != i:\n","                source_insts.append(data_insts[j])\n","                source_labels.append(data_labels[j])\n","        # Build target instances.\n","        target_idx = i\n","        target_insts = data_insts[i]\n","        target_labels = data_labels[i]\n","        target_insts0, X_t, target_labels0, y_t =train_test_split(target_insts, target_labels, test_size=0.2,random_state=100)\n","        \n","        X=np.concatenate(source_insts, axis=0)\n","        Y=np.concatenate(source_labels, axis=0)\n","        \n","        x_train_all, x_test, y_train_all, y_test =train_test_split(X, Y, test_size=0.2,random_state=100)\n","        model=CNN_training_best(X,Y)\n","        prediction=model.predict(X_t)\n","        stopT=get_mae(y_t, prediction)\n","        print(stopT)\n","        print(get_sae(y_t, prediction))\n","        print(get_nde(y_t, prediction))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t66BNBonBfTO","executionInfo":{"status":"ok","timestamp":1660881569923,"user_tz":-600,"elapsed":934516,"user":{"displayName":"XIAOMIN CHANG","userId":"17429039977919006081"}},"outputId":"ae54dc55-f1a5-41c5-a5fe-a23b50efc384"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","---------------------------------------------- domain num 1 is running----------------------------------\n","start training\n","Epoch 1/50\n","271/271 [==============================] - 11s 36ms/step - loss: 35721.8750 - mae: 30.3331 - val_loss: 36448.5195 - val_mae: 29.6640\n","Epoch 2/50\n","271/271 [==============================] - 10s 36ms/step - loss: 33448.1055 - mae: 44.8122 - val_loss: 32956.7031 - val_mae: 53.0786\n","Epoch 3/50\n","271/271 [==============================] - 9s 32ms/step - loss: 32193.0781 - mae: 47.3426 - val_loss: 31067.2676 - val_mae: 51.3792\n","Epoch 4/50\n","271/271 [==============================] - 9s 34ms/step - loss: 31267.5508 - mae: 48.3951 - val_loss: 30838.6660 - val_mae: 42.7676\n","Epoch 5/50\n","271/271 [==============================] - 10s 37ms/step - loss: 29910.1094 - mae: 42.9760 - val_loss: 32555.1250 - val_mae: 69.5932\n","Epoch 6/50\n","271/271 [==============================] - 9s 34ms/step - loss: 28818.5684 - mae: 43.5400 - val_loss: 32053.5371 - val_mae: 56.5072\n","Epoch 7/50\n","271/271 [==============================] - 9s 35ms/step - loss: 27974.0254 - mae: 43.7016 - val_loss: 32966.5078 - val_mae: 48.7763\n","Epoch 8/50\n","271/271 [==============================] - 9s 34ms/step - loss: 27542.5332 - mae: 43.8668 - val_loss: 33856.5078 - val_mae: 47.9453\n","Epoch 9/50\n","271/271 [==============================] - 9s 35ms/step - loss: 26970.4883 - mae: 43.3853 - val_loss: 34602.0156 - val_mae: 52.4606\n","Epoch 10/50\n","271/271 [==============================] - 9s 35ms/step - loss: 26581.5625 - mae: 43.6146 - val_loss: 36272.6367 - val_mae: 52.2804\n","Epoch 11/50\n","271/271 [==============================] - 9s 35ms/step - loss: 26609.2910 - mae: 44.2426 - val_loss: 36353.6602 - val_mae: 63.0374\n","Epoch 12/50\n","271/271 [==============================] - 9s 35ms/step - loss: 26526.5977 - mae: 44.6454 - val_loss: 37485.8555 - val_mae: 65.3080\n","Epoch 13/50\n","271/271 [==============================] - 9s 35ms/step - loss: 25960.4844 - mae: 44.1980 - val_loss: 37432.3906 - val_mae: 56.8012\n","Epoch 14/50\n","271/271 [==============================] - 10s 35ms/step - loss: 25905.5293 - mae: 43.6270 - val_loss: 37715.2930 - val_mae: 57.0722\n","Epoch 15/50\n","271/271 [==============================] - 9s 35ms/step - loss: 26036.7695 - mae: 44.2725 - val_loss: 39785.5625 - val_mae: 71.8367\n","Epoch 16/50\n","271/271 [==============================] - 11s 39ms/step - loss: 25934.6191 - mae: 43.9135 - val_loss: 39514.8398 - val_mae: 52.3266\n","Epoch 17/50\n","271/271 [==============================] - 9s 34ms/step - loss: 25812.0898 - mae: 44.8020 - val_loss: 40013.9414 - val_mae: 51.8065\n","Epoch 18/50\n","271/271 [==============================] - 9s 35ms/step - loss: 26058.9355 - mae: 43.8471 - val_loss: 40315.8008 - val_mae: 52.9063\n","Epoch 19/50\n","271/271 [==============================] - 10s 35ms/step - loss: 25484.2949 - mae: 44.1787 - val_loss: 40762.4648 - val_mae: 62.4313\n","Epoch 20/50\n","271/271 [==============================] - 10s 36ms/step - loss: 25732.5176 - mae: 43.8676 - val_loss: 42097.9375 - val_mae: 77.9394\n","Epoch 21/50\n","271/271 [==============================] - 9s 35ms/step - loss: 25405.2363 - mae: 44.3663 - val_loss: 41501.5430 - val_mae: 63.0620\n","Epoch 22/50\n","271/271 [==============================] - 9s 35ms/step - loss: 26030.2266 - mae: 44.2094 - val_loss: 41669.6562 - val_mae: 63.5669\n","Epoch 23/50\n","271/271 [==============================] - 9s 34ms/step - loss: 25850.1172 - mae: 43.9794 - val_loss: 41876.5508 - val_mae: 57.5343\n","Epoch 24/50\n","271/271 [==============================] - 9s 35ms/step - loss: 25373.5898 - mae: 44.0016 - val_loss: 42720.7891 - val_mae: 62.5547\n","Epoch 25/50\n","271/271 [==============================] - 9s 34ms/step - loss: 25487.0020 - mae: 44.0545 - val_loss: 43840.2773 - val_mae: 71.3631\n","Epoch 26/50\n","271/271 [==============================] - 9s 35ms/step - loss: 24865.4922 - mae: 43.9668 - val_loss: 45854.5312 - val_mae: 74.1935\n","Epoch 27/50\n","271/271 [==============================] - 9s 35ms/step - loss: 25124.2441 - mae: 45.2477 - val_loss: 44020.9414 - val_mae: 67.3407\n","Epoch 28/50\n","271/271 [==============================] - 11s 39ms/step - loss: 25143.2461 - mae: 43.4676 - val_loss: 47850.3320 - val_mae: 69.0237\n","Epoch 29/50\n","271/271 [==============================] - 10s 35ms/step - loss: 24760.7871 - mae: 43.8447 - val_loss: 44596.0547 - val_mae: 72.0024\n","Epoch 30/50\n","271/271 [==============================] - 9s 35ms/step - loss: 25140.6602 - mae: 44.4787 - val_loss: 45554.0312 - val_mae: 56.7870\n","Epoch 31/50\n","271/271 [==============================] - 9s 34ms/step - loss: 24801.5566 - mae: 43.5761 - val_loss: 46529.2422 - val_mae: 56.1948\n","Epoch 32/50\n","271/271 [==============================] - 10s 35ms/step - loss: 24787.2383 - mae: 43.7174 - val_loss: 46976.5742 - val_mae: 71.5763\n","Epoch 33/50\n","271/271 [==============================] - 10s 35ms/step - loss: 24592.0605 - mae: 44.5286 - val_loss: 48407.4570 - val_mae: 76.7846\n","Epoch 34/50\n","271/271 [==============================] - 9s 35ms/step - loss: 24639.5059 - mae: 44.5166 - val_loss: 49492.7617 - val_mae: 62.0426\n","Epoch 35/50\n","271/271 [==============================] - 10s 35ms/step - loss: 25022.8945 - mae: 44.2477 - val_loss: 45056.6367 - val_mae: 66.2796\n","Epoch 36/50\n","271/271 [==============================] - 10s 35ms/step - loss: 24466.6582 - mae: 43.3123 - val_loss: 47244.7266 - val_mae: 59.9351\n","Epoch 37/50\n","271/271 [==============================] - 10s 35ms/step - loss: 24425.0254 - mae: 43.5634 - val_loss: 50216.0039 - val_mae: 62.2823\n","Epoch 38/50\n","271/271 [==============================] - 9s 35ms/step - loss: 24075.2969 - mae: 42.7437 - val_loss: 48627.4531 - val_mae: 70.8636\n","Epoch 39/50\n","271/271 [==============================] - 11s 40ms/step - loss: 24212.4707 - mae: 43.9577 - val_loss: 47030.8242 - val_mae: 57.4705\n","Epoch 40/50\n","271/271 [==============================] - 10s 36ms/step - loss: 24289.4258 - mae: 43.6524 - val_loss: 47431.8906 - val_mae: 82.8266\n","Epoch 41/50\n","271/271 [==============================] - 10s 35ms/step - loss: 24466.8281 - mae: 43.9010 - val_loss: 48569.3594 - val_mae: 68.0601\n","Epoch 42/50\n","271/271 [==============================] - 9s 33ms/step - loss: 24116.9023 - mae: 43.0949 - val_loss: 47491.0039 - val_mae: 65.4206\n","Epoch 43/50\n","271/271 [==============================] - 9s 32ms/step - loss: 24394.6055 - mae: 43.9719 - val_loss: 49441.7305 - val_mae: 59.3767\n","Epoch 44/50\n","271/271 [==============================] - 9s 35ms/step - loss: 23724.3125 - mae: 43.8175 - val_loss: 55606.7461 - val_mae: 93.3698\n","Epoch 45/50\n","271/271 [==============================] - 9s 35ms/step - loss: 23504.6523 - mae: 45.7473 - val_loss: 49222.1953 - val_mae: 78.6519\n","Epoch 46/50\n","271/271 [==============================] - 9s 34ms/step - loss: 24219.0977 - mae: 42.9508 - val_loss: 49118.6055 - val_mae: 60.9644\n","Epoch 47/50\n","271/271 [==============================] - 10s 35ms/step - loss: 24118.8906 - mae: 42.3640 - val_loss: 54175.7070 - val_mae: 76.9999\n","Epoch 48/50\n","271/271 [==============================] - 9s 34ms/step - loss: 23416.6777 - mae: 42.9304 - val_loss: 49355.0938 - val_mae: 67.8209\n","Epoch 49/50\n","271/271 [==============================] - 9s 34ms/step - loss: 23949.9551 - mae: 43.2932 - val_loss: 49744.1016 - val_mae: 78.9675\n","Epoch 50/50\n","271/271 [==============================] - 9s 35ms/step - loss: 23486.5781 - mae: 42.4357 - val_loss: 50378.1250 - val_mae: 62.2924\n","34.77325481478868\n","0.799580840515438\n","0.6538800316532767\n","\n","---------------------------------------------- domain num 3 is running----------------------------------\n","start training\n","Epoch 1/50\n","271/271 [==============================] - 11s 37ms/step - loss: 40091.1602 - mae: 33.1027 - val_loss: 35873.2773 - val_mae: 30.3427\n","Epoch 2/50\n","271/271 [==============================] - 10s 35ms/step - loss: 37468.5938 - mae: 44.7615 - val_loss: 32468.1641 - val_mae: 53.4392\n","Epoch 3/50\n","271/271 [==============================] - 9s 32ms/step - loss: 36138.9648 - mae: 47.8470 - val_loss: 31194.9395 - val_mae: 53.3616\n","Epoch 4/50\n","271/271 [==============================] - 9s 32ms/step - loss: 34946.7188 - mae: 47.0383 - val_loss: 31285.0703 - val_mae: 57.9159\n","Epoch 5/50\n","271/271 [==============================] - 9s 34ms/step - loss: 32988.3672 - mae: 42.6133 - val_loss: 31593.1562 - val_mae: 60.4392\n","Epoch 6/50\n","271/271 [==============================] - 9s 34ms/step - loss: 32329.9062 - mae: 42.9286 - val_loss: 31227.7773 - val_mae: 50.3242\n","Epoch 7/50\n","271/271 [==============================] - 8s 31ms/step - loss: 31109.6836 - mae: 42.1970 - val_loss: 32577.4473 - val_mae: 54.3144\n","Epoch 8/50\n","271/271 [==============================] - 9s 35ms/step - loss: 30782.5449 - mae: 43.7940 - val_loss: 32907.0625 - val_mae: 46.7525\n","Epoch 9/50\n","271/271 [==============================] - 9s 34ms/step - loss: 30298.4883 - mae: 43.3374 - val_loss: 33375.4531 - val_mae: 48.7500\n","Epoch 10/50\n","271/271 [==============================] - 9s 34ms/step - loss: 30734.0098 - mae: 45.4428 - val_loss: 33831.0586 - val_mae: 49.4271\n","Epoch 11/50\n","271/271 [==============================] - 9s 33ms/step - loss: 30325.1777 - mae: 45.5551 - val_loss: 34796.7969 - val_mae: 50.4022\n","Epoch 12/50\n","271/271 [==============================] - 8s 31ms/step - loss: 30470.9629 - mae: 45.8508 - val_loss: 35792.9727 - val_mae: 55.3721\n","Epoch 13/50\n","271/271 [==============================] - 10s 37ms/step - loss: 29695.7148 - mae: 45.2315 - val_loss: 36329.6172 - val_mae: 54.9281\n","Epoch 14/50\n","271/271 [==============================] - 9s 34ms/step - loss: 29875.9258 - mae: 46.1525 - val_loss: 35568.5508 - val_mae: 50.0406\n","Epoch 15/50\n","271/271 [==============================] - 9s 34ms/step - loss: 29851.5156 - mae: 46.6284 - val_loss: 36583.7188 - val_mae: 54.5168\n","Epoch 16/50\n","271/271 [==============================] - 9s 34ms/step - loss: 29793.0254 - mae: 46.4157 - val_loss: 37400.3906 - val_mae: 55.4695\n","Epoch 17/50\n","271/271 [==============================] - 9s 34ms/step - loss: 29720.3965 - mae: 46.6656 - val_loss: 38401.1094 - val_mae: 51.6470\n","Epoch 18/50\n","271/271 [==============================] - 9s 34ms/step - loss: 29553.9004 - mae: 45.9985 - val_loss: 38878.2578 - val_mae: 65.0089\n","Epoch 19/50\n","271/271 [==============================] - 9s 34ms/step - loss: 29069.3672 - mae: 45.9544 - val_loss: 40154.1367 - val_mae: 52.2618\n","Epoch 20/50\n","271/271 [==============================] - 9s 33ms/step - loss: 29064.0078 - mae: 45.7066 - val_loss: 41299.1055 - val_mae: 55.1261\n","Epoch 21/50\n","271/271 [==============================] - 9s 34ms/step - loss: 29196.5234 - mae: 46.2466 - val_loss: 40296.6602 - val_mae: 60.2822\n","Epoch 22/50\n","271/271 [==============================] - 9s 32ms/step - loss: 29625.4609 - mae: 47.1000 - val_loss: 41996.0742 - val_mae: 59.9266\n","Epoch 23/50\n","271/271 [==============================] - 9s 33ms/step - loss: 28867.9863 - mae: 45.9701 - val_loss: 42098.4492 - val_mae: 57.2302\n","Epoch 24/50\n","271/271 [==============================] - 10s 35ms/step - loss: 28522.5918 - mae: 45.6130 - val_loss: 44452.1641 - val_mae: 59.7070\n","Epoch 25/50\n","271/271 [==============================] - 10s 36ms/step - loss: 28903.6426 - mae: 45.8150 - val_loss: 42378.9336 - val_mae: 52.9424\n","Epoch 26/50\n","271/271 [==============================] - 9s 34ms/step - loss: 28936.9199 - mae: 46.3828 - val_loss: 43031.7422 - val_mae: 59.7659\n","Epoch 27/50\n","271/271 [==============================] - 9s 34ms/step - loss: 28514.4551 - mae: 46.2953 - val_loss: 43959.7695 - val_mae: 57.5959\n","Epoch 28/50\n","271/271 [==============================] - 9s 32ms/step - loss: 28381.9395 - mae: 45.7717 - val_loss: 47867.4336 - val_mae: 61.8919\n","Epoch 29/50\n","271/271 [==============================] - 9s 32ms/step - loss: 28692.2188 - mae: 46.7115 - val_loss: 44485.9844 - val_mae: 63.6783\n","Epoch 30/50\n","271/271 [==============================] - 9s 35ms/step - loss: 28525.8340 - mae: 45.9037 - val_loss: 47392.4648 - val_mae: 55.9657\n","Epoch 31/50\n","271/271 [==============================] - 8s 30ms/step - loss: 28383.4961 - mae: 46.3675 - val_loss: 48646.7969 - val_mae: 57.6431\n","Epoch 32/50\n","271/271 [==============================] - 9s 34ms/step - loss: 28156.2051 - mae: 45.8497 - val_loss: 48074.1602 - val_mae: 56.5590\n","Epoch 33/50\n","271/271 [==============================] - 9s 34ms/step - loss: 28366.1602 - mae: 46.6678 - val_loss: 48330.0273 - val_mae: 65.1811\n","Epoch 34/50\n","271/271 [==============================] - 9s 34ms/step - loss: 28222.3457 - mae: 46.0536 - val_loss: 50041.1992 - val_mae: 60.0009\n","Epoch 35/50\n","271/271 [==============================] - 9s 34ms/step - loss: 27984.8574 - mae: 45.9052 - val_loss: 48526.6406 - val_mae: 55.7368\n","Epoch 36/50\n","271/271 [==============================] - 10s 38ms/step - loss: 27961.4375 - mae: 45.3190 - val_loss: 47436.9141 - val_mae: 59.6746\n","Epoch 37/50\n","271/271 [==============================] - 10s 37ms/step - loss: 28008.2109 - mae: 45.8438 - val_loss: 51992.7188 - val_mae: 59.2468\n","Epoch 38/50\n","271/271 [==============================] - 9s 34ms/step - loss: 27722.7148 - mae: 45.2802 - val_loss: 55076.0469 - val_mae: 75.6458\n","Epoch 39/50\n","271/271 [==============================] - 9s 35ms/step - loss: 28443.7656 - mae: 46.3084 - val_loss: 50982.7383 - val_mae: 60.4482\n","Epoch 40/50\n","271/271 [==============================] - 9s 34ms/step - loss: 27973.6406 - mae: 45.5182 - val_loss: 50941.7539 - val_mae: 57.4281\n","Epoch 41/50\n","271/271 [==============================] - 9s 33ms/step - loss: 27858.2891 - mae: 45.7029 - val_loss: 54062.8789 - val_mae: 65.5582\n","Epoch 42/50\n","271/271 [==============================] - 9s 33ms/step - loss: 27445.1055 - mae: 45.0934 - val_loss: 53271.4375 - val_mae: 58.9145\n","Epoch 43/50\n","271/271 [==============================] - 9s 33ms/step - loss: 27809.0664 - mae: 46.5294 - val_loss: 52065.5625 - val_mae: 73.5531\n","Epoch 44/50\n","271/271 [==============================] - 8s 31ms/step - loss: 27603.8516 - mae: 46.4173 - val_loss: 53589.2891 - val_mae: 66.3131\n","Epoch 45/50\n","271/271 [==============================] - 8s 31ms/step - loss: 27627.1641 - mae: 46.1319 - val_loss: 56335.0742 - val_mae: 64.6048\n","Epoch 46/50\n","271/271 [==============================] - 8s 31ms/step - loss: 27163.5996 - mae: 45.3120 - val_loss: 56506.9453 - val_mae: 63.9781\n","Epoch 47/50\n","271/271 [==============================] - 9s 33ms/step - loss: 27313.8848 - mae: 45.7536 - val_loss: 56291.2031 - val_mae: 61.3839\n","Epoch 48/50\n","271/271 [==============================] - 9s 33ms/step - loss: 26791.8574 - mae: 45.4410 - val_loss: 59594.6484 - val_mae: 65.0101\n","Epoch 49/50\n","271/271 [==============================] - 10s 37ms/step - loss: 27109.6582 - mae: 45.0366 - val_loss: 53850.6602 - val_mae: 60.7306\n","Epoch 50/50\n","271/271 [==============================] - 9s 33ms/step - loss: 27341.7637 - mae: 46.0653 - val_loss: 57962.3125 - val_mae: 62.7678\n","25.64707989469944\n","0.35589503572604964\n","0.6312361552532486\n"]}]}]}